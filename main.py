"""
ãƒ•ãƒ©ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å€¤äºˆæ¸¬ãƒ»åå®Ÿä»®æƒ³èª¬æ˜ã‚·ã‚¹ãƒ†ãƒ 
è¡Œå‹•å¤‰æ›´ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã§ã®äºˆæ¸¬ã¨DiCEã«ã‚ˆã‚‹æ”¹å–„ææ¡ˆã‚’æä¾›ã™ã‚‹Flaskã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³
"""

from flask import Flask, render_template, jsonify, request
import os
import logging
import pandas as pd
from datetime import datetime, timedelta
from typing import Dict
import threading
import time
import json

from ml_model import FrustrationPredictor
from sheets_connector import SheetsConnector
from counterfactual_explainer import ActivityCounterfactualExplainer
from llm_feedback_generator import LLMFeedbackGenerator
from scheduler import FeedbackScheduler
from config import Config

app = Flask(__name__)

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
predictor = FrustrationPredictor()
sheets_connector = SheetsConnector()
explainer = ActivityCounterfactualExplainer()
feedback_generator = LLMFeedbackGenerator()
scheduler = FeedbackScheduler()

# DiCE daily scheduler
dice_scheduler_thread = None
dice_scheduler_running = False
last_dice_result = {}

# ãƒ‡ãƒ¼ã‚¿æ›´æ–°ç›£è¦–ã‚¹ãƒ¬ãƒƒãƒ‰
data_monitor_thread = None
data_monitor_running = False
last_prediction_result = {}  # å…¨ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®äºˆæ¸¬çµæœã‚’ä¿å­˜: {user_id: prediction_data}

@app.route('/')
def index():
    """ãƒ¡ã‚¤ãƒ³ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ - éå»24æ™‚é–“ã®DiCEçµæœå¯è¦–åŒ–"""
    import time
    timestamp = str(int(time.time()))
    return render_template('frustration_dashboard.html', timestamp=timestamp)

@app.route('/mirror')
def smart_mirror():
    """ã‚¹ãƒãƒ¼ãƒˆãƒŸãƒ©ãƒ¼å°‚ç”¨UI - å®Œå…¨è‡ªå‹•é‹è»¢ãƒ»ã‚¿ãƒƒãƒãƒ¬ã‚¹æ“ä½œ"""
    return render_template('smart_mirror.html')

@app.route('/tablet')
def tablet_mirror():
    """ã‚¿ãƒ–ãƒ¬ãƒƒãƒˆå°‚ç”¨UI - æ‰‹å‹•ãƒ¦ãƒ¼ã‚¶ãƒ¼é¸æŠãƒ»æ—¥æ¬¡å¹³å‡è¡¨ç¤º"""
    return render_template('tablet_mirror.html')

@app.route('/trends')
def frustration_trends():
    """ãƒ¦ãƒ¼ã‚¶ãƒ¼åˆ¥ãƒ•ãƒ©ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å€¤æ¨ç§»ç¢ºèªã‚·ãƒ¼ãƒˆ"""
    return render_template('frustration_trends.html')

@app.route('/activity')
def activity_page():
    """æ´»å‹•ãƒ‡ãƒ¼ã‚¿å…¥åŠ›ãƒšãƒ¼ã‚¸ (my-liff-appäº’æ›) - ãƒªãƒ€ã‚¤ãƒ¬ã‚¯ãƒˆ"""
    from flask import redirect
    return redirect('https://kotoomii.github.io/my-liff-app/activity.html')

@app.route('/nasa')
def nasa_page():
    """NASA-TLXè©•ä¾¡ãƒšãƒ¼ã‚¸ (my-liff-appäº’æ›) - ãƒªãƒ€ã‚¤ãƒ¬ã‚¯ãƒˆ"""
    from flask import redirect
    return redirect('https://kotoomii.github.io/my-liff-app/nasa.html')

@app.route('/api/frustration/predict', methods=['POST'])
def predict_frustration():
    """
    è¡Œå‹•å¤‰æ›´ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã§ã®ãƒ•ãƒ©ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å€¤äºˆæ¸¬API
    """
    try:
        data = request.get_json()
        user_id = data.get('user_id', 'default')
        target_timestamp = data.get('timestamp')
        
        if target_timestamp:
            target_timestamp = datetime.fromisoformat(target_timestamp)
        
        # ãƒ‡ãƒ¼ã‚¿å–å¾—
        activity_data = sheets_connector.get_activity_data(user_id)
        fitbit_data = sheets_connector.get_fitbit_data(user_id)
        
        if activity_data.empty:
            return jsonify({
                'status': 'error',
                'message': 'æ´»å‹•ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“'
            }), 400
        
        # ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†
        activity_processed = predictor.preprocess_activity_data(activity_data)
        if activity_processed.empty:
            return jsonify({
                'status': 'error', 
                'message': 'ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸ'
            }), 400
        
        # Fitbitãƒ‡ãƒ¼ã‚¿ã¨ã®çµ±åˆ
        df_enhanced = predictor.aggregate_fitbit_by_activity(activity_processed, fitbit_data)
        
        # Walk Forward Validationã§å­¦ç¿’
        if len(df_enhanced) > 10:
            training_results = predictor.walk_forward_validation_train(df_enhanced)
        else:
            training_results = {}
        
        # ãƒ•ãƒ©ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å€¤äºˆæ¸¬
        prediction_result = predictor.predict_frustration_at_activity_change(
            df_enhanced, target_timestamp
        )
        
        # è¡Œå‹•å¤‰æ›´ã‚¿ã‚¤ãƒŸãƒ³ã‚°ä¸€è¦§
        change_timestamps = predictor.get_activity_change_timestamps(df_enhanced)
        
        return jsonify({
            'status': 'success',
            'user_id': user_id,
            'prediction': prediction_result,
            'activity_change_timestamps': [ts.isoformat() for ts in change_timestamps],
            'model_performance': training_results,
            'timestamp': datetime.now().isoformat()
        })
        
    except Exception as e:
        logger.error(f"ãƒ•ãƒ©ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å€¤äºˆæ¸¬ã‚¨ãƒ©ãƒ¼: {e}")
        return jsonify({
            'status': 'error',
            'message': str(e)
        }), 500

@app.route('/api/frustration/predict-activity', methods=['POST'])
def predict_activity_frustration():
    """
    æ–°ã—ã„æ´»å‹•å…¥åŠ›æ™‚ã®ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ•ãƒ©ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³äºˆæ¸¬API
    """
    try:
        data = request.get_json()
        user_id = data.get('user_id', 'default')
        activity_category = data.get('CatSub')  # æ´»å‹•ã‚«ãƒ†ã‚´ãƒª
        activity_subcategory = data.get('CatMid', activity_category)  # æ´»å‹•ã‚µãƒ–ã‚«ãƒ†ã‚´ãƒª
        
        # æ™‚é–“ã®è¨ˆç®— - start_timeã¨end_timeãŒã‚ã‚‹å ´åˆã¯ãã‚Œã‚’ä½¿ç”¨
        start_time = data.get('start_time')
        end_time = data.get('end_time')
        duration = data.get('Duration')
        
        if start_time and end_time and not duration:
            # start_timeã¨end_timeã‹ã‚‰æ™‚é–“ã‚’è¨ˆç®—
            try:
                from datetime import datetime, timedelta
                
                # æ™‚åˆ»å½¢å¼ã‚’è§£æ (HH:MMå½¢å¼ã‚’æƒ³å®š)
                start_hour, start_min = map(int, start_time.split(':'))
                end_hour, end_min = map(int, end_time.split(':'))
                
                start_total_min = start_hour * 60 + start_min
                end_total_min = end_hour * 60 + end_min
                
                # æ—¥ä»˜ã‚’ã¾ãŸãå ´åˆã‚’è€ƒæ…®
                if end_total_min < start_total_min:
                    end_total_min += 24 * 60  # ç¿Œæ—¥ã¨ã¿ãªã™
                
                duration = end_total_min - start_total_min
                logger.info(f"æ™‚é–“è¨ˆç®—: {start_time} â†’ {end_time} = {duration}åˆ†")
                
            except (ValueError, AttributeError) as e:
                logger.warning(f"æ™‚åˆ»è§£æã‚¨ãƒ©ãƒ¼: {e}, ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ60åˆ†ã‚’ä½¿ç”¨")
                duration = 60
        elif not duration:
            duration = 60  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
            
        timestamp = data.get('timestamp', datetime.now().isoformat())
        
        if isinstance(timestamp, str):
            timestamp = datetime.fromisoformat(timestamp)
        
        # éå»ãƒ‡ãƒ¼ã‚¿å–å¾—ãƒ»å‰å‡¦ç†
        activity_data = sheets_connector.get_activity_data(user_id)
        fitbit_data = sheets_connector.get_fitbit_data(user_id)
        
        if activity_data.empty:
            # åˆå›åˆ©ç”¨æ™‚ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆäºˆæ¸¬å€¤ã‚’è¿”ã™
            default_frustration = 10.0  # 1-20ã‚¹ã‚±ãƒ¼ãƒ«ã®ä¸­é–“å€¤
            return jsonify({
                'status': 'success',
                'user_id': user_id,
                'predicted_frustration': default_frustration,
                'activity': activity_category,
                'duration': duration,
                'confidence': 0.5,
                'message': 'åˆå›åˆ©ç”¨ã®ãŸã‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’è¿”ã—ã¾ã—ãŸ',
                'timestamp': timestamp.isoformat()
            })
        
        # ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ã¨ãƒ¢ãƒ‡ãƒ«å­¦ç¿’
        activity_processed = predictor.preprocess_activity_data(activity_data)
        df_enhanced = predictor.aggregate_fitbit_by_activity(activity_processed, fitbit_data)
        
        if len(df_enhanced) > 5:  # æœ€ä½5ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã§å­¦ç¿’
            predictor.walk_forward_validation_train(df_enhanced)
        
        # æ–°ã—ã„æ´»å‹•ã®ãƒ•ãƒ©ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å€¤äºˆæ¸¬
        prediction_result = predictor.predict_single_activity(
            activity_category, 
            duration, 
            timestamp
        )
        
        if 'error' in prediction_result:
            return jsonify({
                'status': 'error',
                'message': prediction_result['error']
            }), 400
        
        predicted_frustration = prediction_result['predicted_frustration']
        confidence = prediction_result['confidence']
        
        # äºˆæ¸¬çµæœã‚’ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã«è¨˜éŒ²
        prediction_data = {
            'timestamp': timestamp.isoformat(),
            'user_id': user_id,
            'activity': activity_category,
            'duration': duration,
            'predicted_frustration': predicted_frustration,
            'confidence': confidence,
            'source': 'manual_api',  # æ‰‹å‹•APIäºˆæ¸¬ã§ã‚ã‚‹ã“ã¨ã‚’æ˜è¨˜
            'notes': f'Subcategory: {activity_subcategory}'
        }
        
        # æ‰‹å‹•äºˆæ¸¬ã®å ´åˆã®ã¿ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã«ä¿å­˜ï¼ˆè‡ªå‹•ç›£è¦–ã¨ã®é‡è¤‡ã‚’é¿ã‘ã‚‹ãŸã‚ï¼‰
        # ãƒ‡ãƒ¼ã‚¿ç›£è¦–ãƒ«ãƒ¼ãƒ—ã«ã‚ˆã‚‹è‡ªå‹•äºˆæ¸¬çµæœã¯ data_monitor_loop ã§ä¿å­˜ã•ã‚Œã‚‹
        try:
            sheets_connector.save_prediction_data(prediction_data)
            logger.info(f"æ‰‹å‹•äºˆæ¸¬çµæœã‚’ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã«è¨˜éŒ²: {user_id}, {activity_category}, äºˆæ¸¬å€¤: {predicted_frustration:.2f}")
        except Exception as save_error:
            logger.error(f"äºˆæ¸¬çµæœä¿å­˜ã‚¨ãƒ©ãƒ¼: {save_error}")
            # ä¿å­˜ã‚¨ãƒ©ãƒ¼ãŒã‚ã£ã¦ã‚‚APIãƒ¬ã‚¹ãƒãƒ³ã‚¹ã«ã¯å½±éŸ¿ã—ãªã„
        
        return jsonify({
            'status': 'success',
            'user_id': user_id,
            'predicted_frustration': round(predicted_frustration, 2),
            'activity': activity_category,
            'subcategory': activity_subcategory,
            'duration': duration,
            'confidence': round(confidence, 3),
            'timestamp': timestamp.isoformat(),
            'logged_to_sheets': True
        })
        
    except Exception as e:
        logger.error(f"æ´»å‹•ãƒ•ãƒ©ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³äºˆæ¸¬ã‚¨ãƒ©ãƒ¼: {e}")
        return jsonify({
            'status': 'error',
            'message': str(e)
        }), 500

@app.route('/api/frustration/daily-dice-schedule', methods=['POST'])
def generate_daily_dice_schedule():
    """
    1æ—¥ã®çµ‚ã‚ã‚Šã«æ™‚é–“ã”ã¨ã®DiCEæ”¹å–„ææ¡ˆã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ç”Ÿæˆ
    """
    try:
        data = request.get_json()
        user_id = data.get('user_id', 'default')
        target_date = data.get('date', datetime.now().date().isoformat())
        
        if isinstance(target_date, str):
            target_date = datetime.fromisoformat(target_date).date()
        
        # ãã®æ—¥ã®æ´»å‹•ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        activity_data = sheets_connector.get_activity_data(user_id)
        fitbit_data = sheets_connector.get_fitbit_data(user_id)
        
        if activity_data.empty:
            return jsonify({
                'status': 'error',
                'message': 'æ´»å‹•ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“'
            }), 400
        
        # æŒ‡å®šæ—¥ã®ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        activity_data['Date'] = pd.to_datetime(activity_data['Timestamp']).dt.date
        daily_activities = activity_data[activity_data['Date'] == target_date].copy()
        
        if daily_activities.empty:
            return jsonify({
                'status': 'success',
                'user_id': user_id,
                'date': target_date.isoformat(),
                'message': 'ãã®æ—¥ã®æ´»å‹•ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“',
                'schedule': [],
                'recommendations': []
            })
        
        # ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ã¨ãƒ¢ãƒ‡ãƒ«å­¦ç¿’
        activity_processed = predictor.preprocess_activity_data(activity_data)
        df_enhanced = predictor.aggregate_fitbit_by_activity(activity_processed, fitbit_data)
        
        if len(df_enhanced) > 5:
            predictor.walk_forward_validation_train(df_enhanced)
        
        # 1æ™‚é–“ã”ã¨ã®ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ææ¡ˆã‚’ç”Ÿæˆï¼ˆDiCEæ–¹å¼ï¼‰
        dice_result = explainer.generate_hourly_alternatives(
            activity_data, 
            predictor,
            target_date
        )
        
        if dice_result and dice_result.get('hourly_schedule'):
            hourly_schedule = dice_result['hourly_schedule']
            message = dice_result.get('message', 'æ™‚é–“åˆ¥æ”¹å–„ææ¡ˆã‚’ç”Ÿæˆã—ã¾ã—ãŸ')
            total_improvement = dice_result.get('total_improvement', 0)
        else:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šåŸºæœ¬çš„ãªæ™‚é–“åˆ¥ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«
            hourly_schedule = []
            daily_activities = daily_activities.sort_values('Timestamp')
            
            for hour in range(24):  # 0-23æ™‚
                hour_start = datetime.combine(target_date, datetime.min.time()) + timedelta(hours=hour)
                hour_end = hour_start + timedelta(hours=1)
                
                # ãã®æ™‚é–“å¸¯ã®æ´»å‹•ã‚’å–å¾—
                hour_activities = daily_activities[
                    (daily_activities['Timestamp'] >= hour_start) & 
                    (daily_activities['Timestamp'] < hour_end)
                ]
                
                if not hour_activities.empty:
                    # å®Ÿéš›ã®æ´»å‹•ã¨ãƒ•ãƒ©ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å€¤
                    actual_activity = hour_activities.iloc[0]
                    actual_frustration = actual_activity.get('NASA_F', 10.0)
                    
                    # ã‚·ãƒ³ãƒ—ãƒ«ãªææ¡ˆï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰
                    suggested_activity = 'ãƒªãƒ©ãƒƒã‚¯ã‚¹' if actual_activity['CatSub'] == 'ä»•äº‹' else 'è»½ã„é‹å‹•'
                
                # ãã®æ™‚é–“ã®ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«æƒ…å ±
                hour_info = {
                    'hour': hour,
                    'time_range': f"{hour:02d}:00-{(hour+1):02d}:00",
                    'actual_activity': actual_activity['CatSub'],
                    'actual_frustration': round(float(actual_frustration), 2),
                    'actual_duration': int(actual_activity.get('Duration', 60)),
                    'suggested_activity': None,
                    'suggested_frustration': None,
                    'improvement': 0.0,
                    'has_suggestion': False
                }
                
                # DiCEææ¡ˆãŒã‚ã‚‹å ´åˆ
                if dice_suggestions and dice_suggestions.get('alternatives'):
                    best_alternative = dice_suggestions['alternatives'][0]
                    suggested_frustration = best_alternative.get('predicted_frustration', actual_frustration)
                    improvement = actual_frustration - suggested_frustration
                    
                    if improvement > 0.5:  # 0.5ä»¥ä¸Šã®æ”¹å–„ãŒè¦‹è¾¼ã‚ã‚‹å ´åˆã®ã¿ææ¡ˆ
                        hour_info.update({
                            'suggested_activity': best_alternative.get('activity', actual_activity['CatSub']),
                            'suggested_frustration': round(suggested_frustration, 2),
                            'improvement': round(improvement, 2),
                            'has_suggestion': True
                        })
                        
                        # æ—¥æ¬¡æ¨å¥¨äº‹é …ã«è¿½åŠ 
                        daily_recommendations.append({
                            'time': f"{hour:02d}:00",
                            'original': f"{actual_activity['CatSub']} (ãƒ•ãƒ©ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³: {actual_frustration:.1f})",
                            'suggested': f"{best_alternative.get('activity')} (äºˆæ¸¬ãƒ•ãƒ©ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³: {suggested_frustration:.1f})",
                            'improvement': round(improvement, 2),
                            'reason': f"ã“ã®æ™‚é–“ã«{best_alternative.get('activity')}ã‚’è¡Œã†ã“ã¨ã§ã€ãƒ•ãƒ©ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’{improvement:.1f}ãƒã‚¤ãƒ³ãƒˆå‰Šæ¸›ã§ãã¾ã™"
                        })
                
                hourly_schedule.append(hour_info)
            
            else:
                # ãã®æ™‚é–“ã«æ´»å‹•ãŒãªã„å ´åˆ
                hourly_schedule.append({
                    'hour': hour,
                    'time_range': f"{hour:02d}:00-{(hour+1):02d}:00",
                    'actual_activity': None,
                    'actual_frustration': None,
                    'actual_duration': 0,
                    'suggested_activity': None,
                    'suggested_frustration': None,
                    'improvement': 0.0,
                    'has_suggestion': False
                })
        
        # å…¨ä½“çµ±è¨ˆ
        total_actual_frustration = sum([h['actual_frustration'] for h in hourly_schedule if h['actual_frustration'] is not None])
        total_suggested_frustration = sum([h['suggested_frustration'] for h in hourly_schedule if h['suggested_frustration'] is not None])
        total_improvement = sum([h['improvement'] for h in hourly_schedule])
        
        # DiCEã«ã‚ˆã‚‹æ™‚é–“åˆ¥æ”¹å–„ææ¡ˆãƒ¬ã‚¹ãƒãƒ³ã‚¹å½¢å¼ã«çµ±ä¸€
        if dice_result and dice_result.get('hourly_schedule'):
            return jsonify({
                'status': 'success',
                'user_id': user_id,
                'date': target_date.isoformat(),
                'schedule': dice_result['hourly_schedule'],
                'message': dice_result.get('message', 'ä»Šæ—¥ã“ã®ã‚ˆã†ãªæ´»å‹•ã‚’ã—ã¦ã„ãŸã‚‰ã‚¹ãƒˆãƒ¬ã‚¹ãƒ¬ãƒ™ãƒ«ãŒä¸‹ãŒã£ã¦ã„ã¾ã—ãŸ'),
                'total_improvement': dice_result.get('total_improvement', 0),
                'summary': dice_result.get('summary', ''),
                'confidence': dice_result.get('confidence', 0.7),
                'generated_at': datetime.now().isoformat()
            })
        else:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å¿œç­”
            return jsonify({
                'status': 'success',
                'user_id': user_id,
                'date': target_date.isoformat(),
                'schedule': [],
                'message': 'ä»Šæ—¥ã“ã®ã‚ˆã†ãªæ´»å‹•ã‚’ã—ã¦ã„ãŸã‚‰ã‚¹ãƒˆãƒ¬ã‚¹ãƒ¬ãƒ™ãƒ«ãŒä¸‹ãŒã£ã¦ã„ã¾ã—ãŸ',
                'total_improvement': 0,
                'summary': 'ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã‚‹ãŸã‚ã€è©³ç´°ãªææ¡ˆã‚’ç”Ÿæˆã§ãã¾ã›ã‚“ã§ã—ãŸ',
                'confidence': 0.3,
                'generated_at': datetime.now().isoformat()
            })
        
    except Exception as e:
        logger.error(f"æ—¥æ¬¡DiCEã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
        return jsonify({
            'status': 'error',
            'message': str(e)
        }), 500

@app.route('/api/frustration/dice-analysis', methods=['POST'])
def generate_dice_analysis():
    """
    éå»24æ™‚é–“ã®è¡Œå‹•ã«å¯¾ã™ã‚‹DiCEåˆ†æAPI
    """
    try:
        data = request.get_json()
        user_id = data.get('user_id', 'default')
        target_timestamp = data.get('timestamp')
        lookback_hours = data.get('lookback_hours', 24)
        
        if target_timestamp:
            target_timestamp = datetime.fromisoformat(target_timestamp)
        
        # ãƒ‡ãƒ¼ã‚¿å–å¾—
        activity_data = sheets_connector.get_activity_data(user_id)
        fitbit_data = sheets_connector.get_fitbit_data(user_id)
        
        if activity_data.empty:
            return jsonify({
                'status': 'error',
                'message': 'æ´»å‹•ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“'
            }), 400
        
        # ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†
        activity_processed = predictor.preprocess_activity_data(activity_data)
        if activity_processed.empty:
            return jsonify({
                'status': 'error',
                'message': 'ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸ'
            }), 400
        
        # Fitbitãƒ‡ãƒ¼ã‚¿ã¨ã®çµ±åˆ
        df_enhanced = predictor.aggregate_fitbit_by_activity(activity_processed, fitbit_data)
        
        # ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ï¼ˆå¿…è¦ã«å¿œã˜ã¦ï¼‰
        if len(df_enhanced) > 10 and predictor.model is None:
            predictor.walk_forward_validation_train(df_enhanced)
        
        # DiCEåˆ†æå®Ÿè¡Œ
        dice_result = explainer.generate_activity_based_explanation(
            df_enhanced, predictor, target_timestamp, lookback_hours
        )
        
        return jsonify({
            'status': 'success',
            'user_id': user_id,
            'dice_analysis': dice_result,
            'lookback_hours': lookback_hours,
            'timestamp': datetime.now().isoformat()
        })
        
    except Exception as e:
        logger.error(f"DiCEåˆ†æã‚¨ãƒ©ãƒ¼: {e}")
        return jsonify({
            'status': 'error',
            'message': str(e)
        }), 500

@app.route('/api/frustration/timeline', methods=['POST'])
def get_frustration_timeline():
    """
    éå»24æ™‚é–“ã®ãƒ•ãƒ©ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å€¤ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³å–å¾—API
    """
    try:
        # ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®ç¢ºèªã¨ä¿®æ­£
        if request.is_json:
            data = request.get_json()
            if data is None:
                data = {}
        else:
            data = {}
        
        user_id = data.get('user_id', 'default')
        date = data.get('date', datetime.now().strftime('%Y-%m-%d'))
        
        logger.info(f"Timeline APIå‘¼ã³å‡ºã— - user_id: {user_id}, date: {date}")
        
        # ãƒ‡ãƒ¼ã‚¿å–å¾—
        activity_data = sheets_connector.get_activity_data(user_id)
        fitbit_data = sheets_connector.get_fitbit_data(user_id)
        
        # Google Sheetsæ¥ç¶šã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯é©åˆ‡ãªãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿”ã™
        if activity_data.empty:
            if sheets_connector.gc is None:
                return jsonify({
                    'status': 'success',
                    'date': date,
                    'timeline': [],
                    'message': 'Google Sheetsã«æ¥ç¶šã§ãã¾ã›ã‚“ã€‚èªè¨¼è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚'
                })
            else:
                return jsonify({
                    'status': 'success', 
                    'date': date,
                    'timeline': [],
                    'message': 'ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“'
                })
        
        # æŒ‡å®šæ—¥ã®ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        target_date = datetime.strptime(date, '%Y-%m-%d').date()
        if 'Timestamp' in activity_data.columns:
            activity_data['date'] = pd.to_datetime(activity_data['Timestamp']).dt.date
            daily_data = activity_data[activity_data['date'] == target_date]
        else:
            daily_data = pd.DataFrame()
        
        if daily_data.empty:
            return jsonify({
                'status': 'success',
                'date': date,
                'timeline': [],
                'message': 'æŒ‡å®šæ—¥ã®ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“'
            })
        
        # ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†
        activity_processed = predictor.preprocess_activity_data(daily_data)
        df_enhanced = predictor.aggregate_fitbit_by_activity(activity_processed, fitbit_data)
        
        # ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³ä½œæˆï¼ˆãƒ¢ãƒ‡ãƒ«äºˆæ¸¬å€¤ã‚’ä½¿ç”¨ï¼‰
        timeline = []
        for idx, row in df_enhanced.iterrows():
            predicted_frustration = None
            
            # å„æ´»å‹•ã«å¯¾ã—ã¦ãƒ¢ãƒ‡ãƒ«äºˆæ¸¬ã‚’å®Ÿè¡Œ
            try:
                # æ´»å‹•ãƒ‡ãƒ¼ã‚¿ã®ãƒãƒƒãƒäºˆæ¸¬ã®ãŸã‚ã«å˜ä¸€è¡Œã®DataFrameã‚’ä½œæˆ
                single_row_df = df_enhanced.iloc[[idx]]
                prediction_result = predictor.predict_frustration_batch(single_row_df)
                
                if prediction_result and len(prediction_result) > 0:
                    predicted_value = prediction_result[0].get('predicted_frustration')
                    if predicted_value is not None:
                        predicted_frustration = predicted_value
                        
            except Exception as e:
                logger.warning(f"äºˆæ¸¬ã‚¨ãƒ©ãƒ¼: {e}")
                predicted_frustration = None
            
            # äºˆæ¸¬å€¤ãŒå–å¾—ã§ããŸå ´åˆã®ã¿ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³ã«è¿½åŠ 
            if predicted_frustration is not None:
                timeline.append({
                    'timestamp': row['Timestamp'].isoformat(),
                    'hour': row.get('hour', 0),
                    'activity': row.get('CatSub', 'unknown'),
                    'duration': row.get('Duration', 0),
                    'frustration_value': predicted_frustration,  # ãƒ¢ãƒ‡ãƒ«äºˆæ¸¬å€¤ã‚’ä½¿ç”¨
                    'actual_frustration': row.get('NASA_F'),      # å®Ÿãƒ‡ãƒ¼ã‚¿ã‚‚ä¿æŒï¼ˆæ¯”è¼ƒç”¨ï¼‰
                    'activity_change': row.get('activity_change', 0) == 1,
                    'lorenz_stats': {
                        'mean': row.get('lorenz_mean', 0),
                        'std': row.get('lorenz_std', 0)
                    }
                })
            else:
                logger.info(f"æ´»å‹•ã‚’ã‚¹ã‚­ãƒƒãƒ—: äºˆæ¸¬å€¤ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ - {row.get('CatSub', 'unknown')} at {row['Timestamp']}")
        
        # æ™‚é–“é †ã«ã‚½ãƒ¼ãƒˆ
        timeline.sort(key=lambda x: x['timestamp'])
        
        return jsonify({
            'status': 'success',
            'user_id': user_id,
            'date': date,
            'timeline': timeline,
            'total_entries': len(timeline)
        })
        
    except Exception as e:
        logger.error(f"ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        return jsonify({
            'status': 'error',
            'message': str(e)
        }), 500

@app.route('/api/feedback/generate', methods=['POST'])
def generate_feedback():
    """
    LLMã‚’ä½¿ç”¨ã—ãŸè‡ªç„¶è¨€èªãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ç”ŸæˆAPI
    """
    try:
        data = request.get_json()
        user_id = data.get('user_id', 'default')
        feedback_type = data.get('type', 'evening')  # 'morning' or 'evening'
        
        # DiCEçµæœã‚’å–å¾—ï¼ˆéå»24æ™‚é–“ï¼‰
        dice_results = []
        
        # éå»24æ™‚é–“ã®DiCEåˆ†æã‚’å®Ÿè¡Œ
        for hours_back in range(0, 24, 6):  # 6æ™‚é–“ãŠãã«åˆ†æ
            target_time = datetime.now() - timedelta(hours=hours_back)
            
            # ãƒ‡ãƒ¼ã‚¿å–å¾—
            activity_data = sheets_connector.get_activity_data(user_id)
            fitbit_data = sheets_connector.get_fitbit_data(user_id)
            
            if not activity_data.empty:
                activity_processed = predictor.preprocess_activity_data(activity_data)
                df_enhanced = predictor.aggregate_fitbit_by_activity(activity_processed, fitbit_data)
                
                if len(df_enhanced) > 5:
                    dice_result = explainer.generate_activity_based_explanation(
                        df_enhanced, predictor, target_time, 6
                    )
                    
                    if dice_result.get('type') != 'fallback':
                        dice_results.append(dice_result)
        
        # ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ç”Ÿæˆ
        if feedback_type == 'morning':
            feedback_result = feedback_generator.generate_morning_briefing(dice_results)
        else:
            feedback_result = feedback_generator.generate_evening_summary(dice_results)
        
        return jsonify({
            'status': 'success',
            'user_id': user_id,
            'feedback_type': feedback_type,
            'feedback': feedback_result,
            'dice_results_count': len(dice_results),
            'timestamp': datetime.now().isoformat()
        })
        
    except Exception as e:
        logger.error(f"ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
        return jsonify({
            'status': 'error',
            'message': str(e)
        }), 500

@app.route('/api/scheduler/status', methods=['GET'])
def scheduler_status():
    """å®šæœŸãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ã®çŠ¶æ…‹å–å¾—"""
    try:
        status = scheduler.get_status()
        return jsonify({
            'status': 'success',
            'scheduler': status
        })
    except Exception as e:
        logger.error(f"ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼çŠ¶æ…‹å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        return jsonify({
            'status': 'error',
            'message': str(e)
        }), 500

@app.route('/api/scheduler/config', methods=['POST'])
def update_scheduler_config():
    """å®šæœŸãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ã®è¨­å®šæ›´æ–°"""
    try:
        data = request.get_json()
        morning_time = data.get('morning_time')
        evening_time = data.get('evening_time')
        enabled = data.get('enabled')
        
        scheduler.update_schedule_config(morning_time, evening_time, enabled)
        
        return jsonify({
            'status': 'success',
            'message': 'ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼è¨­å®šã‚’æ›´æ–°ã—ã¾ã—ãŸ'
        })
    except Exception as e:
        logger.error(f"ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼è¨­å®šæ›´æ–°ã‚¨ãƒ©ãƒ¼: {e}")
        return jsonify({
            'status': 'error',
            'message': str(e)
        }), 500

@app.route('/api/scheduler/trigger', methods=['POST'])
def trigger_manual_feedback():
    """æ‰‹å‹•ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯å®Ÿè¡Œ"""
    try:
        data = request.get_json()
        user_id = data.get('user_id', 'default')
        feedback_type = data.get('type', 'evening')
        
        feedback = scheduler.trigger_manual_feedback(user_id, feedback_type)
        
        return jsonify({
            'status': 'success',
            'feedback': feedback,
            'message': f'{feedback_type}ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’æ‰‹å‹•å®Ÿè¡Œã—ã¾ã—ãŸ'
        })
    except Exception as e:
        logger.error(f"æ‰‹å‹•ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
        return jsonify({
            'status': 'error',
            'message': str(e)
        }), 500

@app.route('/api/feedback/history', methods=['GET'])
def get_feedback_history():
    """ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯å±¥æ­´å–å¾—"""
    try:
        user_id = request.args.get('user_id')
        days = int(request.args.get('days', 7))
        
        history = scheduler.get_recent_feedback(user_id, days)
        
        return jsonify({
            'status': 'success',
            'history': history,
            'count': len(history)
        })
    except Exception as e:
        logger.error(f"ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯å±¥æ­´å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        return jsonify({
            'status': 'error',
            'message': str(e)
        }), 500

@app.route('/api/health', methods=['GET'])
def health_check():
    """ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯"""
    try:
        # å„ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®çŠ¶æ…‹ç¢ºèª
        sheets_status = sheets_connector.test_connection()
        scheduler_status = scheduler.get_status()
        
        return jsonify({
            'status': 'success',
            'timestamp': datetime.now().isoformat(),
            'components': {
                'sheets_connector': sheets_status,
                'scheduler': scheduler_status,
                'predictor_ready': predictor.model is not None,
                'explainer_ready': explainer is not None,
                'feedback_generator_ready': feedback_generator is not None
            }
        })
    except Exception as e:
        logger.error(f"ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {e}")
        return jsonify({
            'status': 'error',
            'message': str(e)
        }), 500

@app.route('/api/users', methods=['GET'])
def get_users():
    """åˆ©ç”¨å¯èƒ½ãƒ¦ãƒ¼ã‚¶ãƒ¼ä¸€è¦§å–å¾—"""
    try:
        # Config.pyã‹ã‚‰è¨­å®šæ¸ˆã¿ãƒ¦ãƒ¼ã‚¶ãƒ¼ä¸€è¦§ã‚’å–å¾—
        config = Config()
        users = config.get_all_users()
        
        return jsonify({
            'status': 'success',
            'users': users
        })
    except Exception as e:
        logger.error(f"ãƒ¦ãƒ¼ã‚¶ãƒ¼ä¸€è¦§å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        return jsonify({
            'status': 'error',
            'message': str(e)
        }), 500

@app.route('/api/frustration/trends', methods=['POST'])
def get_frustration_trends():
    """ãƒ¦ãƒ¼ã‚¶ãƒ¼åˆ¥ãƒ•ãƒ©ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å€¤æ¨ç§»ãƒ‡ãƒ¼ã‚¿å–å¾—"""
    try:
        data = request.get_json()
        user_id = data.get('user_id', 'default')
        days = data.get('days', 30)  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ30æ—¥é–“
        
        # ãƒ‡ãƒ¼ã‚¿å–å¾—
        activity_data = sheets_connector.get_activity_data(user_id)
        
        if activity_data.empty:
            return jsonify({
                'status': 'error',
                'message': 'æ´»å‹•ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“'
            }), 400
        
        # æ—¥åˆ¥å¹³å‡ãƒ•ãƒ©ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å€¤ã‚’è¨ˆç®—
        activity_data['Date'] = pd.to_datetime(activity_data['Timestamp']).dt.date
        
        # éå»æŒ‡å®šæ—¥æ•°ã®ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        end_date = datetime.now().date()
        start_date = end_date - timedelta(days=days)
        activity_data = activity_data[activity_data['Date'] >= start_date]
        
        # æ—¥åˆ¥çµ±è¨ˆã®è¨ˆç®—
        daily_stats = []
        date_range = [start_date + timedelta(days=x) for x in range(days)]
        
        for date in date_range:
            day_data = activity_data[activity_data['Date'] == date]
            
            if not day_data.empty:
                avg_frustration = day_data['NASA_F'].mean()
                min_frustration = day_data['NASA_F'].min()
                max_frustration = day_data['NASA_F'].max()
                activity_count = len(day_data)
                total_duration = day_data['Duration'].sum()
                
                # æ´»å‹•åˆ¥é›†è¨ˆ
                activity_summary = day_data.groupby('CatSub').agg({
                    'NASA_F': ['mean', 'count'],
                    'Duration': 'sum'
                }).round(1)
                
                activity_breakdown = []
                for activity in activity_summary.index:
                    activity_breakdown.append({
                        'activity': activity,
                        'avg_frustration': activity_summary.loc[activity, ('NASA_F', 'mean')],
                        'count': int(activity_summary.loc[activity, ('NASA_F', 'count')]),
                        'total_duration': int(activity_summary.loc[activity, ('Duration', 'sum')])
                    })
            else:
                avg_frustration = None
                min_frustration = None
                max_frustration = None
                activity_count = 0
                total_duration = 0
                activity_breakdown = []
            
            daily_stats.append({
                'date': date.isoformat(),
                'avg_frustration': avg_frustration,
                'min_frustration': min_frustration,
                'max_frustration': max_frustration,
                'activity_count': activity_count,
                'total_duration': total_duration,
                'activity_breakdown': activity_breakdown
            })
        
        # æœŸé–“å…¨ä½“ã®çµ±è¨ˆ
        if not activity_data.empty:
            period_stats = {
                'avg_frustration': activity_data['NASA_F'].mean(),
                'min_frustration': activity_data['NASA_F'].min(),
                'max_frustration': activity_data['NASA_F'].max(),
                'total_activities': len(activity_data),
                'total_duration': activity_data['Duration'].sum(),
                'improvement_trend': calculate_trend(activity_data)
            }
        else:
            period_stats = {
                'avg_frustration': 0,
                'min_frustration': 0,
                'max_frustration': 0,
                'total_activities': 0,
                'total_duration': 0,
                'improvement_trend': 0
            }
        
        return jsonify({
            'status': 'success',
            'user_id': user_id,
            'period': f'{days}æ—¥é–“',
            'daily_trends': daily_stats,
            'period_summary': period_stats,
            'timestamp': datetime.now().isoformat()
        })
        
    except Exception as e:
        logger.error(f"æ¨ç§»ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        return jsonify({
            'status': 'error',
            'message': str(e)
        }), 500

def calculate_trend(activity_data):
    """ãƒ•ãƒ©ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å€¤ã®æ”¹å–„ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’è¨ˆç®—"""
    try:
        if len(activity_data) < 2:
            return 0
        
        # æ—¥ä»˜é †ã«ã‚½ãƒ¼ãƒˆ
        activity_data = activity_data.sort_values('Timestamp')
        
        # å‰åŠã¨å¾ŒåŠã«åˆ†ã‘ã¦å¹³å‡å€¤ã‚’æ¯”è¼ƒ
        mid_point = len(activity_data) // 2
        first_half_avg = activity_data.iloc[:mid_point]['NASA_F'].mean()
        second_half_avg = activity_data.iloc[mid_point:]['NASA_F'].mean()
        
        # æ”¹å–„åº¦ã‚’è¨ˆç®—ï¼ˆè² ã®å€¤ãŒæ”¹å–„ã‚’æ„å‘³ã™ã‚‹ï¼‰
        trend = second_half_avg - first_half_avg
        return round(trend, 2)
        
    except Exception:
        return 0

# ===== DEBUG API ENDPOINTS =====

@app.route('/api/debug/dice-scheduler/status', methods=['GET'])
def debug_dice_scheduler_status():
    """DiCEã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ã®çŠ¶æ…‹ã¨ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ç¢ºèªAPI"""
    try:
        now = datetime.now()
        next_run = now.replace(hour=21, minute=0, second=0, microsecond=0)
        if now > next_run:
            next_run += timedelta(days=1)
        
        status = {
            'scheduler_running': dice_scheduler_running,
            'current_time': now.isoformat(),
            'next_scheduled_run': next_run.isoformat(),
            'seconds_until_next_run': (next_run - now).total_seconds(),
            'last_dice_result': last_dice_result,
            'scheduler_thread_alive': dice_scheduler_thread.is_alive() if dice_scheduler_thread else False
        }
        
        return jsonify({
            'status': 'success',
            'data': status
        })
    except Exception as e:
        logger.error(f"DiCEã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼çŠ¶æ…‹ç¢ºèªã‚¨ãƒ©ãƒ¼: {e}")
        return jsonify({
            'status': 'error',
            'message': str(e)
        }), 500

@app.route('/api/debug/dice-scheduler/trigger', methods=['POST'])
def debug_trigger_dice():
    """æ‰‹å‹•ã§DiCEæ”¹å–„ææ¡ˆã‚’å®Ÿè¡Œã™ã‚‹ãƒ‡ãƒãƒƒã‚°API"""
    global last_dice_result
    
    try:
        data = request.get_json() or {}
        user_id = data.get('user_id', 'default')
        target_date = data.get('date')
        
        if target_date:
            if isinstance(target_date, str):
                target_date = datetime.fromisoformat(target_date.replace('Z', '+00:00')).date()
        else:
            target_date = datetime.now().date()
        
        logger.info(f"æ‰‹å‹•DiCEå®Ÿè¡Œé–‹å§‹: ãƒ¦ãƒ¼ã‚¶ãƒ¼={user_id}, æ—¥ä»˜={target_date}")
        
        dice_result = run_daily_dice_for_user(user_id)
        
        if dice_result:
            last_dice_result = {
                'timestamp': datetime.now().isoformat(),
                'user_id': user_id,
                'result': dice_result,
                'execution_type': 'manual_debug'
            }
            
            return jsonify({
                'status': 'success',
                'message': 'æ‰‹å‹•DiCEå®Ÿè¡Œå®Œäº†',
                'data': {
                    'user_id': user_id,
                    'execution_time': last_dice_result['timestamp'],
                    'total_improvement': dice_result.get('total_improvement', 0),
                    'schedule_items': len(dice_result.get('hourly_schedule', [])),
                    'dice_message': dice_result.get('message', ''),
                    'confidence': dice_result.get('confidence', 0),
                    'summary': dice_result.get('summary', ''),
                    'full_result': dice_result
                }
            })
        else:
            return jsonify({
                'status': 'error',
                'message': 'DiCEå®Ÿè¡Œã«å¤±æ•—ã—ã¾ã—ãŸã€‚ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚'
            }), 400
            
    except Exception as e:
        logger.error(f"æ‰‹å‹•DiCEå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
        return jsonify({
            'status': 'error',
            'message': f'ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}'
        }), 500

@app.route('/api/debug/dice-scheduler/results', methods=['GET'])
def debug_get_dice_results():
    """æœ€æ–°ã®DiCEçµæœã‚’å–å¾—ã™ã‚‹ãƒ‡ãƒãƒƒã‚°API"""
    try:
        if not last_dice_result:
            return jsonify({
                'status': 'success',
                'message': 'DiCEçµæœãŒã¾ã ã‚ã‚Šã¾ã›ã‚“',
                'data': None
            })

        return jsonify({
            'status': 'success',
            'data': last_dice_result
        })
    except Exception as e:
        logger.error(f"DiCEçµæœå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        return jsonify({
            'status': 'error',
            'message': str(e)
        }), 500

@app.route('/api/debug/data-monitor/status', methods=['GET'])
def debug_data_monitor_status():
    """ãƒ‡ãƒ¼ã‚¿ç›£è¦–ã‚¹ãƒ¬ãƒƒãƒ‰ã®çŠ¶æ…‹ç¢ºèªAPI"""
    try:
        status = {
            'monitor_running': data_monitor_running,
            'monitor_thread_alive': data_monitor_thread.is_alive() if data_monitor_thread else False,
            'last_prediction': last_prediction_result if last_prediction_result else None,
            'current_time': datetime.now().isoformat()
        }

        return jsonify({
            'status': 'success',
            'data': status
        })
    except Exception as e:
        logger.error(f"ãƒ‡ãƒ¼ã‚¿ç›£è¦–çŠ¶æ…‹ç¢ºèªã‚¨ãƒ©ãƒ¼: {e}")
        return jsonify({
            'status': 'error',
            'message': str(e)
        }), 500

@app.route('/api/debug/data-monitor/check', methods=['POST'])
def debug_trigger_data_check():
    """æ‰‹å‹•ã§ãƒ‡ãƒ¼ã‚¿æ›´æ–°ãƒã‚§ãƒƒã‚¯ã‚’å®Ÿè¡Œã™ã‚‹ãƒ‡ãƒãƒƒã‚°API"""
    try:
        data = request.get_json() or {}
        user_id = data.get('user_id', 'default')

        has_new = sheets_connector.has_new_data(user_id)

        return jsonify({
            'status': 'success',
            'user_id': user_id,
            'has_new_data': has_new,
            'timestamp': datetime.now().isoformat()
        })
    except Exception as e:
        logger.error(f"ãƒ‡ãƒ¼ã‚¿æ›´æ–°ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {e}")
        return jsonify({
            'status': 'error',
            'message': str(e)
        }), 500

@app.route('/api/tablet/data/<user_id>', methods=['GET'])
def get_tablet_data(user_id):
    """ã‚¿ãƒ–ãƒ¬ãƒƒãƒˆç”¨çµ±åˆãƒ‡ãƒ¼ã‚¿API - ã™ã¹ã¦ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä¸€åº¦ã«å–å¾—"""
    try:
        logger.info(f"ã‚¿ãƒ–ãƒ¬ãƒƒãƒˆãƒ‡ãƒ¼ã‚¿APIå‘¼ã³å‡ºã— - user_id: {user_id}")
        
        # ä»Šæ—¥ã®æ—¥ä»˜ã‚’å–å¾—
        today = datetime.now().strftime('%Y-%m-%d')
        
        # 1. ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        timeline_data = []
        try:
            with app.test_request_context(json={'user_id': user_id, 'date': today}):
                timeline_response = get_frustration_timeline()
                if hasattr(timeline_response, 'get_json'):
                    timeline_result = timeline_response.get_json()
                    if timeline_result and timeline_result.get('status') == 'success':
                        timeline_data = timeline_result.get('timeline', [])
        except Exception as timeline_error:
            logger.warning(f"ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³ãƒ‡ãƒ¼ã‚¿å–å¾—è­¦å‘Š: {timeline_error}")
        
        # 2. DiCEåˆ†æãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        dice_data = {}
        try:
            with app.test_request_context(json={'user_id': user_id}):
                dice_response = get_dice_analysis()
                if hasattr(dice_response, 'get_json'):
                    dice_result = dice_response.get_json()
                    if dice_result and dice_result.get('status') == 'success':
                        dice_data = dice_result.get('dice_analysis', {})
        except Exception as dice_error:
            logger.warning(f"DiCEåˆ†æãƒ‡ãƒ¼ã‚¿å–å¾—è­¦å‘Š: {dice_error}")
        
        # 3. ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        feedback_data = {}
        try:
            # ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ç”Ÿæˆãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
            with app.test_request_context(json={'user_id': user_id, 'feedback_type': 'daily'}):
                feedback_response = generate_feedback()
                if hasattr(feedback_response, 'get_json'):
                    feedback_result = feedback_response.get_json()
                    if feedback_result and feedback_result.get('status') == 'success':
                        feedback_data = feedback_result.get('feedback', {})
        except Exception as feedback_error:
            logger.warning(f"ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿å–å¾—è­¦å‘Š: {feedback_error}")
        
        # 4. ä»Šæ—¥ã®çµ±è¨ˆã‚’è¨ˆç®—
        daily_stats = {
            'date': today,
            'total_activities': len(timeline_data),
            'avg_frustration': 0,
            'min_frustration': 0,
            'max_frustration': 0
        }
        
        if timeline_data:
            frustration_values = [item.get('frustration_value', 0) for item in timeline_data if item.get('frustration_value') is not None]
            if frustration_values:
                daily_stats['avg_frustration'] = round(sum(frustration_values) / len(frustration_values), 1)
                daily_stats['min_frustration'] = min(frustration_values)
                daily_stats['max_frustration'] = max(frustration_values)
        
        # 5. çµ±åˆãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ä½œæˆ
        response_data = {
            'status': 'success',
            'user_id': user_id,
            'timestamp': datetime.now().isoformat(),
            'daily_stats': daily_stats,
            'timeline': timeline_data,
            'dice_analysis': dice_data,
            'feedback': feedback_data,
            'system_info': {
                'data_source': 'spreadsheet',
                'last_update': datetime.now().isoformat(),
                'prediction_logging': True,
                'data_monitoring': True
            }
        }
        
        return jsonify(response_data)
        
    except Exception as e:
        logger.error(f"ã‚¿ãƒ–ãƒ¬ãƒƒãƒˆãƒ‡ãƒ¼ã‚¿API ã‚¨ãƒ©ãƒ¼: {e}")
        return jsonify({
            'status': 'error',
            'user_id': user_id,
            'message': str(e),
            'timestamp': datetime.now().isoformat()
        }), 500

# ===== HELPER FUNCTIONS =====

def get_user_config(user_id: str) -> Dict:
    """ãƒ¦ãƒ¼ã‚¶ãƒ¼è¨­å®šã‚’å–å¾—"""
    # main.pyã®usersé…åˆ—ã¨åŒã˜è¨­å®šã‚’å–å¾—
    users_config = [
        {
            'user_id': 'default', 
            'name': 'ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ¦ãƒ¼ã‚¶ãƒ¼', 
            'icon': 'ğŸ‘¤',
            'activity_sheet': 'Ua06e990fd6d5f4646615595d4e8d337f',
            'fitbit_sheet': 'kotoomi_Fitbit-data-kotomi'
        },
        {
            'user_id': 'user1', 
            'name': 'ãƒ¦ãƒ¼ã‚¶ãƒ¼1', 
            'icon': 'ğŸ‘¨',
            'activity_sheet': 'Ua06e990fd6d5f4646615595d4e8d33',
            'fitbit_sheet': 'kotoomi_Fitbit-data-kotomi'
        },
        {
            'user_id': 'user2', 
            'name': 'ãƒ¦ãƒ¼ã‚¶ãƒ¼2', 
            'icon': 'ğŸ‘©',
            'activity_sheet': 'Ua06e990fd6d5f4646615595d4e8d33',
            'fitbit_sheet': 'kotoomi_Fitbit-data-kotomi'
        },
        {
            'user_id': 'user3', 
            'name': 'ãƒ¦ãƒ¼ã‚¶ãƒ¼3', 
            'icon': 'ğŸ§‘',
            'activity_sheet': 'Ua06e990fd6d5f4646615595d4e8d33',
            'fitbit_sheet': 'kotoomi_Fitbit-data-kotomi'
        },
    ]
    
    for user in users_config:
        if user['user_id'] == user_id:
            return user
    
    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚’è¿”ã™
    return users_config[0]

def daily_dice_scheduler():
    """æ¯æ—¥21:00ã«DiCEæ”¹å–„ææ¡ˆã‚’ç”Ÿæˆã™ã‚‹ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼"""
    global dice_scheduler_running, last_dice_result
    
    while dice_scheduler_running:
        try:
            now = datetime.now()
            # æ¯æ—¥21:00ã«å®Ÿè¡Œ
            target_time = now.replace(hour=21, minute=0, second=0, microsecond=0)
            
            # ä»Šæ—¥ã®21:00ãŒã¾ã æ¥ã¦ã„ãªã„å ´åˆã¯ãã®ã¾ã¾ã€éãã¦ã„ã‚‹å ´åˆã¯æ˜æ—¥ã®21:00
            if now > target_time:
                target_time += timedelta(days=1)
            
            sleep_seconds = (target_time - now).total_seconds()
            logger.info(f"æ¬¡å›DiCEå®Ÿè¡Œäºˆå®š: {target_time.strftime('%Y-%m-%d %H:%M:%S')} ({sleep_seconds:.0f}ç§’å¾Œ)")
            
            # æŒ‡å®šæ™‚åˆ»ã¾ã§å¾…æ©Ÿ
            time.sleep(sleep_seconds)
            
            if dice_scheduler_running:  # ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ãŒåœæ­¢ã•ã‚Œã¦ã„ãªã„ã‹ç¢ºèª
                logger.info("å®šæ™‚DiCEæ”¹å–„ææ¡ˆã‚’å®Ÿè¡Œä¸­...")
                
                # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ¦ãƒ¼ã‚¶ãƒ¼ã§DiCEå®Ÿè¡Œ
                user_id = 'default'
                dice_result = run_daily_dice_for_user(user_id)
                
                if dice_result:
                    last_dice_result = {
                        'timestamp': datetime.now().isoformat(),
                        'user_id': user_id,
                        'result': dice_result,
                        'execution_type': 'scheduled'
                    }
                    logger.info(f"å®šæ™‚DiCEå®Ÿè¡Œå®Œäº†: æ”¹å–„ãƒã‚¤ãƒ³ãƒˆ {dice_result.get('total_improvement', 0):.1f}ç‚¹")
                else:
                    logger.error("å®šæ™‚DiCEå®Ÿè¡Œã«å¤±æ•—ã—ã¾ã—ãŸ")
                    
        except Exception as e:
            logger.error(f"DiCEã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ã‚¨ãƒ©ãƒ¼: {e}")
            time.sleep(3600)  # ã‚¨ãƒ©ãƒ¼æ™‚ã¯1æ™‚é–“å¾…æ©Ÿ

def run_daily_dice_for_user(user_id: str):
    """æŒ‡å®šãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ—¥æ¬¡DiCEæ”¹å–„ææ¡ˆã‚’å®Ÿè¡Œ"""
    try:
        # ãƒ¢ãƒ‡ãƒ«ãŒè¨“ç·´ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª
        activity_data = sheets_connector.get_activity_data(user_id)
        fitbit_data = sheets_connector.get_fitbit_data(user_id)

        if activity_data.empty:
            logger.warning(f"ãƒ¦ãƒ¼ã‚¶ãƒ¼ {user_id} ã®æ´»å‹•ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return None

        # ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ã¨ãƒ¢ãƒ‡ãƒ«è¨“ç·´
        enhanced_data = predictor.preprocess_activity_data(activity_data)
        if not enhanced_data.empty:
            enhanced_data = predictor.aggregate_fitbit_by_activity(enhanced_data, fitbit_data)

            # æœ€æ–°ã®ãƒ¢ãƒ‡ãƒ«ã§è¨“ç·´
            predictor.walk_forward_validation_train(enhanced_data)

        # æ˜¨æ—¥ã®ãƒ‡ãƒ¼ã‚¿ã§DiCEå®Ÿè¡Œ
        yesterday = datetime.now() - timedelta(days=1)
        dice_result = explainer.generate_hourly_alternatives(enhanced_data, predictor, yesterday)

        return dice_result

    except Exception as e:
        logger.error(f"ãƒ¦ãƒ¼ã‚¶ãƒ¼ {user_id} ã®DiCEå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
        return None

def data_monitor_loop():
    """
    å…¨ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ‡ãƒ¼ã‚¿æ›´æ–°ã‚’ç›£è¦–ã—ã€æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ãŒè¿½åŠ ã•ã‚ŒãŸã‚‰è‡ªå‹•çš„ã«ãƒ•ãƒ©ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³äºˆæ¸¬ã‚’å®Ÿè¡Œ
    """
    global data_monitor_running, last_prediction_result

    check_interval = 600  # 600ç§’ï¼ˆ10åˆ†ï¼‰ã”ã¨ã«ãƒã‚§ãƒƒã‚¯
    
    # å…¨ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒªã‚¹ãƒˆã‚’å–å¾—ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã¿åˆ©ç”¨å¯èƒ½ï¼‰
    users_config = [
        {'user_id': 'default', 'name': 'ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ¦ãƒ¼ã‚¶ãƒ¼'},
    ]

    while data_monitor_running:
        try:
            # å…¨ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’ãƒã‚§ãƒƒã‚¯
            for user_config in users_config:
                user_id = user_config['user_id']
                user_name = user_config['name']
                
                if sheets_connector.has_new_data(user_id):
                    logger.info(f"æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã‚’æ¤œçŸ¥ã—ã¾ã—ãŸã€‚ãƒ•ãƒ©ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³äºˆæ¸¬ã‚’å®Ÿè¡Œã—ã¾ã™: {user_name} ({user_id})")

                    # æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢ã—ã¦æœ€æ–°ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼‰
                    activity_data = sheets_connector.get_activity_data(user_id, use_cache=False)
                    fitbit_data = sheets_connector.get_fitbit_data(user_id, use_cache=False)

                    if not activity_data.empty:
                        # ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†
                        activity_processed = predictor.preprocess_activity_data(activity_data)
                        df_enhanced = predictor.aggregate_fitbit_by_activity(activity_processed, fitbit_data)

                        # ãƒ¢ãƒ‡ãƒ«å†è¨“ç·´
                        if len(df_enhanced) > 10:
                            training_results = predictor.walk_forward_validation_train(df_enhanced)
                            logger.info(f"ãƒ¢ãƒ‡ãƒ«å†è¨“ç·´å®Œäº† ({user_name}): {training_results}")

                        # æœ€æ–°ã®æ´»å‹•ã«å¯¾ã™ã‚‹ãƒ•ãƒ©ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³äºˆæ¸¬
                        latest_activity = activity_processed.iloc[-1]
                        prediction_result = predictor.predict_single_activity(
                            latest_activity.get('CatSub', 'unknown'),
                            latest_activity.get('Duration', 60),
                            latest_activity.get('Timestamp', datetime.now())
                        )

                        # ãƒ¦ãƒ¼ã‚¶ãƒ¼åˆ¥ã«äºˆæ¸¬çµæœã‚’ä¿å­˜
                        last_prediction_result[user_id] = {
                            'timestamp': datetime.now().isoformat(),
                            'user_id': user_id,
                            'user_name': user_name,
                            'latest_activity': latest_activity.get('CatSub', 'unknown'),
                            'prediction': prediction_result,
                            'data_count': len(df_enhanced)
                        }

                        logger.info(f"è‡ªå‹•äºˆæ¸¬å®Œäº† ({user_name}): {prediction_result}")

                        # äºˆæ¸¬çµæœã‚’ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã«ä¿å­˜ï¼ˆé‡è¤‡ãƒã‚§ãƒƒã‚¯ä»˜ãï¼‰
                        activity_timestamp = latest_activity.get('Timestamp')
                        prediction_data = {
                            'timestamp': datetime.now().isoformat(),
                            'user_id': user_id,
                            'activity': latest_activity.get('CatSub', 'unknown'),
                            'duration': latest_activity.get('Duration', 0),
                            'predicted_frustration': prediction_result.get('predicted_frustration', 0),
                            'confidence': prediction_result.get('confidence', 0),
                            'actual_frustration': latest_activity.get('NASA_F', None),
                            'source': 'auto_monitoring',  # è‡ªå‹•ç›£è¦–ã«ã‚ˆã‚‹äºˆæ¸¬ã§ã‚ã‚‹ã“ã¨ã‚’æ˜è¨˜
                            'activity_timestamp': activity_timestamp  # é‡è¤‡ãƒã‚§ãƒƒã‚¯ç”¨ã®æ´»å‹•ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—
                        }
                        
                        try:
                            # é‡è¤‡ãƒã‚§ãƒƒã‚¯ï¼šåŒã˜activity_timestampã®äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ãŒæ—¢ã«å­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
                            if not sheets_connector.is_prediction_duplicate(user_id, activity_timestamp):
                                sheets_connector.save_prediction_data(prediction_data)
                                logger.info(f"è‡ªå‹•äºˆæ¸¬çµæœã‚’ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã«è¨˜éŒ²: {user_name}, {latest_activity.get('CatSub', 'unknown')}, äºˆæ¸¬å€¤: {prediction_result.get('predicted_frustration', 0):.2f}")
                            else:
                                logger.info(f"é‡è¤‡ã™ã‚‹äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¹ã‚­ãƒƒãƒ—: {user_name}, {latest_activity.get('CatSub', 'unknown')}")
                        except Exception as save_error:
                            logger.error(f"äºˆæ¸¬çµæœä¿å­˜ã‚¨ãƒ©ãƒ¼ ({user_name}): {save_error}")

            # æ¬¡ã®ãƒã‚§ãƒƒã‚¯ã¾ã§å¾…æ©Ÿ
            time.sleep(check_interval)

        except Exception as e:
            logger.error(f"ãƒ‡ãƒ¼ã‚¿ç›£è¦–ãƒ«ãƒ¼ãƒ—ã‚¨ãƒ©ãƒ¼: {e}")
            time.sleep(check_interval)

def initialize_application():
    """ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³åˆæœŸåŒ–"""
    global dice_scheduler_thread, dice_scheduler_running, data_monitor_thread, data_monitor_running

    try:
        logger.info("ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’åˆæœŸåŒ–ã—ã¦ã„ã¾ã™...")

        # ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼é–‹å§‹
        scheduler.start_scheduler()
        logger.info("å®šæœŸãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ã‚’é–‹å§‹ã—ã¾ã—ãŸ")

        # DiCE daily scheduleré–‹å§‹
        dice_scheduler_running = True
        dice_scheduler_thread = threading.Thread(target=daily_dice_scheduler, daemon=True)
        dice_scheduler_thread.start()
        logger.info("DiCEæ—¥æ¬¡ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ã‚’é–‹å§‹ã—ã¾ã—ãŸ (æ¯æ—¥21:00å®Ÿè¡Œ)")

        # ãƒ‡ãƒ¼ã‚¿æ›´æ–°ç›£è¦–ã‚¹ãƒ¬ãƒƒãƒ‰é–‹å§‹
        data_monitor_running = True
        data_monitor_thread = threading.Thread(target=data_monitor_loop, daemon=True)
        data_monitor_thread.start()
        logger.info("ãƒ‡ãƒ¼ã‚¿æ›´æ–°ç›£è¦–ã‚¹ãƒ¬ãƒƒãƒ‰ã‚’é–‹å§‹ã—ã¾ã—ãŸ (10åˆ†ã”ã¨ã«ãƒã‚§ãƒƒã‚¯)")

        logger.info("ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³åˆæœŸåŒ–å®Œäº†")
    except Exception as e:
        logger.error(f"ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")

def cleanup_application():
    """ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³çµ‚äº†å‡¦ç†"""
    global dice_scheduler_running, data_monitor_running

    try:
        logger.info("ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’çµ‚äº†ã—ã¦ã„ã¾ã™...")

        # DiCE ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼åœæ­¢
        dice_scheduler_running = False

        # ãƒ‡ãƒ¼ã‚¿ç›£è¦–ã‚¹ãƒ¬ãƒƒãƒ‰åœæ­¢
        data_monitor_running = False

        scheduler.stop_scheduler()
        logger.info("ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³çµ‚äº†å®Œäº†")
    except Exception as e:
        logger.error(f"ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³çµ‚äº†ã‚¨ãƒ©ãƒ¼: {e}")

if __name__ == '__main__':
    try:
        # ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³åˆæœŸåŒ–
        initialize_application()
        
        # é–‹ç™ºã‚µãƒ¼ãƒãƒ¼èµ·å‹•
        port = int(os.environ.get('PORT', 8080))
        app.run(host='0.0.0.0', port=port, debug=False, threaded=True)
        
    except KeyboardInterrupt:
        logger.info("ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰å‰²ã‚Šè¾¼ã¿ã«ã‚ˆã‚‹çµ‚äº†")
    except Exception as e:
        logger.error(f"ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
    finally:
        cleanup_application()