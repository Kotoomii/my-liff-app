"""
è¡Œå‹•å˜ä½ã®åå®Ÿä»®æƒ³èª¬æ˜ï¼ˆCounterfactual Explanationsï¼‰æ©Ÿèƒ½
webhooktest.pyã®æˆåŠŸãƒ‘ã‚¿ãƒ¼ãƒ³ã«åŸºã¥ãDiCEå®Ÿè£…
"""

import pandas as pd
import numpy as np
import logging
from typing import Dict, List, Optional
import dice_ml
from dice_ml import Dice
from datetime import datetime, timedelta

from config import Config
from ml_model import KNOWN_ACTIVITIES

logger = logging.getLogger(__name__)

class ActivityCounterfactualExplainer:
    def __init__(self):
        self.config = Config()

    def generate_activity_based_explanation(self,
                                          df_enhanced: pd.DataFrame,
                                          predictor,
                                          target_timestamp: datetime = None,
                                          lookback_hours: int = 24,
                                          callback=None) -> Dict:
        """
        DiCEãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ä½¿ç”¨ã—ãŸåå®Ÿä»®æƒ³èª¬æ˜ç”Ÿæˆ (1æ—¥åˆ†ã®ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦å®Ÿè¡Œ)
        21:00ãªã©ã®å®šæ™‚å®Ÿè¡Œã‚’æƒ³å®šã—ã€ãã®æ—¥1æ—¥ã®å…¨æ´»å‹•ã«å¯¾ã—ã¦DiCEææ¡ˆã‚’ç”Ÿæˆ
        """
        try:
            if target_timestamp is None:
                target_timestamp = datetime.now()

            if df_enhanced.empty:
                logger.warning("DiCEèª¬æ˜ç”Ÿæˆ: ãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™")
                return self._get_error_explanation("ãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™")

            if predictor is None or predictor.model is None:
                logger.warning("ãƒ¢ãƒ‡ãƒ«ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“")
                return self._get_error_explanation("ãƒ¢ãƒ‡ãƒ«ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“")

            # ãã®æ—¥1æ—¥åˆ†ã®ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦DiCEã‚’å®Ÿè¡Œ
            target_date = target_timestamp.date()
            logger.info(f"DiCE: {target_date}ã®1æ—¥åˆ†ã®ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦DiCEåˆ†æã‚’å®Ÿè¡Œã—ã¾ã™")

            # generate_hourly_alternativesã‚’ä½¿ç”¨ã—ã¦1æ—¥åˆ†ã®DiCEææ¡ˆã‚’ç”Ÿæˆ
            daily_result = self.generate_hourly_alternatives(df_enhanced, predictor, target_date, callback=callback)

            if daily_result.get('type') == 'hourly_dice_schedule' and daily_result.get('hourly_schedule'):
                # æ™‚é–“åˆ¥ã®ææ¡ˆã‚’ãƒ•ãƒ©ãƒƒãƒˆãªå½¢å¼ã«å¤‰æ›
                timeline = []
                for item in daily_result['hourly_schedule']:
                    # æ™‚åˆ»æƒ…å ±ã‚’è¿½åŠ 
                    hour = item['hour']
                    timestamp = datetime.combine(target_date, datetime.min.time()) + timedelta(hours=hour)
                    timeline.append({
                        'hour': hour,
                        'time': item.get('time'),  # å®Ÿéš›ã®Timestamp (ä¾‹: "14:30")
                        'timestamp': timestamp.isoformat(),
                        'original_timestamp': timestamp.isoformat(),
                        'time_range': item['time_range'],
                        'original_activity': item['original_activity'],
                        'suggested_activity': item['suggested_activity'],
                        'original_frustration': item.get('original_frustration'),  # ç¾åœ¨ã®Få€¤
                        'predicted_frustration': item.get('predicted_frustration'),  # æ”¹å–„å¾Œã®Få€¤
                        'frustration_reduction': item['improvement'],
                        'improvement': item['improvement'],
                        'confidence': item['confidence']
                    })

                return {
                    'type': 'daily_dice_analysis',
                    'date': target_date.strftime('%Y-%m-%d'),
                    'timeline': timeline,
                    'hourly_schedule': timeline,  # schedulerã¨ã®äº’æ›æ€§ã®ãŸã‚è¿½åŠ 
                    'total_improvement': daily_result['total_improvement'],
                    'average_improvement': daily_result.get('average_improvement', 0),
                    'schedule_items': len(timeline),
                    'message': daily_result.get('message', ''),
                    'summary': daily_result.get('summary', ''),
                    'confidence': daily_result.get('confidence', 0.5)
                }
            else:
                return self._get_error_explanation(daily_result.get('error_message', 'DiCEç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ'))

        except Exception as e:
            logger.error(f"åå®Ÿä»®æƒ³èª¬æ˜ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
            return self._get_error_explanation(str(e))

    def _generate_dice_counterfactual_simple(self,
                                             df_enhanced: pd.DataFrame,
                                             activity_idx: int,
                                             activity: pd.Series,
                                             predictor) -> Optional[Dict]:
        """
        DiCEã‚’ä½¿ç”¨ã—ã¦åå®Ÿä»®æƒ³ä¾‹ã‚’ç”Ÿæˆ (webhooktest.pyå½¢å¼ã®ã‚·ãƒ³ãƒ—ãƒ«ãªå®Ÿè£…)
        """
        try:
            logger.warning(f"ğŸ² DiCEå€‹åˆ¥å‡¦ç†é–‹å§‹: activity_idx={activity_idx}")
            # ===== ãƒ‡ãƒãƒƒã‚°é–‹å§‹: å€¤ã®å‡ºæ‰€ã‚’è¿½è·¡ =====
            logger.info(f"DiCE: activity_idx = {activity_idx}")
            logger.info(f"DiCE: å¯¾è±¡è¡Œã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ = {df_enhanced.index[activity_idx]}")

            # å¯¾è±¡è¡Œã®å…¨ãƒ‡ãƒ¼ã‚¿ã‚’ç¢ºèª
            target_row = df_enhanced.iloc[activity_idx]
            logger.info(f"DiCE: å¯¾è±¡è¡Œã®CatSub = {target_row.get('CatSub', 'N/A')}")
            logger.info(f"DiCE: å¯¾è±¡è¡Œã®Timestamp = {target_row.get('Timestamp', 'N/A')}")

            # NASA_Få€¤ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèªï¼ˆå®Ÿæ¸¬å€¤ï¼‰
            if 'NASA_F' in target_row.index:
                logger.info(f"DiCE: å¯¾è±¡è¡Œã®NASA_Fï¼ˆå®Ÿæ¸¬å€¤ï¼‰= {target_row['NASA_F']}")
            else:
                logger.info("DiCE: å¯¾è±¡è¡Œã«NASA_Fåˆ—ã¯å­˜åœ¨ã—ã¾ã›ã‚“")

            if 'NASA_F_scaled' in target_row.index:
                logger.info(f"DiCE: å¯¾è±¡è¡Œã®NASA_F_scaledï¼ˆå®Ÿæ¸¬å€¤ã‚¹ã‚±ãƒ¼ãƒ«æ¸ˆã¿ï¼‰= {target_row['NASA_F_scaled']}")
            else:
                logger.info("DiCE: å¯¾è±¡è¡Œã«NASA_F_scaledåˆ—ã¯å­˜åœ¨ã—ã¾ã›ã‚“")

            # ç¾åœ¨ã®æ´»å‹•ã®ãƒ•ãƒ©ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å€¤ã‚’ãƒ¢ãƒ‡ãƒ«ã§äºˆæ¸¬
            # ã‚¯ã‚¨ãƒªã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’æº–å‚™
            query_features = df_enhanced.iloc[[activity_idx]][predictor.feature_columns]

            # ãƒ‡ãƒãƒƒã‚°: query_featuresã®å†…å®¹ã‚’ç¢ºèª
            logger.info(f"DiCE: query_features shape: {query_features.shape}")
            logger.info(f"DiCE: query_features columns: {query_features.columns.tolist()}")
            logger.info(f"DiCE: query_features ã®ä¸»è¦ãªå€¤:")
            for col in ['SDNN_scaled', 'Lorenz_Area_scaled', 'hour', 'weekday']:
                if col in query_features.columns:
                    logger.info(f"  - {col} = {query_features[col].iloc[0]}")

            # ã‚¢ã‚¯ãƒ†ã‚£ãƒ“ãƒ†ã‚£ã‚«ãƒ†ã‚´ãƒªã‚’ç¢ºèª
            activity_cols = [col for col in query_features.columns if col.startswith('activity_')]
            active_activity = None
            for col in activity_cols:
                if query_features[col].iloc[0] == 1:
                    active_activity = col.replace('activity_', '')
                    break
            logger.info(f"DiCE: é¸æŠã•ã‚Œã¦ã„ã‚‹æ´»å‹•ã‚«ãƒ†ã‚´ãƒª = {active_activity if active_activity else 'ãªã—'}")

            # é‡è¦ãªç”Ÿä½“æƒ…å ±ã‚«ãƒ©ãƒ ã®NaNãƒã‚§ãƒƒã‚¯
            # ç”Ÿä½“æƒ…å ±ãŒãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—ã™ã‚‹ï¼ˆå¹³å‡å€¤ã§è£œå®Œã—ãªã„ï¼‰
            critical_cols = ['SDNN_scaled', 'Lorenz_Area_scaled']
            for col in critical_cols:
                if col in query_features.columns:
                    val = query_features[col].iloc[0]
                    if pd.isna(val):
                        logger.info(f"DiCE: {col}ãŒNaNã§ã™ã€‚ç”Ÿä½“æƒ…å ±ãŒãªã„ãŸã‚ã“ã®æ´»å‹•ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™")
                        return None
                else:
                    logger.error(f"DiCE: {col}åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                    return None

            # ãƒ¢ãƒ‡ãƒ«ã§äºˆæ¸¬ï¼ˆã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°å¾Œã®å€¤: 0-1ï¼‰
            logger.info("DiCE: ===== ãƒ¢ãƒ‡ãƒ«äºˆæ¸¬ã‚’å®Ÿè¡Œã—ã¾ã™ =====")
            logger.info(f"DiCE: predictor.model ã®ã‚¿ã‚¤ãƒ— = {type(predictor.model)}")

            current_frustration_scaled = predictor.model.predict(query_features)[0]

            logger.info(f"DiCE: ãƒ¢ãƒ‡ãƒ«äºˆæ¸¬çµæœï¼ˆã‚¹ã‚±ãƒ¼ãƒ«æ¸ˆã¿ 0-1ï¼‰= {current_frustration_scaled}")

            if np.isnan(current_frustration_scaled) or np.isinf(current_frustration_scaled):
                logger.warning(f"äºˆæ¸¬å€¤ãŒä¸æ­£ã§ã™ (NaN/Inf): {current_frustration_scaled}")
                logger.warning(f"query_featureså€¤: {query_features.iloc[0].to_dict()}")
                return None

            # ã‚¹ã‚±ãƒ¼ãƒ«æˆ»ã—ï¼ˆ0-1 â†’ 1-20ï¼‰
            current_frustration = current_frustration_scaled * 20.0

            logger.info(f"DiCE: ã‚¹ã‚±ãƒ¼ãƒ«å¤‰æ›ï¼ˆÃ—20ï¼‰å¾Œã®Få€¤ = {current_frustration}")
            logger.info(f"DiCE: ===== ãƒ¢ãƒ‡ãƒ«äºˆæ¸¬å®Œäº† =====")

            # è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™: NaNå€¤ã¨'CatSub'ãŒæ¬ æã—ã¦ã„ã‚‹è¡Œã‚’é™¤å¤–
            required_cols = ['SDNN_scaled', 'Lorenz_Area_scaled', 'NASA_F_scaled', 'CatSub']
            df_train = df_enhanced.dropna(subset=required_cols).copy()

            if len(df_train) < 20:
                logger.warning(f"è¨“ç·´ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ï¼ˆ{len(df_train)}ä»¶ï¼‰")
                return None

            # DiCEç”¨ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä½œæˆ: CatSubåˆ—ã¨ç”Ÿä½“æƒ…å ±ã€æ™‚é–“ç‰¹å¾´é‡ã®ã¿ã‚’å«ã‚€
            # One-Hotã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸæ´»å‹•åˆ—ã¯å«ã‚ãªã„
            dice_features = ['CatSub', 'SDNN_scaled', 'Lorenz_Area_scaled', 'hour_sin', 'hour_cos']

            # æ›œæ—¥åˆ—ã‚’è¿½åŠ 
            weekday_cols = [col for col in df_train.columns if col.startswith('weekday_')]
            dice_features.extend(weekday_cols)

            # DiCEç”¨ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä½œæˆ
            df_dice_train = df_train[dice_features + ['NASA_F_scaled']].copy()

            # 'CatSub'ã‚’ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å‹ã«å¤‰æ›ï¼ˆè¨“ç·´ãƒ‡ãƒ¼ã‚¿ã«å­˜åœ¨ã™ã‚‹ã‚«ãƒ†ã‚´ãƒªã®ã¿ï¼‰
            # ã‚«ãƒ†ã‚´ãƒªä¸€è¦§ã‚’æ˜ç¤ºçš„ã«å–å¾—
            train_categories = sorted(df_dice_train['CatSub'].unique().tolist())
            logger.warning(f"ğŸ”§ DiCE: è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã«å­˜åœ¨ã™ã‚‹CatSub = {train_categories}")

            df_dice_train['CatSub'] = pd.Categorical(df_dice_train['CatSub'], categories=train_categories)

            logger.warning(f"ğŸ”§ DiCE: CatSubåˆ—ã‚’ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å‹ã«å¤‰æ›ã—ã¾ã—ãŸ")
            logger.warning(f"ğŸ”§ DiCE: CatSubã®ã‚«ãƒ†ã‚´ãƒªæ•° = {df_dice_train['CatSub'].nunique()}")

            # ã‚¯ã‚¨ãƒªã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã®æº–å‚™: CatSubåˆ—ã‚’å«ã‚ã‚‹
            query_catsub = target_row.get('CatSub')
            logger.warning(f"ğŸ”§ DiCE: å…ƒã®æ´»å‹• (query) = {query_catsub}")

            # ã‚¯ã‚¨ãƒªã®CatSubãŒè¨“ç·´ãƒ‡ãƒ¼ã‚¿ã«å­˜åœ¨ã™ã‚‹ã‹ç¢ºèª
            if query_catsub not in train_categories:
                logger.info(f"â„¹ï¸ DiCE: å…ƒã®æ´»å‹• '{query_catsub}' ãŒè¨“ç·´ãƒ‡ãƒ¼ã‚¿ã«å­˜åœ¨ã—ãªã„ãŸã‚ã€DiCEææ¡ˆã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™")
                logger.debug(f"   è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã«å­˜åœ¨ã™ã‚‹ã‚«ãƒ†ã‚´ãƒª: {train_categories}")
                return None

            query_dict = {
                'CatSub': [query_catsub],
                'SDNN_scaled': [query_features['SDNN_scaled'].iloc[0]],
                'Lorenz_Area_scaled': [query_features['Lorenz_Area_scaled'].iloc[0]],
                'hour_sin': [query_features['hour_sin'].iloc[0]],
                'hour_cos': [query_features['hour_cos'].iloc[0]]
            }

            # æ›œæ—¥åˆ—ã‚’ã‚¯ã‚¨ãƒªã«è¿½åŠ 
            for col in weekday_cols:
                query_dict[col] = [query_features[col].iloc[0]]

            query_dice = pd.DataFrame(query_dict)
            # query_diceã®CatSubã‚‚è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã¨åŒã˜ã‚«ãƒ†ã‚´ãƒªã§è¨­å®š
            query_dice['CatSub'] = pd.Categorical(query_dice['CatSub'], categories=train_categories)

            logger.warning(f"ğŸ”§ DiCE: query_dice = {query_dice.to_dict('records')[0]}")
            logger.warning(f"ğŸ”§ DiCE: query CatSubã®ã‚«ãƒ†ã‚´ãƒªã‚³ãƒ¼ãƒ‰ = {query_dice['CatSub'].cat.codes[0]}")

            # webhooktest.pyå½¢å¼: ç”Ÿä½“æƒ…å ±ã¨æ™‚é–“ç‰¹å¾´é‡ã‚’continuousã«æŒ‡å®š
            continuous_features = ['SDNN_scaled', 'Lorenz_Area_scaled', 'hour_sin', 'hour_cos']
            # æ›œæ—¥åˆ—ã‚‚continuousã¨ã—ã¦æ‰±ã†ï¼ˆOne-Hotã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰æ¸ˆã¿ã®ãŸã‚ï¼‰
            continuous_features.extend(weekday_cols)

            logger.warning(f"ğŸ”§ DiCE: continuous_features = {continuous_features}")
            logger.warning(f"ğŸ”§ DiCE: CatSubã‚’ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å¤‰æ•°ã¨ã—ã¦æ‰±ã„ã¾ã™")

            # DiCEãƒ‡ãƒ¼ã‚¿ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½œæˆ
            d = dice_ml.Data(
                dataframe=df_dice_train,
                continuous_features=continuous_features,
                outcome_name='NASA_F_scaled'
            )

            # ãƒ¢ãƒ‡ãƒ«ãƒ©ãƒƒãƒ‘ãƒ¼ã‚¯ãƒ©ã‚¹ã‚’ä½œæˆ
            # CatSubã‚’One-Hotã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã—ã¦ã‹ã‚‰å…ƒã®ãƒ¢ãƒ‡ãƒ«ã§äºˆæ¸¬ã™ã‚‹
            class ModelWrapper:
                def __init__(self, original_model, feature_columns, known_activities):
                    self.original_model = original_model
                    self.feature_columns = feature_columns
                    self.known_activities = known_activities
                    self.call_count = 0  # å‘¼ã³å‡ºã—å›æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ

                def predict(self, X):
                    """CatSubã‚’One-Hotã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã—ã¦ã‹ã‚‰äºˆæ¸¬"""
                    self.call_count += 1
                    logger.warning(f"ğŸ”§ğŸ”§ğŸ”§ ModelWrapper.predict() å‘¼ã³å‡ºã— #{self.call_count}")
                    logger.warning(f"ğŸ”§ å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã®å½¢çŠ¶: {X.shape}")
                    logger.warning(f"ğŸ”§ å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã®åˆ—: {X.columns.tolist()}")

                    X_encoded = X.copy()

                    # CatSubã‚’One-Hotã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°
                    if 'CatSub' in X_encoded.columns:
                        # ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å‹ã‚’strå‹ã«å¤‰æ›
                        catsub_values = X_encoded['CatSub'].astype(str)

                        logger.warning(f"ğŸ”§ ModelWrapper: CatSubå€¤ = {catsub_values.tolist()}")

                        for activity in self.known_activities:
                            X_encoded[f'activity_{activity}'] = (catsub_values == activity).astype(int)

                        # ãƒ‡ãƒãƒƒã‚°: One-Hotã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã®çµæœã‚’ç¢ºèª
                        activity_cols = [f'activity_{act}' for act in self.known_activities]
                        active_activities = []
                        for idx in range(len(X_encoded)):
                            row_activities = [col.replace('activity_', '') for col in activity_cols
                                            if col in X_encoded.columns and X_encoded[col].iloc[idx] == 1]
                            active_activities.append(row_activities)
                        logger.warning(f"ğŸ”§ ModelWrapper: One-Hotçµæœ = {active_activities}")

                        # CatSubåˆ—ã‚’å‰Šé™¤
                        X_encoded = X_encoded.drop('CatSub', axis=1)
                    else:
                        logger.error(f"âŒ ModelWrapper: CatSubåˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼åˆ—: {X_encoded.columns.tolist()}")

                    # å¿…è¦ãªåˆ—ã®ã¿ã‚’é¸æŠï¼ˆé †åºã‚‚å…ƒã®feature_columnsã«åˆã‚ã›ã‚‹ï¼‰
                    try:
                        X_final = X_encoded[self.feature_columns]
                    except KeyError as e:
                        logger.error(f"âŒ ModelWrapper: åˆ—ãŒä¸è¶³ã—ã¦ã„ã¾ã™: {e}")
                        logger.error(f"   å¿…è¦ãªåˆ—: {self.feature_columns}")
                        logger.error(f"   å®Ÿéš›ã®åˆ—: {X_encoded.columns.tolist()}")
                        raise

                    # äºˆæ¸¬ã‚’å®Ÿè¡Œ
                    predictions = self.original_model.predict(X_final)
                    logger.warning(f"ğŸ”§ ModelWrapper: äºˆæ¸¬çµæœ = {predictions.tolist()}")
                    logger.warning(f"ğŸ”§ğŸ”§ğŸ”§ ModelWrapper.predict() å®Œäº† #{self.call_count}")

                    return predictions

            # ãƒ©ãƒƒãƒ‘ãƒ¼ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆ
            wrapped_model = ModelWrapper(predictor.model, predictor.feature_columns, KNOWN_ACTIVITIES)

            # DiCEãƒ¢ãƒ‡ãƒ«ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½œæˆï¼ˆãƒ©ãƒƒãƒ‘ãƒ¼ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ï¼‰
            m = dice_ml.Model(
                model=wrapped_model,
                backend="sklearn",
                model_type="regressor"
            )

            # DiCE Explainerã‚’ä½œæˆ
            exp = Dice(d, m)

            # Få€¤ã¯1-20ã®ç¯„å›² â†’ ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°å¾Œã¯0.05-1.0
            # desired_rangeã‚’ç¾åœ¨ã®Få€¤ã«åŸºã¥ã„ã¦å‹•çš„ã«è¨­å®š
            # ç¾åœ¨ã®Få€¤ã‹ã‚‰20-30%ç¨‹åº¦ã®æ”¹å–„ã‚’ç›®æ¨™ã¨ã™ã‚‹ï¼ˆã‚ˆã‚Šç¾å®Ÿçš„ãªç¯„å›²ï¼‰

            # æ”¹å–„ç›®æ¨™ã‚’è¨ˆç®—ï¼ˆç¾åœ¨å€¤ã®20-40%æ”¹å–„ï¼‰
            improvement_low = max(0.05, current_frustration_scaled * 0.6)   # 40%æ”¹å–„ï¼ˆæœ€å°å€¤ã¯0.05ï¼‰
            improvement_high = max(0.05, current_frustration_scaled * 0.8)  # 20%æ”¹å–„

            # ç¯„å›²ãŒç‹­ã™ãã‚‹å ´åˆã¯æœ€å°å¹…ã‚’ç¢ºä¿
            if improvement_high - improvement_low < 0.1:
                improvement_low = max(0.05, improvement_high - 0.1)

            desired_range = [improvement_low, improvement_high]

            logger.info(f"DiCEå®Ÿè¡Œ: ç¾åœ¨Få€¤(äºˆæ¸¬å€¤)={current_frustration:.2f}(scaled={current_frustration_scaled:.3f}), ç›®æ¨™ç¯„å›²={desired_range} (Få€¤{improvement_low*20:.1f}-{improvement_high*20:.1f}ã«ç›¸å½“)")

            # ç”Ÿä½“æƒ…å ±ã¨æ™‚é–“ç‰¹å¾´ã‚’å›ºå®šã™ã‚‹ãŸã‚ã®permitted_rangeè¨­å®š
            # features_to_varyã§æŒ‡å®šã•ã‚Œã¦ã„ãªã„åˆ—ã¯ã€å…ƒã®å€¤ã‹ã‚‰å¤‰æ›´ã•ã‚Œãªã„ã‚ˆã†ã«åˆ¶ç´„
            permitted_range = {}
            for col in ['SDNN_scaled', 'Lorenz_Area_scaled', 'hour_sin', 'hour_cos']:
                if col in query_dice.columns:
                    val = query_dice[col].iloc[0]
                    # ç”Ÿä½“æƒ…å ±ã¨æ™‚é–“ã¯ç¾åœ¨å€¤Â±0.001ã®ç¯„å›²ã«å›ºå®šï¼ˆå®Ÿè³ªå¤‰æ›´ä¸å¯ï¼‰
                    permitted_range[col] = [val - 0.001, val + 0.001]

            # æ›œæ—¥åˆ—ã‚‚å›ºå®š
            for col in weekday_cols:
                if col in query_dice.columns:
                    val = query_dice[col].iloc[0]
                    permitted_range[col] = [val - 0.001, val + 0.001]

            logger.warning(f"ğŸ”§ DiCE: permitted_rangeè¨­å®š = ç”Ÿä½“æƒ…å ±ã€æ™‚é–“ã€æ›œæ—¥ã‚’å›ºå®š")
            logger.warning(f"ğŸ”§ DiCE: features_to_vary = ['CatSub'] ã®ã¿")

            # ğŸ” DiCEå®Ÿè¡Œå‰ã®æœ€çµ‚ç¢ºèª
            logger.warning(f"ğŸ”ğŸ”ğŸ” DiCEå®Ÿè¡Œå‰ã®æœ€çµ‚ç¢ºèª")
            logger.warning(f"ğŸ” è¨“ç·´ãƒ‡ãƒ¼ã‚¿:")
            logger.warning(f"   - è¡Œæ•°: {len(df_dice_train)}")
            logger.warning(f"   - CatSubãƒ¦ãƒ‹ãƒ¼ã‚¯å€¤æ•°: {df_dice_train['CatSub'].nunique()}")
            logger.warning(f"   - CatSubãƒ¦ãƒ‹ãƒ¼ã‚¯å€¤: {df_dice_train['CatSub'].unique().tolist()}")
            logger.warning(f"   - NASA_F_scaled ç¯„å›²: [{df_dice_train['NASA_F_scaled'].min():.3f}, {df_dice_train['NASA_F_scaled'].max():.3f}]")
            logger.warning(f"   - NASA_F_scaled å¹³å‡: {df_dice_train['NASA_F_scaled'].mean():.3f}")
            logger.warning(f"ğŸ” ã‚¯ã‚¨ãƒª:")
            logger.warning(f"   - CatSub: {query_dice['CatSub'].iloc[0]}")
            logger.warning(f"   - ç¾åœ¨ã®Få€¤(äºˆæ¸¬): {current_frustration:.2f} (scaled={current_frustration_scaled:.3f})")
            logger.warning(f"ğŸ” ç›®æ¨™:")
            logger.warning(f"   - desired_range: {desired_range}")
            logger.warning(f"   - Få€¤æ›ç®—: [{desired_range[0]*20:.2f}, {desired_range[1]*20:.2f}]")
            logger.warning(f"   - æ”¹å–„å¹…: {(current_frustration_scaled - desired_range[1])*20:.2f} ã€œ {(current_frustration_scaled - desired_range[0])*20:.2f} ç‚¹")

            # DiCEã§åå®Ÿä»®æƒ³ä¾‹ã‚’ç”Ÿæˆï¼ˆCatSubåˆ—ã‚’ä½¿ç”¨ã—ãŸquery_diceã‚’ä½¿ç”¨ï¼‰
            logger.warning(f"ğŸš€ğŸš€ğŸš€ DiCE.generate_counterfactuals()ã‚’é–‹å§‹ã—ã¾ã™...")
            logger.warning(f"ğŸš€ ModelWrapperå‘¼ã³å‡ºã—å›æ•°ï¼ˆé–‹å§‹å‰ï¼‰: {wrapped_model.call_count}")

            dice_exp = exp.generate_counterfactuals(
                query_instances=query_dice,
                total_CFs=5,
                desired_range=desired_range,  # å‹•çš„ç¯„å›²: ç¾åœ¨å€¤ã‹ã‚‰20-40%æ”¹å–„ã‚’ç›®æ¨™
                features_to_vary=['CatSub'],  # CatSubã®ã¿å¤‰æ›´
                permitted_range=permitted_range  # ç”Ÿä½“æƒ…å ±ãƒ»æ™‚é–“ãƒ»æ›œæ—¥ã‚’å›ºå®š
            )

            logger.warning(f"ğŸš€ğŸš€ğŸš€ DiCE.generate_counterfactuals()ãŒå®Œäº†ã—ã¾ã—ãŸ")
            logger.warning(f"ğŸš€ ModelWrapperå‘¼ã³å‡ºã—å›æ•°ï¼ˆå®Œäº†å¾Œï¼‰: {wrapped_model.call_count}")

            # çµæœã‚’å–å¾—
            logger.warning(f"ğŸ”ğŸ”ğŸ” DiCEç”Ÿæˆçµæœã‚’å–å¾—ã—ã¾ã™")
            logger.warning(f"ğŸ” dice_exp.cf_examples_list ã®é•·ã•: {len(dice_exp.cf_examples_list)}")

            if len(dice_exp.cf_examples_list) == 0:
                logger.error("âŒ DiCE: cf_examples_listãŒç©ºã§ã™ï¼åå®Ÿä»®æƒ³ä¾‹ãŒ1ã¤ã‚‚ç”Ÿæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
                logger.error(f"   - ç¾åœ¨ã®Få€¤: {current_frustration:.2f} (scaled={current_frustration_scaled:.3f})")
                logger.error(f"   - ç›®æ¨™ç¯„å›²: {desired_range}")
                logger.error(f"   - è¨“ç·´ãƒ‡ãƒ¼ã‚¿æ•°: {len(df_dice_train)}")
                logger.error(f"   - CatSubãƒ¦ãƒ‹ãƒ¼ã‚¯æ•°: {df_dice_train['CatSub'].nunique()}")
                return None

            cf_df = dice_exp.cf_examples_list[0].final_cfs_df
            logger.warning(f"ğŸ” cf_df is None: {cf_df is None}")
            logger.warning(f"ğŸ” cf_df is empty: {cf_df.empty if cf_df is not None else 'N/A'}")

            if cf_df is None:
                logger.error("âŒ DiCE: final_cfs_dfãŒNoneã§ã™ï¼")
                return None

            if cf_df.empty:
                logger.error("âŒ DiCE: final_cfs_dfãŒç©ºã§ã™ï¼åå®Ÿä»®æƒ³ä¾‹ã‚’ç”Ÿæˆã§ãã¾ã›ã‚“ã§ã—ãŸ")
                logger.error(f"   - ç¾åœ¨ã®Få€¤: {current_frustration:.2f} (scaled={current_frustration_scaled:.3f})")
                logger.error(f"   - ç›®æ¨™ç¯„å›²: {desired_range} (Få€¤{desired_range[0]*20:.1f}-{desired_range[1]*20:.1f})")
                logger.error(f"   - åˆ¶ç´„æ¡ä»¶ãŒå³ã—ã™ãã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™")
                return None

            # ãƒ‡ãƒãƒƒã‚°: cf_dfã®åˆ—ã‚’ç¢ºèª
            logger.warning(f"ğŸ” DiCE cf_df ã®åˆ—: {cf_df.columns.tolist()}")
            logger.warning(f"ğŸ” DiCE cf_df ã®è¡Œæ•°: {len(cf_df)}")
            if 'NASA_F_scaled' in cf_df.columns:
                logger.warning(f"âš ï¸  DiCEãŒè¿”ã—ãŸNASA_F_scaled: {cf_df['NASA_F_scaled'].tolist()}")
            else:
                logger.warning(f"âŒ NASA_F_scaledåˆ—ãŒå­˜åœ¨ã—ã¾ã›ã‚“ï¼")
                logger.warning(f"   åˆ©ç”¨å¯èƒ½ãªåˆ—: {cf_df.columns.tolist()}")

            # DiCEãŒè¿”ã—ãŸNASA_F_scaledã¯ä¿¡é ¼ã§ããªã„ãŸã‚ã€ModelWrapperã§æ˜ç¤ºçš„ã«äºˆæ¸¬ã—ç›´ã™
            logger.warning(f"ğŸ”§ ModelWrapperã§æ˜ç¤ºçš„ã«NASA_F_scaledã‚’äºˆæ¸¬ã—ç›´ã—ã¾ã™")

            # ğŸ” DiCEãŒç”Ÿæˆã—ãŸCatSubã®å€¤ã‚’è©³ç´°ã«ç¢ºèª
            logger.warning(f"ğŸ”ğŸ”ğŸ” DiCEç”Ÿæˆå¾Œã®CatSubè©³ç´°ãƒã‚§ãƒƒã‚¯é–‹å§‹")
            logger.warning(f"ğŸ” cf_df['CatSub']ã®dtype: {cf_df['CatSub'].dtype}")
            logger.warning(f"ğŸ” cf_df['CatSub']ã®å€¤: {cf_df['CatSub'].tolist()}")
            logger.warning(f"ğŸ” cf_df['CatSub']ã®å‹: {[type(x) for x in cf_df['CatSub'].tolist()]}")

            # ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å‹ã®å ´åˆã€ã‚«ãƒ†ã‚´ãƒªåã«å¤‰æ›
            if pd.api.types.is_categorical_dtype(cf_df['CatSub']):
                logger.warning(f"ğŸ” CatSubãŒã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å‹ã§ã™ï¼ã‚«ãƒ†ã‚´ãƒªåã«å¤‰æ›ã—ã¾ã™")
                logger.warning(f"ğŸ” ã‚«ãƒ†ã‚´ãƒªã‚³ãƒ¼ãƒ‰: {cf_df['CatSub'].cat.codes.tolist()}")
                logger.warning(f"ğŸ” ã‚«ãƒ†ã‚´ãƒªä¸€è¦§: {cf_df['CatSub'].cat.categories.tolist()}")
                # ã‚«ãƒ†ã‚´ãƒªã‚³ãƒ¼ãƒ‰ã‚’ã‚«ãƒ†ã‚´ãƒªåã«å¤‰æ›
                cf_df['CatSub'] = cf_df['CatSub'].astype(str)
                logger.warning(f"ğŸ” å¤‰æ›å¾Œã®CatSub: {cf_df['CatSub'].tolist()}")

            # cf_dfã‹ã‚‰NASA_F_scaledåˆ—ã‚’å‰Šé™¤
            cf_features_only = cf_df.drop('NASA_F_scaled', axis=1, errors='ignore').copy()

            # ModelWrapperã§äºˆæ¸¬
            logger.warning(f"ğŸ”§ ModelWrapper.predict()ã‚’å‘¼ã³å‡ºã—ã¾ã™...")
            logger.warning(f"ğŸ”§ äºˆæ¸¬ã«ä½¿ç”¨ã™ã‚‹CatSub: {cf_features_only['CatSub'].tolist()}")
            predicted_f_values = wrapped_model.predict(cf_features_only)
            logger.warning(f"ğŸ”§ ModelWrapperã®äºˆæ¸¬çµæœ: {predicted_f_values.tolist()}")

            # äºˆæ¸¬çµæœã§ä¸Šæ›¸ã
            cf_df['NASA_F_scaled'] = predicted_f_values
            logger.warning(f"âœ… ä¸Šæ›¸ãå¾Œã®NASA_F_scaled: {cf_df['NASA_F_scaled'].tolist()}")

            # ğŸ” å„å€™è£œã®CatSubã¨Få€¤ã®å¯¾å¿œã‚’ç¢ºèª
            logger.warning(f"ğŸ”ğŸ”ğŸ” å„å€™è£œã®æ´»å‹•ã¨Få€¤ã®å¯¾å¿œç¢ºèª:")
            for i, (idx, cf_row) in enumerate(cf_df.iterrows()):
                cf_activity = cf_row.get('CatSub')
                cf_f = cf_row.get('NASA_F_scaled')
                logger.warning(f"ğŸ”   å€™è£œ{i+1}: CatSub='{cf_activity}' â†’ F_scaled={cf_f:.4f} (Få€¤={cf_f*20:.2f})")

            # ãƒ‡ãƒãƒƒã‚°: å„å€™è£œã®æ´»å‹•ã‚«ãƒ†ã‚´ãƒªã¨ç”Ÿä½“æƒ…å ±ã‚’ç¢ºèª
            logger.warning(f"ğŸ” DiCE cf_df ã®æ´»å‹•ã‚«ãƒ†ã‚´ãƒªã¨ç”Ÿä½“æƒ…å ±:")
            for i, (idx, cf_row) in enumerate(cf_df.iterrows()):
                activity_name = cf_row.get('CatSub', 'N/A')
                sdnn = cf_row.get('SDNN_scaled', 'N/A')
                lorenz = cf_row.get('Lorenz_Area_scaled', 'N/A')
                f_scaled = cf_row.get('NASA_F_scaled', 'N/A')
                # ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆæŒ‡å®šå­ã‚’æ¡ä»¶å¼ã®å¤–ã§é©ç”¨
                sdnn_str = f"{sdnn:.4f}" if isinstance(sdnn, float) else str(sdnn)
                lorenz_str = f"{lorenz:.4f}" if isinstance(lorenz, float) else str(lorenz)
                f_scaled_str = f"{f_scaled:.4f}" if isinstance(f_scaled, float) else str(f_scaled)
                logger.warning(f"   å€™è£œ{i+1}: {activity_name}, SDNN={sdnn_str}, Lorenz={lorenz_str}, F_scaled={f_scaled_str}")

            # å…ƒã®æ´»å‹•ã‚«ãƒ†ã‚´ãƒªã‚’ç‰¹å®š
            original_activity_name = activity.get('CatSub', 'unknown')

            # å…¨ã¦ã®åå®Ÿä»®æƒ³ä¾‹ã‚’è©•ä¾¡ã—ã€æœ€è‰¯ã®æ”¹å–„æ¡ˆã‚’é¸æŠ
            best_result = None
            best_improvement = 0

            for idx, cf_row in cf_df.iterrows():
                # åå®Ÿä»®æƒ³ä¾‹ã®æ´»å‹•ã‚«ãƒ†ã‚´ãƒªã‚’å–å¾—ï¼ˆCatSubåˆ—ã‹ã‚‰ç›´æ¥å–å¾—ï¼‰
                suggested_activity_name = cf_row.get('CatSub', 'unknown')

                # æ´»å‹•ãŒå¤‰ã‚ã£ã¦ã„ãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
                if suggested_activity_name == original_activity_name:
                    logger.warning(f"   å€™è£œ{idx}: æ´»å‹•ãŒå…ƒã¨åŒã˜ï¼ˆ{suggested_activity_name}ï¼‰ã®ã§ã‚¹ã‚­ãƒƒãƒ—")
                    continue

                # æ”¹å–„åŠ¹æœã‚’è¨ˆç®—
                alternative_frustration_scaled = cf_row.get('NASA_F_scaled', current_frustration_scaled)
                alternative_frustration = alternative_frustration_scaled * 20.0
                improvement = current_frustration - alternative_frustration

                # æ”¹å–„ãŒè¦‹ã‚‰ã‚Œã€ã‹ã¤æœ€è‰¯ã®çµæœã®å ´åˆã«æ¡ç”¨
                # æœ€ä½æ”¹å–„é–¾å€¤ã‚’ç¾åœ¨ã®Få€¤ã«å¿œã˜ã¦èª¿æ•´ï¼ˆé«˜Få€¤ã»ã©å°ã•ã„æ”¹å–„ã§ã‚‚è¨±å®¹ï¼‰
                # Få€¤ãŒé«˜ã„(15ä»¥ä¸Š)å ´åˆ: 0.3ç‚¹ä»¥ä¸Šã€ä¸­ç¨‹åº¦(8-15)ã®å ´åˆ: 0.5ç‚¹ä»¥ä¸Šã€ä½ã„å ´åˆ(8æœªæº€): 1.0ç‚¹ä»¥ä¸Š
                if current_frustration >= 15:
                    min_improvement = 0.3
                elif current_frustration >= 8:
                    min_improvement = 0.5
                else:
                    min_improvement = 1.0

                if improvement > min_improvement and improvement > best_improvement:
                    best_improvement = improvement
                    best_result = {
                        'original_activity': original_activity_name,
                        'suggested_activity': suggested_activity_name,
                        'original_frustration': current_frustration,
                        'predicted_frustration': alternative_frustration,
                        'improvement': improvement,
                        'confidence': min(0.9, 0.6 + 0.3 * (improvement / 6))
                    }

            if best_result:
                logger.warning(f"âœ… DiCEå€‹åˆ¥å‡¦ç†æˆåŠŸ: {best_result['original_activity']} â†’ {best_result['suggested_activity']} (æ”¹å–„: {best_improvement:.2f}ç‚¹)")
                return best_result
            else:
                # ã‚ˆã‚Šè©³ç´°ãªãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’è¿½åŠ 
                logger.warning(f"DiCE: æœ‰æ„ãªæ”¹å–„æ¡ˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
                logger.warning(f"  - å…ƒã®æ´»å‹•: {original_activity_name}")
                logger.warning(f"  - ç¾åœ¨Få€¤(äºˆæ¸¬å€¤): {current_frustration:.2f} (scaled={current_frustration_scaled:.3f})")
                logger.warning(f"  - ç›®æ¨™ç¯„å›²: {desired_range} (Få€¤{desired_range[0]*20:.1f}-{desired_range[1]*20:.1f})")
                if cf_df is not None and not cf_df.empty:
                    logger.warning(f"  - DiCEãŒç”Ÿæˆã—ãŸå€™è£œæ•°: {len(cf_df)}ä»¶")
                    # å€™è£œã®è©³ç´°ã‚’ãƒ­ã‚°å‡ºåŠ›
                    for i, (idx, cf_row) in enumerate(cf_df.iterrows()):
                        suggested_act = cf_row.get('CatSub', 'unknown')
                        alt_f_scaled = cf_row.get('NASA_F_scaled', 0)
                        alt_f = alt_f_scaled * 20.0
                        imp = current_frustration - alt_f
                        logger.warning(f"    å€™è£œ{i+1}: {suggested_act}, Få€¤={alt_f:.2f}, æ”¹å–„={imp:.2f}ç‚¹")
                return None

        except Exception as e:
            logger.error(f"âŒ DiCEå€‹åˆ¥å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
            logger.warning(f"âŒ DiCEå€‹åˆ¥å‡¦ç†ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {str(e)[:200]}")
            return None

    def generate_hourly_alternatives(self, activities_data: pd.DataFrame,
                                   predictor, target_date: datetime = None, callback=None) -> dict:
        """
        1æ—¥ã®çµ‚ã‚ã‚Šã«æ™‚é–“å˜ä½ã§DiCEæ”¹å–„ææ¡ˆã‚’ç”Ÿæˆ

        Args:
            callback: DiCEçµæœã‚’1ä»¶ç”Ÿæˆã™ã‚‹ãŸã³ã«å‘¼ã³å‡ºã•ã‚Œã‚‹é–¢æ•°
        """
        try:
            if target_date is None:
                target_date = datetime.now().date()

            if activities_data.empty:
                logger.warning("æ™‚é–“åˆ¥DiCEææ¡ˆ: æ´»å‹•ãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™")
                return self._get_error_hourly_schedule("æ´»å‹•ãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™")

            # æŒ‡å®šæ—¥ã®ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
            logger.warning(f"ğŸ” å¯¾è±¡æ—¥ {target_date} ã®ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºä¸­...")
            logger.warning(f"ğŸ” å…¨æ´»å‹•ãƒ‡ãƒ¼ã‚¿ã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ç¯„å›²: {activities_data['Timestamp'].min()} - {activities_data['Timestamp'].max()}")

            day_data = activities_data[
                activities_data['Timestamp'].dt.date == target_date
            ].copy()

            logger.warning(f"ğŸ” æŠ½å‡ºçµæœ: {len(day_data)}ä»¶ã®ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ")

            if day_data.empty:
                logger.error(f"âŒ æ™‚é–“åˆ¥DiCEææ¡ˆ: {target_date}ã®ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                logger.error(f"   activities_dataå…¨ä½“ã®ä»¶æ•°: {len(activities_data)}")
                logger.error(f"   Timestampã‚«ãƒ©ãƒ ã®å‹: {activities_data['Timestamp'].dtype}")
                return self._get_error_hourly_schedule(f"{target_date}ã®ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

            # æ™‚é–“åˆ¥ã®æ”¹å–„ææ¡ˆã‚’ç”Ÿæˆ
            hourly_schedule = []
            total_improvement = 0

            logger.warning(f"ğŸ”„ 24æ™‚é–“åˆ†ã®DiCEææ¡ˆã‚’ç”Ÿæˆé–‹å§‹ï¼ˆå¯¾è±¡æ—¥ã«æ´»å‹•ãŒã‚ã‚‹æ™‚é–“å¸¯ã®ã¿å‡¦ç†ï¼‰")
            activities_processed = 0

            for hour in range(24):
                hour_start = datetime.combine(target_date, datetime.min.time()) + timedelta(hours=hour)
                hour_end = hour_start + timedelta(hours=1)

                # ã“ã®æ™‚é–“å¸¯ã®æ´»å‹•ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
                hour_activities = day_data[
                    (day_data['Timestamp'] >= hour_start) &
                    (day_data['Timestamp'] < hour_end)
                ]

                if not hour_activities.empty:
                    logger.warning(f"  ğŸ” {hour}æ™‚å°: æ´»å‹•ã‚ã‚Šã€DiCEå‡¦ç†é–‹å§‹...")
                    activities_processed += 1
                    original_activity = hour_activities.iloc[0]
                    idx = activities_data.index[activities_data['Timestamp'] == original_activity['Timestamp']]

                    if len(idx) > 0:
                        # DiCEã‚’ä½¿ã£ãŸä»£æ›¿æ´»å‹•ã®ææ¡ˆ
                        import time
                        start_time = time.time()
                        result = self._generate_dice_counterfactual_simple(
                            activities_data, idx[0], original_activity, predictor
                        )
                        elapsed = time.time() - start_time

                        if result:
                            # ã€é‡è¦ã€‘å®Ÿéš›ã®Timestampã‹ã‚‰æ™‚åˆ»ã‚’å–å¾—ï¼ˆHourly Logã¨ã®ä¸€è‡´ã®ãŸã‚ï¼‰
                            actual_time = original_activity['Timestamp'].strftime('%H:%M')
                            dice_result = {
                                'hour': hour,
                                'time': actual_time,  # å®Ÿéš›ã®Timestamp (ä¾‹: "14:30")
                                'time_range': f"{hour:02d}:00-{hour+1:02d}:00",
                                'original_activity': result['original_activity'],
                                'suggested_activity': result['suggested_activity'],
                                'original_frustration': result['original_frustration'],  # ç¾åœ¨ã®Få€¤ï¼ˆäºˆæ¸¬å€¤ï¼‰
                                'predicted_frustration': result['predicted_frustration'],  # æ”¹å–„å¾Œã®Få€¤
                                'improvement': result['improvement'],
                                'confidence': result['confidence']
                            }
                            hourly_schedule.append(dice_result)
                            total_improvement += result['improvement']
                            logger.warning(f"  âœ… {hour}æ™‚å°: {result['original_activity']} â†’ {result['suggested_activity']} (æ”¹å–„: {result['improvement']:.2f}, å‡¦ç†æ™‚é–“: {elapsed:.1f}ç§’)")

                            # ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°ãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚Œã°ã€å³åº§ã«å‘¼ã³å‡ºã™
                            if callback:
                                callback(dice_result)
                        else:
                            logger.warning(f"  âš ï¸ {hour}æ™‚å°: DiCEææ¡ˆãªã—ï¼ˆå‡¦ç†æ™‚é–“: {elapsed:.1f}ç§’ï¼‰")

            logger.warning(f"ğŸ” hourly_scheduleç”Ÿæˆå®Œäº†: {len(hourly_schedule)}ä»¶, total_improvement={total_improvement:.2f}")

            if total_improvement == 0:
                logger.error(f"âŒ æ™‚é–“åˆ¥DiCEææ¡ˆ: æ”¹å–„ææ¡ˆã‚’ç”Ÿæˆã§ãã¾ã›ã‚“ã§ã—ãŸ")
                logger.error(f"   å¯¾è±¡æ—¥ã®ãƒ‡ãƒ¼ã‚¿ä»¶æ•°: {len(day_data)}")
                logger.error(f"   hourly_scheduleã®é•·ã•: {len(hourly_schedule)}")
                return self._get_error_hourly_schedule("æ”¹å–„ææ¡ˆã‚’ç”Ÿæˆã§ãã¾ã›ã‚“ã§ã—ãŸ")

            return {
                'type': 'hourly_dice_schedule',
                'date': target_date.strftime('%Y-%m-%d'),
                'hourly_schedule': hourly_schedule,
                'total_improvement': total_improvement,
                'average_improvement': total_improvement / 24 if hourly_schedule else 0,
                'message': f"ä»Šæ—¥ã“ã®ã‚ˆã†ãªæ´»å‹•ã‚’ã—ã¦ã„ãŸã‚‰ã‚¹ãƒˆãƒ¬ã‚¹ãƒ¬ãƒ™ãƒ«ãŒ{total_improvement:.1f}ç‚¹ä¸‹ãŒã£ã¦ã„ã¾ã—ãŸ",
                'confidence': min(0.9, 0.5 + len(hourly_schedule) * 0.05),
                'summary': f"24æ™‚é–“ä¸­{len(hourly_schedule)}æ™‚é–“ã§æ”¹å–„ã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã—ãŸ"
            }

        except Exception as e:
            logger.error(f"æ™‚é–“åˆ¥DiCEææ¡ˆç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
            return self._get_error_hourly_schedule(str(e))

    def _get_error_explanation(self, error_message: str) -> Dict:
        """ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿæ™‚ã®èª¬æ˜"""
        return {
            'type': 'error',
            'status': 'error',
            'error_message': error_message,
            'confidence': 0.0
        }

    def _get_error_hourly_schedule(self, error_message: str) -> dict:
        """ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿæ™‚ã®æ™‚é–“åˆ¥ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«"""
        return {
            'type': 'error',
            'status': 'error',
            'error_message': error_message,
            'date': datetime.now().strftime('%Y-%m-%d'),
            'hourly_schedule': [],
            'total_improvement': 0,
            'confidence': 0.0
        }
