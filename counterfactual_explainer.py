"""
è¡Œå‹•å˜ä½ã®åå®Ÿä»®æƒ³èª¬æ˜ï¼ˆCounterfactual Explanationsï¼‰æ©Ÿèƒ½
webhooktest.pyã®æˆåŠŸãƒ‘ã‚¿ãƒ¼ãƒ³ã«åŸºã¥ãDiCEå®Ÿè£…
"""

import pandas as pd
import numpy as np
import logging
from typing import Dict, List, Optional
import dice_ml
from dice_ml import Dice
from datetime import datetime, timedelta

from config import Config
from ml_model import KNOWN_ACTIVITIES

logger = logging.getLogger(__name__)

class ActivityCounterfactualExplainer:
    def __init__(self):
        self.config = Config()

    def generate_activity_based_explanation(self,
                                          df_enhanced: pd.DataFrame,
                                          predictor,
                                          target_timestamp: datetime = None,
                                          lookback_hours: int = 24) -> Dict:
        """
        DiCEãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ä½¿ç”¨ã—ãŸåå®Ÿä»®æƒ³èª¬æ˜ç”Ÿæˆ (1æ—¥åˆ†ã®ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦å®Ÿè¡Œ)
        21:00ãªã©ã®å®šæ™‚å®Ÿè¡Œã‚’æƒ³å®šã—ã€ãã®æ—¥1æ—¥ã®å…¨æ´»å‹•ã«å¯¾ã—ã¦DiCEææ¡ˆã‚’ç”Ÿæˆ
        """
        try:
            if target_timestamp is None:
                target_timestamp = datetime.now()

            if df_enhanced.empty:
                logger.warning("DiCEèª¬æ˜ç”Ÿæˆ: ãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™")
                return self._get_error_explanation("ãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™")

            if predictor is None or predictor.model is None:
                logger.warning("ãƒ¢ãƒ‡ãƒ«ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“")
                return self._get_error_explanation("ãƒ¢ãƒ‡ãƒ«ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“")

            # ãã®æ—¥1æ—¥åˆ†ã®ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦DiCEã‚’å®Ÿè¡Œ
            target_date = target_timestamp.date()
            logger.info(f"DiCE: {target_date}ã®1æ—¥åˆ†ã®ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦DiCEåˆ†æã‚’å®Ÿè¡Œã—ã¾ã™")

            # generate_hourly_alternativesã‚’ä½¿ç”¨ã—ã¦1æ—¥åˆ†ã®DiCEææ¡ˆã‚’ç”Ÿæˆ
            daily_result = self.generate_hourly_alternatives(df_enhanced, predictor, target_date)

            if daily_result.get('type') == 'hourly_dice_schedule' and daily_result.get('hourly_schedule'):
                # æ™‚é–“åˆ¥ã®ææ¡ˆã‚’ãƒ•ãƒ©ãƒƒãƒˆãªå½¢å¼ã«å¤‰æ›
                timeline = []
                for item in daily_result['hourly_schedule']:
                    # æ™‚åˆ»æƒ…å ±ã‚’è¿½åŠ 
                    hour = item['hour']
                    timestamp = datetime.combine(target_date, datetime.min.time()) + timedelta(hours=hour)
                    timeline.append({
                        'hour': hour,
                        'timestamp': timestamp.isoformat(),
                        'original_timestamp': timestamp.isoformat(),
                        'time_range': item['time_range'],
                        'original_activity': item['original_activity'],
                        'suggested_activity': item['suggested_activity'],
                        'frustration_reduction': item['improvement'],
                        'improvement': item['improvement'],
                        'confidence': item['confidence']
                    })

                return {
                    'type': 'daily_dice_analysis',
                    'date': target_date.strftime('%Y-%m-%d'),
                    'timeline': timeline,
                    'total_improvement': daily_result['total_improvement'],
                    'average_improvement': daily_result.get('average_improvement', 0),
                    'schedule_items': len(timeline),
                    'message': daily_result.get('message', ''),
                    'summary': daily_result.get('summary', ''),
                    'confidence': daily_result.get('confidence', 0.5)
                }
            else:
                return self._get_error_explanation(daily_result.get('error_message', 'DiCEç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ'))

        except Exception as e:
            logger.error(f"åå®Ÿä»®æƒ³èª¬æ˜ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
            return self._get_error_explanation(str(e))

    def _generate_dice_counterfactual_simple(self,
                                             df_enhanced: pd.DataFrame,
                                             activity_idx: int,
                                             activity: pd.Series,
                                             predictor) -> Optional[Dict]:
        """
        DiCEã‚’ä½¿ç”¨ã—ã¦åå®Ÿä»®æƒ³ä¾‹ã‚’ç”Ÿæˆ (webhooktest.pyå½¢å¼ã®ã‚·ãƒ³ãƒ—ãƒ«ãªå®Ÿè£…)
        """
        try:
            # ===== ãƒ‡ãƒãƒƒã‚°é–‹å§‹: å€¤ã®å‡ºæ‰€ã‚’è¿½è·¡ =====
            logger.info(f"DiCE: activity_idx = {activity_idx}")
            logger.info(f"DiCE: å¯¾è±¡è¡Œã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ = {df_enhanced.index[activity_idx]}")

            # å¯¾è±¡è¡Œã®å…¨ãƒ‡ãƒ¼ã‚¿ã‚’ç¢ºèª
            target_row = df_enhanced.iloc[activity_idx]
            logger.info(f"DiCE: å¯¾è±¡è¡Œã®CatSub = {target_row.get('CatSub', 'N/A')}")
            logger.info(f"DiCE: å¯¾è±¡è¡Œã®Timestamp = {target_row.get('Timestamp', 'N/A')}")

            # NASA_Få€¤ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèªï¼ˆå®Ÿæ¸¬å€¤ï¼‰
            if 'NASA_F' in target_row.index:
                logger.info(f"DiCE: å¯¾è±¡è¡Œã®NASA_Fï¼ˆå®Ÿæ¸¬å€¤ï¼‰= {target_row['NASA_F']}")
            else:
                logger.info("DiCE: å¯¾è±¡è¡Œã«NASA_Fåˆ—ã¯å­˜åœ¨ã—ã¾ã›ã‚“")

            if 'NASA_F_scaled' in target_row.index:
                logger.info(f"DiCE: å¯¾è±¡è¡Œã®NASA_F_scaledï¼ˆå®Ÿæ¸¬å€¤ã‚¹ã‚±ãƒ¼ãƒ«æ¸ˆã¿ï¼‰= {target_row['NASA_F_scaled']}")
            else:
                logger.info("DiCE: å¯¾è±¡è¡Œã«NASA_F_scaledåˆ—ã¯å­˜åœ¨ã—ã¾ã›ã‚“")

            # ç¾åœ¨ã®æ´»å‹•ã®ãƒ•ãƒ©ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å€¤ã‚’ãƒ¢ãƒ‡ãƒ«ã§äºˆæ¸¬
            # ã‚¯ã‚¨ãƒªã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’æº–å‚™
            query_features = df_enhanced.iloc[[activity_idx]][predictor.feature_columns]

            # ãƒ‡ãƒãƒƒã‚°: query_featuresã®å†…å®¹ã‚’ç¢ºèª
            logger.info(f"DiCE: query_features shape: {query_features.shape}")
            logger.info(f"DiCE: query_features columns: {query_features.columns.tolist()}")
            logger.info(f"DiCE: query_features ã®ä¸»è¦ãªå€¤:")
            for col in ['SDNN_scaled', 'Lorenz_Area_scaled', 'hour', 'weekday']:
                if col in query_features.columns:
                    logger.info(f"  - {col} = {query_features[col].iloc[0]}")

            # ã‚¢ã‚¯ãƒ†ã‚£ãƒ“ãƒ†ã‚£ã‚«ãƒ†ã‚´ãƒªã‚’ç¢ºèª
            activity_cols = [col for col in query_features.columns if col.startswith('activity_')]
            active_activity = None
            for col in activity_cols:
                if query_features[col].iloc[0] == 1:
                    active_activity = col.replace('activity_', '')
                    break
            logger.info(f"DiCE: é¸æŠã•ã‚Œã¦ã„ã‚‹æ´»å‹•ã‚«ãƒ†ã‚´ãƒª = {active_activity if active_activity else 'ãªã—'}")

            # é‡è¦ãªç”Ÿä½“æƒ…å ±ã‚«ãƒ©ãƒ ã®NaNãƒã‚§ãƒƒã‚¯
            critical_cols = ['SDNN_scaled', 'Lorenz_Area_scaled']
            for col in critical_cols:
                if col in query_features.columns:
                    val = query_features[col].iloc[0]
                    if pd.isna(val):
                        logger.warning(f"DiCE: {col}ãŒNaNã§ã™ã€‚å±¥æ­´ãƒ‡ãƒ¼ã‚¿ã®å¹³å‡å€¤ã§è£œå®Œã—ã¾ã™")
                        # å±¥æ­´ãƒ‡ãƒ¼ã‚¿ã®å¹³å‡å€¤ã§è£œå®Œ
                        mean_val = df_enhanced[col].dropna().mean()
                        if pd.notna(mean_val):
                            query_features.loc[query_features.index[0], col] = mean_val
                            logger.info(f"DiCE: {col}ã‚’å¹³å‡å€¤ {mean_val:.4f} ã§è£œå®Œã—ã¾ã—ãŸ")
                        else:
                            logger.error(f"DiCE: {col}ã®å¹³å‡å€¤ã‚‚è¨ˆç®—ã§ãã¾ã›ã‚“")
                            return None

            # ãƒ¢ãƒ‡ãƒ«ã§äºˆæ¸¬ï¼ˆã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°å¾Œã®å€¤: 0-1ï¼‰
            logger.info("DiCE: ===== ãƒ¢ãƒ‡ãƒ«äºˆæ¸¬ã‚’å®Ÿè¡Œã—ã¾ã™ =====")
            logger.info(f"DiCE: predictor.model ã®ã‚¿ã‚¤ãƒ— = {type(predictor.model)}")

            current_frustration_scaled = predictor.model.predict(query_features)[0]

            logger.info(f"DiCE: ãƒ¢ãƒ‡ãƒ«äºˆæ¸¬çµæœï¼ˆã‚¹ã‚±ãƒ¼ãƒ«æ¸ˆã¿ 0-1ï¼‰= {current_frustration_scaled}")

            if np.isnan(current_frustration_scaled) or np.isinf(current_frustration_scaled):
                logger.warning(f"äºˆæ¸¬å€¤ãŒä¸æ­£ã§ã™ (NaN/Inf): {current_frustration_scaled}")
                logger.warning(f"query_featureså€¤: {query_features.iloc[0].to_dict()}")
                return None

            # ã‚¹ã‚±ãƒ¼ãƒ«æˆ»ã—ï¼ˆ0-1 â†’ 1-20ï¼‰
            current_frustration = current_frustration_scaled * 20.0

            logger.info(f"DiCE: ã‚¹ã‚±ãƒ¼ãƒ«å¤‰æ›ï¼ˆÃ—20ï¼‰å¾Œã®Få€¤ = {current_frustration}")
            logger.info(f"DiCE: ===== ãƒ¢ãƒ‡ãƒ«äºˆæ¸¬å®Œäº† =====")

            # è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™: NaNå€¤ã‚’é™¤å¤–
            required_cols = ['SDNN_scaled', 'Lorenz_Area_scaled', 'NASA_F_scaled']
            df_train = df_enhanced.dropna(subset=required_cols).copy()

            if len(df_train) < 20:
                logger.warning(f"è¨“ç·´ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ï¼ˆ{len(df_train)}ä»¶ï¼‰")
                return None

            # ç‰¹å¾´é‡ã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ
            X_train = df_train[predictor.feature_columns]
            y_train = df_train['NASA_F_scaled']

            # DiCEãƒ‡ãƒ¼ã‚¿ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½œæˆ
            # æ´»å‹•ã‚«ãƒ†ã‚´ãƒªåˆ—ã®ã¿ã‚’å¤‰æ›´å¯èƒ½ã«ã™ã‚‹
            activity_cols = [col for col in predictor.feature_columns if col.startswith('activity_')]

            # webhooktest.pyå½¢å¼: ç”Ÿä½“æƒ…å ±ã¨æ™‚é–“ç‰¹å¾´é‡ã‚’continuousã«æŒ‡å®š
            # æ›œæ—¥ã¯categoricalã¨ã—ã¦æ‰±ã†ï¼ˆcontinuous_featuresã«å«ã‚ãªã„ï¼‰
            continuous_features = ['SDNN_scaled', 'Lorenz_Area_scaled', 'hour_sin', 'hour_cos']

            # ãƒ‡ãƒãƒƒã‚°: features_to_varyã®å†…å®¹ã‚’ç¢ºèª
            logger.warning(f"ğŸ”§ DiCE: predictor.feature_columnsæ•° = {len(predictor.feature_columns)}")
            logger.warning(f"ğŸ”§ DiCE: activity_colsï¼ˆå¤‰æ›´å¯èƒ½ãªåˆ—ï¼‰æ•° = {len(activity_cols)}")
            logger.warning(f"ğŸ”§ DiCE: continuous_featuresï¼ˆå›ºå®šåˆ—ï¼‰ = {continuous_features}")
            if len(activity_cols) <= 10:
                logger.warning(f"ğŸ”§ DiCE: activity_colsï¼ˆå…¨ã¦ï¼‰ = {activity_cols}")
            else:
                logger.warning(f"ğŸ”§ DiCE: activity_colsæ•°ãŒå¤šã„ãŸã‚ã€æœ€åˆã®10å€‹ã®ã¿è¡¨ç¤º = {activity_cols[:10]}")

            if len(activity_cols) == 0:
                logger.error("DiCE: activity_colsãŒç©ºã§ã™ï¼æ´»å‹•ã‚«ãƒ†ã‚´ãƒªåˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                return None

            dice_data = pd.concat([X_train, y_train], axis=1)
            d = dice_ml.Data(
                dataframe=dice_data,
                continuous_features=continuous_features,
                outcome_name='NASA_F_scaled'
            )

            # DiCEãƒ¢ãƒ‡ãƒ«ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½œæˆ
            m = dice_ml.Model(
                model=predictor.model,
                backend="sklearn",
                model_type="regressor"
            )

            # DiCE Explainerã‚’ä½œæˆ
            exp = Dice(d, m)

            # Få€¤ã¯1-20ã®ç¯„å›² â†’ ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°å¾Œã¯0.05-1.0
            # desired_rangeã‚’ç¾åœ¨ã®Få€¤ã«åŸºã¥ã„ã¦å‹•çš„ã«è¨­å®š
            # ç¾åœ¨ã®Få€¤ã‹ã‚‰20-30%ç¨‹åº¦ã®æ”¹å–„ã‚’ç›®æ¨™ã¨ã™ã‚‹ï¼ˆã‚ˆã‚Šç¾å®Ÿçš„ãªç¯„å›²ï¼‰

            # æ”¹å–„ç›®æ¨™ã‚’è¨ˆç®—ï¼ˆç¾åœ¨å€¤ã®20-40%æ”¹å–„ï¼‰
            improvement_low = max(0.05, current_frustration_scaled * 0.6)   # 40%æ”¹å–„ï¼ˆæœ€å°å€¤ã¯0.05ï¼‰
            improvement_high = max(0.05, current_frustration_scaled * 0.8)  # 20%æ”¹å–„

            # ç¯„å›²ãŒç‹­ã™ãã‚‹å ´åˆã¯æœ€å°å¹…ã‚’ç¢ºä¿
            if improvement_high - improvement_low < 0.1:
                improvement_low = max(0.05, improvement_high - 0.1)

            desired_range = [improvement_low, improvement_high]

            logger.info(f"DiCEå®Ÿè¡Œ: ç¾åœ¨Få€¤(äºˆæ¸¬å€¤)={current_frustration:.2f}(scaled={current_frustration_scaled:.3f}), ç›®æ¨™ç¯„å›²={desired_range} (Få€¤{improvement_low*20:.1f}-{improvement_high*20:.1f}ã«ç›¸å½“)")

            # ç”Ÿä½“æƒ…å ±ã¨æ™‚é–“ç‰¹å¾´ã‚’å›ºå®šã™ã‚‹ãŸã‚ã®permitted_rangeè¨­å®š
            # features_to_varyã§æŒ‡å®šã•ã‚Œã¦ã„ãªã„åˆ—ã¯ã€å…ƒã®å€¤ã‹ã‚‰å¤‰æ›´ã•ã‚Œãªã„ã‚ˆã†ã«åˆ¶ç´„
            permitted_range = {}
            for col in continuous_features:
                if col in query_features.columns:
                    val = query_features[col].iloc[0]
                    # ç”Ÿä½“æƒ…å ±ã¨æ™‚é–“ã¯ç¾åœ¨å€¤Â±0.001ã®ç¯„å›²ã«å›ºå®šï¼ˆå®Ÿè³ªå¤‰æ›´ä¸å¯ï¼‰
                    permitted_range[col] = [val - 0.001, val + 0.001]

            # æ›œæ—¥ã‚‚å›ºå®š
            weekday_cols = [col for col in query_features.columns if col.startswith('weekday_')]
            for col in weekday_cols:
                val = query_features[col].iloc[0]
                permitted_range[col] = [val, val]  # å®Œå…¨å›ºå®š

            logger.warning(f"ğŸ”§ DiCE: permitted_rangeè¨­å®š = ç”Ÿä½“æƒ…å ±ã¨æ™‚é–“ã‚’å›ºå®š")

            # DiCEã§åå®Ÿä»®æƒ³ä¾‹ã‚’ç”Ÿæˆï¼ˆæ—¢ã«å®šç¾©ã—ãŸquery_featuresã‚’ä½¿ç”¨ï¼‰
            dice_exp = exp.generate_counterfactuals(
                query_instances=query_features,
                total_CFs=5,
                desired_range=desired_range,  # å‹•çš„ç¯„å›²: ç¾åœ¨å€¤ã‹ã‚‰20-40%æ”¹å–„ã‚’ç›®æ¨™
                features_to_vary=activity_cols,  # æ´»å‹•ã‚«ãƒ†ã‚´ãƒªã®ã¿å¤‰æ›´
                permitted_range=permitted_range  # ç”Ÿä½“æƒ…å ±ãƒ»æ™‚é–“ã‚’å›ºå®š
            )

            # çµæœã‚’å–å¾—
            cf_df = dice_exp.cf_examples_list[0].final_cfs_df

            if cf_df is None or cf_df.empty:
                logger.warning("DiCEãŒåå®Ÿä»®æƒ³ä¾‹ã‚’ç”Ÿæˆã§ãã¾ã›ã‚“ã§ã—ãŸ")
                return None

            # ãƒ‡ãƒãƒƒã‚°: cf_dfã®åˆ—ã‚’ç¢ºèª
            logger.warning(f"ğŸ” DiCE cf_df ã®åˆ—: {cf_df.columns.tolist()}")
            logger.warning(f"ğŸ” DiCE cf_df ã®è¡Œæ•°: {len(cf_df)}")
            if 'NASA_F_scaled' in cf_df.columns:
                logger.warning(f"âœ… NASA_F_scaledåˆ—ãŒå­˜åœ¨ã—ã¾ã™: {cf_df['NASA_F_scaled'].tolist()}")
            else:
                logger.warning(f"âŒ NASA_F_scaledåˆ—ãŒå­˜åœ¨ã—ã¾ã›ã‚“ï¼")
                logger.warning(f"   åˆ©ç”¨å¯èƒ½ãªåˆ—: {[c for c in cf_df.columns if not c.startswith('activity_')][:10]}")

            # ãƒ‡ãƒãƒƒã‚°: å„å€™è£œã®æ´»å‹•ã‚«ãƒ†ã‚´ãƒªã‚’ç¢ºèª
            logger.warning(f"ğŸ” DiCE cf_df ã®æ´»å‹•ã‚«ãƒ†ã‚´ãƒª:")
            for i, (idx, cf_row) in enumerate(cf_df.iterrows()):
                active_activities = [col.replace('activity_', '') for col in activity_cols if cf_row[col] == 1]
                logger.warning(f"   å€™è£œ{i+1}: {active_activities}")

            # å…ƒã®æ´»å‹•ã‚«ãƒ†ã‚´ãƒªã‚’ç‰¹å®š
            original_activity_name = activity.get('CatSub', 'unknown')

            # å…¨ã¦ã®åå®Ÿä»®æƒ³ä¾‹ã‚’è©•ä¾¡ã—ã€æœ€è‰¯ã®æ”¹å–„æ¡ˆã‚’é¸æŠ
            best_result = None
            best_improvement = 0

            for idx, cf_row in cf_df.iterrows():
                # åå®Ÿä»®æƒ³ä¾‹ã®æ´»å‹•ã‚«ãƒ†ã‚´ãƒªã‚’å–å¾—
                suggested_activity_name = None
                for activity_name in KNOWN_ACTIVITIES:
                    col_name = f'activity_{activity_name}'
                    if col_name in cf_row.index and cf_row[col_name] == 1:
                        suggested_activity_name = activity_name
                        break

                if suggested_activity_name is None:
                    suggested_activity_name = 'unknown'

                # æ´»å‹•ãŒå¤‰ã‚ã£ã¦ã„ãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
                if suggested_activity_name == original_activity_name:
                    continue

                # æ”¹å–„åŠ¹æœã‚’è¨ˆç®—
                alternative_frustration_scaled = cf_row.get('NASA_F_scaled', current_frustration_scaled)
                alternative_frustration = alternative_frustration_scaled * 20.0
                improvement = current_frustration - alternative_frustration

                # æ”¹å–„ãŒè¦‹ã‚‰ã‚Œã€ã‹ã¤æœ€è‰¯ã®çµæœã®å ´åˆã«æ¡ç”¨
                # æœ€ä½æ”¹å–„é–¾å€¤ã‚’ç¾åœ¨ã®Få€¤ã«å¿œã˜ã¦èª¿æ•´ï¼ˆé«˜Få€¤ã»ã©å°ã•ã„æ”¹å–„ã§ã‚‚è¨±å®¹ï¼‰
                # Få€¤ãŒé«˜ã„(15ä»¥ä¸Š)å ´åˆ: 0.3ç‚¹ä»¥ä¸Šã€ä¸­ç¨‹åº¦(8-15)ã®å ´åˆ: 0.5ç‚¹ä»¥ä¸Šã€ä½ã„å ´åˆ(8æœªæº€): 1.0ç‚¹ä»¥ä¸Š
                if current_frustration >= 15:
                    min_improvement = 0.3
                elif current_frustration >= 8:
                    min_improvement = 0.5
                else:
                    min_improvement = 1.0

                if improvement > min_improvement and improvement > best_improvement:
                    best_improvement = improvement
                    best_result = {
                        'original_activity': original_activity_name,
                        'suggested_activity': suggested_activity_name,
                        'original_frustration': current_frustration,
                        'predicted_frustration': alternative_frustration,
                        'improvement': improvement,
                        'confidence': min(0.9, 0.6 + 0.3 * (improvement / 6))
                    }

            if best_result:
                logger.info(f"DiCEæˆåŠŸ: {best_result['original_activity']} â†’ {best_result['suggested_activity']} (æ”¹å–„: {best_improvement:.2f}ç‚¹)")
                return best_result
            else:
                # ã‚ˆã‚Šè©³ç´°ãªãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’è¿½åŠ 
                logger.warning(f"DiCE: æœ‰æ„ãªæ”¹å–„æ¡ˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
                logger.warning(f"  - å…ƒã®æ´»å‹•: {original_activity_name}")
                logger.warning(f"  - ç¾åœ¨Få€¤(äºˆæ¸¬å€¤): {current_frustration:.2f} (scaled={current_frustration_scaled:.3f})")
                logger.warning(f"  - ç›®æ¨™ç¯„å›²: {desired_range} (Få€¤{desired_range[0]*20:.1f}-{desired_range[1]*20:.1f})")
                if cf_df is not None and not cf_df.empty:
                    logger.warning(f"  - DiCEãŒç”Ÿæˆã—ãŸå€™è£œæ•°: {len(cf_df)}ä»¶")
                    # å€™è£œã®è©³ç´°ã‚’ãƒ­ã‚°å‡ºåŠ›
                    for idx, cf_row in cf_df.iterrows():
                        suggested_act = None
                        for act_name in KNOWN_ACTIVITIES:
                            if f'activity_{act_name}' in cf_row.index and cf_row[f'activity_{act_name}'] == 1:
                                suggested_act = act_name
                                break
                        alt_f_scaled = cf_row.get('NASA_F_scaled', 0)
                        alt_f = alt_f_scaled * 20.0
                        imp = current_frustration - alt_f
                        logger.warning(f"    å€™è£œ{idx+1}: {suggested_act}, Få€¤={alt_f:.2f}, æ”¹å–„={imp:.2f}ç‚¹")
                return None

        except Exception as e:
            logger.error(f"DiCEåå®Ÿä»®æƒ³ä¾‹ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
            return None

    def generate_hourly_alternatives(self, activities_data: pd.DataFrame,
                                   predictor, target_date: datetime = None) -> dict:
        """
        1æ—¥ã®çµ‚ã‚ã‚Šã«æ™‚é–“å˜ä½ã§DiCEæ”¹å–„ææ¡ˆã‚’ç”Ÿæˆ
        """
        try:
            if target_date is None:
                target_date = datetime.now().date()

            if activities_data.empty:
                logger.warning("æ™‚é–“åˆ¥DiCEææ¡ˆ: æ´»å‹•ãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™")
                return self._get_error_hourly_schedule("æ´»å‹•ãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™")

            # æŒ‡å®šæ—¥ã®ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
            day_data = activities_data[
                activities_data['Timestamp'].dt.date == target_date
            ].copy()

            if day_data.empty:
                logger.info(f"æ™‚é–“åˆ¥DiCEææ¡ˆ: {target_date}ã®ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                return self._get_error_hourly_schedule(f"{target_date}ã®ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

            # æ™‚é–“åˆ¥ã®æ”¹å–„ææ¡ˆã‚’ç”Ÿæˆ
            hourly_schedule = []
            total_improvement = 0

            for hour in range(24):
                hour_start = datetime.combine(target_date, datetime.min.time()) + timedelta(hours=hour)
                hour_end = hour_start + timedelta(hours=1)

                # ã“ã®æ™‚é–“å¸¯ã®æ´»å‹•ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
                hour_activities = day_data[
                    (day_data['Timestamp'] >= hour_start) &
                    (day_data['Timestamp'] < hour_end)
                ]

                if not hour_activities.empty:
                    original_activity = hour_activities.iloc[0]
                    idx = activities_data.index[activities_data['Timestamp'] == original_activity['Timestamp']]

                    if len(idx) > 0:
                        # DiCEã‚’ä½¿ã£ãŸä»£æ›¿æ´»å‹•ã®ææ¡ˆ
                        result = self._generate_dice_counterfactual_simple(
                            activities_data, idx[0], original_activity, predictor
                        )

                        if result:
                            hourly_schedule.append({
                                'hour': hour,
                                'time_range': f"{hour:02d}:00-{hour+1:02d}:00",
                                'original_activity': result['original_activity'],
                                'suggested_activity': result['suggested_activity'],
                                'improvement': result['improvement'],
                                'confidence': result['confidence']
                            })
                            total_improvement += result['improvement']

            if total_improvement == 0:
                logger.warning("æ™‚é–“åˆ¥DiCEææ¡ˆ: æ”¹å–„ææ¡ˆã‚’ç”Ÿæˆã§ãã¾ã›ã‚“ã§ã—ãŸ")
                return self._get_error_hourly_schedule("æ”¹å–„ææ¡ˆã‚’ç”Ÿæˆã§ãã¾ã›ã‚“ã§ã—ãŸ")

            return {
                'type': 'hourly_dice_schedule',
                'date': target_date.strftime('%Y-%m-%d'),
                'hourly_schedule': hourly_schedule,
                'total_improvement': total_improvement,
                'average_improvement': total_improvement / 24 if hourly_schedule else 0,
                'message': f"ä»Šæ—¥ã“ã®ã‚ˆã†ãªæ´»å‹•ã‚’ã—ã¦ã„ãŸã‚‰ã‚¹ãƒˆãƒ¬ã‚¹ãƒ¬ãƒ™ãƒ«ãŒ{total_improvement:.1f}ç‚¹ä¸‹ãŒã£ã¦ã„ã¾ã—ãŸ",
                'confidence': min(0.9, 0.5 + len(hourly_schedule) * 0.05),
                'summary': f"24æ™‚é–“ä¸­{len(hourly_schedule)}æ™‚é–“ã§æ”¹å–„ã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã—ãŸ"
            }

        except Exception as e:
            logger.error(f"æ™‚é–“åˆ¥DiCEææ¡ˆç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
            return self._get_error_hourly_schedule(str(e))

    def _get_error_explanation(self, error_message: str) -> Dict:
        """ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿæ™‚ã®èª¬æ˜"""
        return {
            'type': 'error',
            'status': 'error',
            'error_message': error_message,
            'confidence': 0.0
        }

    def _get_error_hourly_schedule(self, error_message: str) -> dict:
        """ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿæ™‚ã®æ™‚é–“åˆ¥ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«"""
        return {
            'type': 'error',
            'status': 'error',
            'error_message': error_message,
            'date': datetime.now().strftime('%Y-%m-%d'),
            'hourly_schedule': [],
            'total_improvement': 0,
            'confidence': 0.0
        }
