"""
æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®ãƒ‡ãƒãƒƒã‚°ç”¨ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""

import pandas as pd
import numpy as np
from datetime import datetime
from ml_model import FrustrationPredictor
from sheets_connector import SheetsConnector
from config import Config
import logging

logging.basicConfig(level=logging.DEBUG)
logger = logging.getLogger(__name__)

def debug_model():
    """ãƒ¢ãƒ‡ãƒ«ã®çŠ¶æ…‹ã‚’è©³ç´°ã«ãƒ‡ãƒãƒƒã‚°"""

    print("=" * 80)
    print("æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ« ãƒ‡ãƒãƒƒã‚°ãƒ¬ãƒãƒ¼ãƒˆ")
    print("=" * 80)
    print()

    # åˆæœŸåŒ–
    predictor = FrustrationPredictor()
    sheets_connector = SheetsConnector()
    config = Config()

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ID
    user_id = 'default'

    # ãƒ‡ãƒ¼ã‚¿å–å¾—
    print("ğŸ“Š ãƒ‡ãƒ¼ã‚¿å–å¾—ä¸­...")
    activity_data = sheets_connector.get_activity_data(user_id)
    fitbit_data = sheets_connector.get_fitbit_data(user_id)

    print(f"  - æ´»å‹•ãƒ‡ãƒ¼ã‚¿: {len(activity_data)} ä»¶")
    print(f"  - Fitbitãƒ‡ãƒ¼ã‚¿: {len(fitbit_data)} ä»¶")
    print()

    if activity_data.empty:
        print("âŒ ã‚¨ãƒ©ãƒ¼: æ´»å‹•ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
        return

    # ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†
    print("ğŸ”§ ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†...")
    activity_processed = predictor.preprocess_activity_data(activity_data)
    df_enhanced = predictor.aggregate_fitbit_by_activity(activity_processed, fitbit_data)

    print(f"  - å‰å‡¦ç†å¾Œ: {len(df_enhanced)} ä»¶")
    print()

    # ãƒ‡ãƒ¼ã‚¿å“è³ªãƒã‚§ãƒƒã‚¯
    print("ğŸ“ˆ ãƒ‡ãƒ¼ã‚¿å“è³ªãƒã‚§ãƒƒã‚¯...")
    data_quality = predictor.check_data_quality(df_enhanced)
    print(f"  - ç·ã‚µãƒ³ãƒ—ãƒ«æ•°: {data_quality['total_samples']}")
    print(f"  - ãƒ‡ãƒ¼ã‚¿å……è¶³: {data_quality['is_sufficient']}")
    print(f"  - å“è³ªãƒ¬ãƒ™ãƒ«: {data_quality['quality_level']}")
    if data_quality['warnings']:
        print(f"  âš ï¸ è­¦å‘Š:")
        for warning in data_quality['warnings']:
            print(f"    - {warning}")
    print()

    # NASA_Fçµ±è¨ˆ
    print("ğŸ“Š NASA_Fçµ±è¨ˆ...")
    if 'NASA_F' in df_enhanced.columns:
        nasa_f = df_enhanced['NASA_F'].dropna()
        print(f"  - ä»¶æ•°: {len(nasa_f)}")
        print(f"  - å¹³å‡: {nasa_f.mean():.2f}")
        print(f"  - æ¨™æº–åå·®: {nasa_f.std():.2f}")
        print(f"  - æœ€å°å€¤: {nasa_f.min():.2f}")
        print(f"  - æœ€å¤§å€¤: {nasa_f.max():.2f}")
        print(f"  - ãƒ¦ãƒ‹ãƒ¼ã‚¯å€¤: {nasa_f.nunique()}")
        print(f"  - å€¤ã®åˆ†å¸ƒ: {nasa_f.value_counts().head(10).to_dict()}")
    print()

    # æ´»å‹•ã‚«ãƒ†ã‚´ãƒªçµ±è¨ˆ
    print("ğŸƒ æ´»å‹•ã‚«ãƒ†ã‚´ãƒªçµ±è¨ˆ...")
    if 'CatSub' in df_enhanced.columns:
        activities = df_enhanced['CatSub'].dropna()
        print(f"  - ç·æ´»å‹•æ•°: {len(activities)}")
        print(f"  - ãƒ¦ãƒ‹ãƒ¼ã‚¯æ´»å‹•æ•°: {activities.nunique()}")
        print(f"  - ä¸Šä½5æ´»å‹•:")
        for activity, count in activities.value_counts().head(5).items():
            print(f"    - {activity}: {count}ä»¶")
    print()

    # ãƒ¢ãƒ‡ãƒ«è¨“ç·´
    print("ğŸ¤– ãƒ¢ãƒ‡ãƒ«è¨“ç·´...")
    if len(df_enhanced) >= 10:
        training_results = predictor.walk_forward_validation_train(df_enhanced)
        print(f"  - ãƒ¢ãƒ‡ãƒ«è¨“ç·´: âœ… å®Œäº†")
        print(f"  - RMSE: {training_results.get('walk_forward_rmse', 'N/A'):.2f}")
        print(f"  - MAE: {training_results.get('walk_forward_mae', 'N/A'):.2f}")
        print(f"  - RÂ²: {training_results.get('walk_forward_r2', 'N/A'):.3f}")

        # äºˆæ¸¬å€¤ã®å¤šæ§˜æ€§
        pred_diversity = training_results.get('prediction_diversity', {})
        print(f"  - äºˆæ¸¬å€¤æ¨™æº–åå·®: {pred_diversity.get('std', 0):.3f}")
        print(f"  - äºˆæ¸¬å€¤ç¨®é¡æ•°: {pred_diversity.get('unique_values', 0)}")
        print(f"  - å¤šæ§˜æ€§OK: {pred_diversity.get('is_diverse', False)}")

        # ç‰¹å¾´é‡é‡è¦åº¦
        print(f"\n  ğŸ“Š ç‰¹å¾´é‡é‡è¦åº¦ï¼ˆä¸Šä½10ï¼‰:")
        feature_importance = training_results.get('feature_importance', {})
        sorted_features = sorted(feature_importance.items(), key=lambda x: x[1], reverse=True)[:10]
        for feature, importance in sorted_features:
            print(f"    - {feature}: {importance:.4f}")
    else:
        print(f"  âŒ ãƒ‡ãƒ¼ã‚¿ä¸è¶³: {len(df_enhanced)}ä»¶ < 10ä»¶")
    print()

    # ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ç¢ºèª
    print("ğŸ”‘ ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ç¢ºèª...")
    if hasattr(predictor, 'encoders'):
        for key, encoder in predictor.encoders.items():
            print(f"  - {key}:")
            if hasattr(encoder, 'classes_'):
                print(f"    ã‚¯ãƒ©ã‚¹æ•°: {len(encoder.classes_)}")
                print(f"    ã‚¯ãƒ©ã‚¹: {list(encoder.classes_[:5])}...")
    print()

    # ãƒ†ã‚¹ãƒˆäºˆæ¸¬ï¼ˆéå»ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ï¼‰
    print("ğŸ”® ãƒ†ã‚¹ãƒˆäºˆæ¸¬...")
    if not df_enhanced.empty and predictor.model is not None:
        test_cases = df_enhanced.head(5)

        for idx, row in test_cases.iterrows():
            activity = row.get('CatSub', 'unknown')
            duration = row.get('Duration', 60)
            timestamp = pd.to_datetime(row.get('Timestamp'))
            actual_frustration = row.get('NASA_F')

            print(f"\n  ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ {idx + 1}:")
            print(f"    - æ´»å‹•: {activity}")
            print(f"    - æ™‚åˆ»: {timestamp}")
            print(f"    - å®Ÿæ¸¬å€¤: {actual_frustration}")

            # predict_single_activityï¼ˆå›ºå®šå€¤ä½¿ç”¨ï¼‰
            result1 = predictor.predict_single_activity(activity, duration, timestamp)
            print(f"    - äºˆæ¸¬å€¤(å›ºå®šç‰¹å¾´é‡): {result1.get('predicted_frustration', 'N/A'):.2f}")

            # predict_with_historyï¼ˆå±¥æ­´ä½¿ç”¨ï¼‰
            result2 = predictor.predict_with_history(activity, duration, timestamp, df_enhanced)
            print(f"    - äºˆæ¸¬å€¤(å±¥æ­´ä½¿ç”¨): {result2.get('predicted_frustration', 'N/A'):.2f}")
            print(f"    - ä½¿ç”¨å±¥æ­´æ•°: {result2.get('historical_records', 'N/A')}")
    print()

    # æœ€æ–°ãƒ‡ãƒ¼ã‚¿ã§ã®äºˆæ¸¬ãƒ†ã‚¹ãƒˆ
    print("ğŸ¯ æœ€æ–°ãƒ‡ãƒ¼ã‚¿ã§ã®äºˆæ¸¬ãƒ†ã‚¹ãƒˆ...")
    if not df_enhanced.empty and predictor.model is not None:
        latest = df_enhanced.iloc[-1]
        activity = latest.get('CatSub', 'unknown')
        duration = latest.get('Duration', 60)
        timestamp = datetime.now()

        print(f"  - æ´»å‹•: {activity}")
        print(f"  - æœŸé–“: {duration}åˆ†")

        result = predictor.predict_with_history(activity, duration, timestamp, df_enhanced)
        print(f"  - äºˆæ¸¬å€¤: {result.get('predicted_frustration', 'N/A'):.2f}")
        print(f"  - ä¿¡é ¼åº¦: {result.get('confidence', 0):.3f}")
        print(f"  - ä½¿ç”¨å±¥æ­´æ•°: {result.get('historical_records', 'N/A')}")
    print()

    # è¨ºæ–­çµæœ
    print("=" * 80)
    print("ğŸ” è¨ºæ–­çµæœ")
    print("=" * 80)

    issues = []

    if data_quality['total_samples'] < 10:
        issues.append(f"ãƒ‡ãƒ¼ã‚¿æ•°ä¸è¶³: {data_quality['total_samples']}ä»¶ < 10ä»¶")

    if 'NASA_F' in df_enhanced.columns:
        nasa_f = df_enhanced['NASA_F'].dropna()
        if nasa_f.std() < 1.0:
            issues.append(f"NASA_Fã®åˆ†æ•£ãŒå°ã•ã„: Ïƒ={nasa_f.std():.2f}")
        if nasa_f.nunique() < 3:
            issues.append(f"NASA_Fã®ç¨®é¡ãŒå°‘ãªã„: {nasa_f.nunique()}ç¨®é¡")

    if predictor.model is None:
        issues.append("ãƒ¢ãƒ‡ãƒ«ãŒè¨“ç·´ã•ã‚Œã¦ã„ã¾ã›ã‚“")

    if 'CatSub' in df_enhanced.columns:
        if df_enhanced['CatSub'].nunique() < 3:
            issues.append(f"æ´»å‹•ã®ç¨®é¡ãŒå°‘ãªã„: {df_enhanced['CatSub'].nunique()}ç¨®é¡")

    if issues:
        print("âŒ æ¤œå‡ºã•ã‚ŒãŸå•é¡Œ:")
        for issue in issues:
            print(f"  - {issue}")
    else:
        print("âœ… å•é¡Œãªã—: ãƒ¢ãƒ‡ãƒ«ã¯æ­£å¸¸ã«å‹•ä½œã—ã¦ã„ã¾ã™")

    print()
    print("=" * 80)

if __name__ == '__main__':
    debug_model()
