"""
LLMã«ã‚ˆã‚‹è‡ªç„¶è¨€èªãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ç”Ÿæˆæ©Ÿèƒ½
éå»24æ™‚é–“ã®DiCEçµæœã‚’è€ƒæ…®ã—ã¦è‡ªç„¶è¨€èªã§ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’ç”Ÿæˆ
Google Cloud Secret Managerã‚’ä½¿ç”¨ã—ã¦APIã‚­ãƒ¼ã‚’å®‰å…¨ã«ç®¡ç†
"""

import pandas as pd
import numpy as np
import logging
from typing import Dict, List, Optional
from datetime import datetime, timedelta
import json
import requests
import os

from config import Config

logger = logging.getLogger(__name__)

class LLMFeedbackGenerator:
    def __init__(self):
        logger.info("=" * 60)
        logger.info("ğŸš€ LLMFeedbackGenerator åˆæœŸåŒ–é–‹å§‹")
        logger.info("=" * 60)

        self.config = Config()
        logger.info(f"ğŸ“‹ è¨­å®šèª­ã¿è¾¼ã¿å®Œäº† (IS_CLOUD_RUN: {self.config.IS_CLOUD_RUN})")

        self.llm_api_key = self._get_api_key_from_secret_manager()
        self.llm_api_base = "https://api.openai.com/v1"

        if self.llm_api_key:
            logger.info(f"âœ… LLMFeedbackGenerator åˆæœŸåŒ–å®Œäº† (APIã‚­ãƒ¼: è¨­å®šæ¸ˆã¿)")
        else:
            logger.warning(f"âš ï¸ LLMFeedbackGenerator åˆæœŸåŒ–å®Œäº† (APIã‚­ãƒ¼: æœªè¨­å®š)")
        logger.info("=" * 60)

    def _get_api_key_from_secret_manager(self) -> str:
        """
        ç’°å¢ƒå¤‰æ•°ã‹ã‚‰OpenAI APIã‚­ãƒ¼ã‚’å–å¾—
        Cloud Runç’°å¢ƒã§ã¯Secret Managerã®ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆãŒç’°å¢ƒå¤‰æ•°ã¨ã—ã¦ãƒã‚¦ãƒ³ãƒˆã•ã‚Œã¾ã™
        """
        logger.info("ğŸ”‘ OpenAI APIã‚­ãƒ¼å–å¾—ã‚’é–‹å§‹...")
        logger.info("ğŸ“ ç’°å¢ƒå¤‰æ•° 'OPENAI_API_KEY' ã‚’ç¢ºèªä¸­...")

        try:
            # OPENAI_API_KEY ã¾ãŸã¯ OPEN_API_KEY ã‹ã‚‰å–å¾—ï¼ˆä¸¡æ–¹ã«å¯¾å¿œï¼‰
            api_key = os.environ.get('OPENAI_API_KEY', os.environ.get('OPEN_API_KEY', ''))

            if api_key:
                # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã®ãŸã‚æœ€åˆã®7æ–‡å­—ã®ã¿è¡¨ç¤º
                masked_key = api_key[:7] + "..." if len(api_key) > 7 else "***"
                logger.info(f"âœ… OpenAI APIã‚­ãƒ¼ã‚’ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—ã—ã¾ã—ãŸ")
                logger.info(f"ğŸ” APIã‚­ãƒ¼ (ãƒã‚¹ã‚¯è¡¨ç¤º): {masked_key}")
                logger.info(f"ğŸ“ APIã‚­ãƒ¼ã®é•·ã•: {len(api_key)}æ–‡å­—")
            else:
                logger.error("âŒ OPENAI_API_KEYç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ï¼")
                if self.config.IS_CLOUD_RUN:
                    logger.error("ğŸ’¡ Cloud Runç’°å¢ƒ: Secret Managerã®ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆã‚’ç’°å¢ƒå¤‰æ•°ã¨ã—ã¦ãƒã‚¦ãƒ³ãƒˆã—ã¦ãã ã•ã„")
                    logger.error("   ä¾‹: gcloud run services update SERVICE_NAME --update-secrets=OPENAI_API_KEY=openai-api-key:latest")
                else:
                    logger.error("ğŸ’¡ ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒ: ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã§ 'export OPENAI_API_KEY=your-api-key' ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„")

            return api_key

        except Exception as e:
            logger.error(f"APIã‚­ãƒ¼å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return ''

    def _generate_with_llm(self, prompt: str) -> str:
        """
        OpenAI APIç­‰ã®LLMã‚’ä½¿ç”¨ã—ã¦ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’ç”Ÿæˆ
        """
        try:
            logger.info("ğŸ¤– ChatGPT API (gpt-3.5-turbo) ã‚’å‘¼ã³å‡ºã—ä¸­...")
            logger.debug(f"ğŸ“¤ é€ä¿¡ã™ã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: {prompt[:200]}...")  # æœ€åˆã®200æ–‡å­—ã®ã¿

            headers = {
                'Authorization': f'Bearer {self.llm_api_key}',
                'Content-Type': 'application/json'
            }

            data = {
                'model': 'gpt-3.5-turbo',
                'messages': [
                    {
                        'role': 'system',
                        'content': 'ã‚ãªãŸã¯å„ªç§€ãªã‚¹ãƒˆãƒ¬ã‚¹ç®¡ç†ã‚³ãƒ³ã‚µãƒ«ã‚¿ãƒ³ãƒˆã§ã™ã€‚æ¸©ã‹ãã€å…·ä½“çš„ã§å®Ÿè·µçš„ãªã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’æä¾›ã—ã¾ã™ã€‚'
                    },
                    {
                        'role': 'user',
                        'content': prompt
                    }
                ],
                'max_tokens': 500,
                'temperature': 0.7
            }

            response = requests.post(
                f"{self.llm_api_base}/chat/completions",
                headers=headers,
                json=data,
                timeout=30
            )

            if response.status_code == 200:
                result = response.json()
                generated_text = result['choices'][0]['message']['content'].strip()
                logger.info(f"âœ… ChatGPT APIã‹ã‚‰ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’ç”Ÿæˆã—ã¾ã—ãŸ (æ–‡å­—æ•°: {len(generated_text)})")
                logger.info(f"ğŸ“ ç”Ÿæˆã•ã‚ŒãŸãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯: {generated_text}")
                return generated_text
            else:
                logger.warning(f"âŒ LLM API ã‚¨ãƒ©ãƒ¼: {response.status_code}, Response: {response.text}")
                return self._generate_rule_based_feedback_simple()

        except Exception as e:
            logger.error(f"LLM ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return self._generate_rule_based_feedback_simple()

    def _generate_rule_based_feedback_simple(self) -> str:
        """
        ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯
        """
        return "ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’ç”Ÿæˆã™ã‚‹ã«ã¯OpenAI APIã‚­ãƒ¼ãŒå¿…è¦ã§ã™ã€‚"

    def generate_daily_dice_feedback(self,
                                    daily_dice_result: Dict,
                                    timeline_data: List[Dict] = None) -> Dict:
        """
        1æ—¥ã®çµ‚ã‚ã‚Šã«DiCEçµæœã«åŸºã¥ã„ãŸæ—¥æ¬¡ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’ç”Ÿæˆ
        ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³å…¨ä½“ã‚’è€ƒæ…®ã—ãŸåŒ…æ‹¬çš„ãªã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’æä¾›

        Args:
            daily_dice_result: 1æ—¥åˆ†ã®DiCEåˆ†æçµæœ
            timeline_data: 1æ—¥ã®ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³ãƒ‡ãƒ¼ã‚¿ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰

        Returns:
            æ—¥æ¬¡ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯è¾æ›¸
        """
        try:
            if not daily_dice_result:
                return self._get_fallback_daily_feedback()

            # DiCEçµæœã‹ã‚‰é‡è¦ãªæƒ…å ±ã‚’æŠ½å‡º
            hourly_schedule = daily_dice_result.get('hourly_schedule', [])
            total_improvement = daily_dice_result.get('total_improvement', 0)
            date = daily_dice_result.get('date', datetime.now().strftime('%Y-%m-%d'))

            # ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰çµ±è¨ˆæƒ…å ±ã‚’è¨ˆç®—
            timeline_stats = self._analyze_timeline_data(timeline_data) if timeline_data else {}

            # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰
            prompt = self._build_daily_dice_feedback_prompt(
                hourly_schedule,
                total_improvement,
                date,
                timeline_stats
            )

            # LLMã§ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ç”Ÿæˆ
            if self.llm_api_key:
                logger.info("ğŸ”‘ OpenAI APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã™ã€‚ChatGPTã§ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’ç”Ÿæˆã—ã¾ã™ã€‚")
                feedback_content = self._generate_with_llm(prompt)
            else:
                logger.warning("âš ï¸ OpenAI APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
                feedback_content = self._generate_rule_based_daily_feedback(
                    hourly_schedule,
                    total_improvement,
                    timeline_stats
                )

            # æ˜æ—¥ã¸ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ©ãƒ³ã‚’ç”Ÿæˆ
            action_plan = self._generate_tomorrow_action_plan(hourly_schedule, timeline_stats)

            return {
                'type': 'daily_dice_feedback',
                'date': date,
                'generated_at': datetime.now().isoformat(),
                'main_feedback': feedback_content,
                'total_improvement_potential': total_improvement,
                'num_suggestions': len(hourly_schedule),
                'action_plan': action_plan,
                'timeline_stats': timeline_stats,
                'confidence': 0.85 if self.llm_api_key else 0.65
            }

        except Exception as e:
            logger.error(f"æ—¥æ¬¡DiCEãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return self._get_fallback_daily_feedback()

    def _analyze_timeline_data(self, timeline_data: List[Dict]) -> Dict:
        """
        ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†æã—ã¦çµ±è¨ˆæƒ…å ±ã‚’ç”Ÿæˆ
        """
        try:
            if not timeline_data:
                return {}

            frustration_values = [item.get('frustration_value', 10) for item in timeline_data]
            activities = [item.get('activity', 'ä¸æ˜') for item in timeline_data]

            # æ´»å‹•åˆ¥ã®å¹³å‡ãƒ•ãƒ©ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å€¤
            activity_frustration = {}
            for item in timeline_data:
                activity = item.get('activity', 'ä¸æ˜')
                frustration = item.get('frustration_value', 10)
                if activity not in activity_frustration:
                    activity_frustration[activity] = []
                activity_frustration[activity].append(frustration)

            # å¹³å‡å€¤ã‚’è¨ˆç®—
            activity_avg = {
                activity: sum(values) / len(values)
                for activity, values in activity_frustration.items()
            }

            # æœ€ã‚‚ã‚¹ãƒˆãƒ¬ã‚¹ãŒé«˜ã‹ã£ãŸæ´»å‹•ã¨ä½ã‹ã£ãŸæ´»å‹•
            sorted_activities = sorted(activity_avg.items(), key=lambda x: x[1], reverse=True)

            return {
                'avg_frustration': sum(frustration_values) / len(frustration_values) if frustration_values else 10,
                'min_frustration': min(frustration_values) if frustration_values else 0,
                'max_frustration': max(frustration_values) if frustration_values else 20,
                'total_activities': len(timeline_data),
                'highest_stress_activity': sorted_activities[0] if sorted_activities else ('ä¸æ˜', 10),
                'lowest_stress_activity': sorted_activities[-1] if sorted_activities else ('ä¸æ˜', 10),
                'activity_distribution': activity_avg
            }

        except Exception as e:
            logger.error(f"ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³ãƒ‡ãƒ¼ã‚¿åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            return {}

    def _build_daily_dice_feedback_prompt(self,
                                         hourly_schedule: List[Dict],
                                         total_improvement: float,
                                         date: str,
                                         timeline_stats: Dict) -> str:
        """
        æ—¥æ¬¡DiCEãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ç”¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰
        """
        try:
            # æ”¹å–„ææ¡ˆã‚’ãƒ†ã‚­ã‚¹ãƒˆåŒ–
            suggestions_text = []
            for suggestion in hourly_schedule[:5]:  # ä¸Šä½5ä»¶
                time_range = suggestion.get('time_range', 'ä¸æ˜')
                original = suggestion.get('original_activity', 'ä¸æ˜')
                suggested = suggestion.get('suggested_activity', 'ä¸æ˜')
                improvement = suggestion.get('improvement', 0)

                suggestions_text.append(
                    f"- {time_range}: ã€Œ{original}ã€â†’ã€Œ{suggested}ã€(æ”¹å–„: {improvement:.1f}ç‚¹)"
                )

            # ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³çµ±è¨ˆ
            avg_frustration = timeline_stats.get('avg_frustration', 10)
            highest_stress = timeline_stats.get('highest_stress_activity', ('ä¸æ˜', 10))
            lowest_stress = timeline_stats.get('lowest_stress_activity', ('ä¸æ˜', 10))

            prompt = f"""
ã‚ãªãŸã¯ã‚¹ãƒˆãƒ¬ã‚¹ç®¡ç†ã®å°‚é–€å®¶ã§ã™ã€‚ä»Šæ—¥1æ—¥ã®æ´»å‹•ãƒ‡ãƒ¼ã‚¿ã¨DiCEåˆ†æçµæœã‚’ã‚‚ã¨ã«ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«å¯„ã‚Šæ·»ã£ãŸæ¸©ã‹ã¿ã®ã‚ã‚‹ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

## ä»Šæ—¥ã®æ—¥ä»˜
{date}

## ä»Šæ—¥ã®çµ±è¨ˆ
- å¹³å‡ãƒ•ãƒ©ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å€¤: {avg_frustration:.1f}ç‚¹ (1-20ã‚¹ã‚±ãƒ¼ãƒ«)
- æœ€å¤§: {timeline_stats.get('max_frustration', 20):.1f}ç‚¹ã€æœ€å°: {timeline_stats.get('min_frustration', 0):.1f}ç‚¹
- æ´»å‹•æ•°: {timeline_stats.get('total_activities', 0)}ä»¶
- æœ€ã‚‚ã‚¹ãƒˆãƒ¬ã‚¹ãŒé«˜ã‹ã£ãŸæ´»å‹•: {highest_stress[0]} ({highest_stress[1]:.1f}ç‚¹)
- æœ€ã‚‚ãƒªãƒ©ãƒƒã‚¯ã‚¹ã§ããŸæ´»å‹•: {lowest_stress[0]} ({lowest_stress[1]:.1f}ç‚¹)

## DiCEåˆ†æã«ã‚ˆã‚‹æ”¹å–„ææ¡ˆ
ç·æ”¹å–„ãƒãƒ†ãƒ³ã‚·ãƒ£ãƒ«: {total_improvement:.1f}ç‚¹
ææ¡ˆæ•°: {len(hourly_schedule)}ä»¶

### ä¸»ãªæ”¹å–„ææ¡ˆ
{chr(10).join(suggestions_text[:5]) if suggestions_text else 'æ”¹å–„ææ¡ˆãªã—'}

## ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ç”Ÿæˆã®æŒ‡é‡
1. **ä»Šæ—¥1æ—¥ã®æŒ¯ã‚Šè¿”ã‚Š**ã‹ã‚‰å§‹ã‚ã¦ãã ã•ã„ï¼ˆãƒã‚¸ãƒ†ã‚£ãƒ–ãªç‚¹ã‚’å¼·èª¿ï¼‰
2. **æ•°å€¤ã‚’è‡ªç„¶ã«ç¹”ã‚Šäº¤ãœã¦**å…·ä½“æ€§ã‚’æŒãŸã›ã¦ãã ã•ã„
3. **DiCEææ¡ˆã‹ã‚‰1-2ã¤ã®å®Ÿè·µçš„ãªã‚¢ãƒ‰ãƒã‚¤ã‚¹**ã‚’å«ã‚ã¦ãã ã•ã„
4. **åŠ±ã¾ã—ã¨å‰å‘ããªãƒ¡ãƒƒã‚»ãƒ¼ã‚¸**ã§ç· ã‚ããã£ã¦ãã ã•ã„
5. **æœ€å¾Œã«å¿…ãšã€Œâ€»ChatGPTã«ã‚ˆã£ã¦ç”Ÿæˆã•ã‚ŒãŸã‚¢ãƒ‰ãƒã‚¤ã‚¹ã§ã™ã€‚ã€ã¨ã„ã†æ–‡è¨€ã‚’è¿½åŠ **ã—ã¦ãã ã•ã„
6. **ã€ãƒ†ã‚¹ãƒˆç”¨ã€‘æ–‡ç« ã®æœ€å¾Œã«å±±æ‰‹ç·šã®é§…åã‚’ä¸€ã¤ãƒ©ãƒ³ãƒ€ãƒ ã«è¿½åŠ ã—ã¦ãã ã•ã„**ï¼ˆä¾‹ï¼šã€Œæ¸‹è°·ã€ã€Œæ–°å®¿ã€ã€Œæ±äº¬ã€ãªã©ï¼‰

ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã¯100æ–‡å­—ç¨‹åº¦ã§ã€ç°¡æ½”ã§è¦ªã—ã¿ã‚„ã™ã„è¨€è‘‰é£ã„ã§æ›¸ã„ã¦ãã ã•ã„ã€‚
"""

            return prompt

        except Exception as e:
            logger.error(f"æ—¥æ¬¡DiCEãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰ã‚¨ãƒ©ãƒ¼: {e}")
            return "ä»Šæ—¥ã‚‚ãŠç–²ã‚Œã•ã¾ã§ã—ãŸã€‚æ˜æ—¥ã¯ã‚ˆã‚Šè‰¯ã„ä¸€æ—¥ã«ãªã‚Šã¾ã™ã‚ˆã†ã«ã€‚"

    def _generate_rule_based_daily_feedback(self,
                                           hourly_schedule: List[Dict],
                                           total_improvement: float,
                                           timeline_stats: Dict) -> str:
        """
        APIã‚­ãƒ¼ãŒãªã„å ´åˆã®ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        """
        return "ä»Šæ—¥ã‚‚ãŠç–²ã‚Œã•ã¾ã§ã—ãŸã€‚ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’ç”Ÿæˆã™ã‚‹ã«ã¯OpenAI APIã‚­ãƒ¼ãŒå¿…è¦ã§ã™ã€‚"

    def _generate_tomorrow_action_plan(self,
                                      hourly_schedule: List[Dict],
                                      timeline_stats: Dict) -> List[str]:
        """
        æ˜æ—¥ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ©ãƒ³ã‚’ç”Ÿæˆ
        """
        try:
            action_plan = []

            # æ”¹å–„åŠ¹æœãŒé«˜ã„ä¸Šä½3ä»¶ã®ææ¡ˆã‚’æŠ½å‡º
            top_suggestions = sorted(
                hourly_schedule,
                key=lambda x: x.get('improvement', 0),
                reverse=True
            )[:3]

            for suggestion in top_suggestions:
                time_range = suggestion.get('time_range', 'ä¸æ˜')
                suggested = suggestion.get('suggested_activity', 'ä¸æ˜')
                improvement = suggestion.get('improvement', 0)

                if improvement > 2:  # 2ç‚¹ä»¥ä¸Šã®æ”¹å–„åŠ¹æœãŒã‚ã‚‹å ´åˆã®ã¿
                    action_plan.append(
                        f"{time_range}é ƒã«ã€Œ{suggested}ã€ã‚’è©¦ã—ã¦ã¿ã‚‹ (æœŸå¾…åŠ¹æœ: {improvement:.1f}ç‚¹)"
                    )

            # ä¸€èˆ¬çš„ãªã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’è¿½åŠ 
            highest_stress = timeline_stats.get('highest_stress_activity', ('ä¸æ˜', 10))
            if highest_stress[1] > 15:
                action_plan.append(f"ã€Œ{highest_stress[0]}ã€ã®å‰å¾Œã«ä¼‘æ†©æ™‚é–“ã‚’è¨­ã‘ã‚‹")

            if not action_plan:
                action_plan.append("ç¾åœ¨ã®è‰¯å¥½ãªç”Ÿæ´»ãƒªã‚ºãƒ ã‚’ç¶­æŒã™ã‚‹")
                action_plan.append("å®šæœŸçš„ãªä¼‘æ†©ã¨ãƒªãƒ©ãƒƒã‚¯ã‚¹ã‚¿ã‚¤ãƒ ã‚’ç¢ºä¿ã™ã‚‹")

            return action_plan

        except Exception as e:
            logger.error(f"æ˜æ—¥ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ©ãƒ³ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return ["ååˆ†ãªç¡çœ ã¨ä¼‘æ¯ã‚’å–ã‚‹", "ç„¡ç†ã®ãªã„ãƒšãƒ¼ã‚¹ã§æ´»å‹•ã™ã‚‹"]

    def _get_fallback_daily_feedback(self) -> Dict:
        """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨æ—¥æ¬¡ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯"""
        return {
            'type': 'daily_dice_feedback',
            'date': datetime.now().strftime('%Y-%m-%d'),
            'generated_at': datetime.now().isoformat(),
            'main_feedback': "ä»Šæ—¥ã‚‚ãŠç–²ã‚Œã•ã¾ã§ã—ãŸã€‚ã‚†ã£ãã‚Šä¼‘ã‚“ã§ã€æ˜æ—¥ã‚‚å¥åº·çš„ãªä¸€æ—¥ã‚’éã”ã—ã¦ãã ã•ã„ã€‚",
            'total_improvement_potential': 0,
            'num_suggestions': 0,
            'action_plan': ["ååˆ†ãªä¼‘æ¯ã‚’å–ã‚‹", "æ˜æ—¥ã‚‚ç„¡ç†ã‚’ã—ãªã„"],
            'timeline_stats': {},
            'confidence': 0.3
        }