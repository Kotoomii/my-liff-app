"""
LLMã«ã‚ˆã‚‹è‡ªç„¶è¨€èªãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ç”Ÿæˆæ©Ÿèƒ½
éå»24æ™‚é–“ã®DiCEçµæœã‚’è€ƒæ…®ã—ã¦è‡ªç„¶è¨€èªã§ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’ç”Ÿæˆ
Google Cloud Secret Managerã‚’ä½¿ç”¨ã—ã¦APIã‚­ãƒ¼ã‚’å®‰å…¨ã«ç®¡ç†
"""

import pandas as pd
import numpy as np
import logging
from typing import Dict, List, Optional
from datetime import datetime, timedelta
import json
import requests
import os

from config import Config

logger = logging.getLogger(__name__)

class LLMFeedbackGenerator:
    def __init__(self, sheets_connector=None):
        logger.info("=" * 60)
        logger.info("ğŸš€ LLMFeedbackGenerator åˆæœŸåŒ–é–‹å§‹")
        logger.info("=" * 60)

        self.config = Config()
        logger.info(f"ğŸ“‹ è¨­å®šèª­ã¿è¾¼ã¿å®Œäº† (IS_CLOUD_RUN: {self.config.IS_CLOUD_RUN})")

        self.sheets_connector = sheets_connector

        self.llm_api_key = self._get_api_key_from_secret_manager()
        self.llm_api_base = "https://api.openai.com/v1"

        if self.llm_api_key:
            logger.info(f"âœ… LLMFeedbackGenerator åˆæœŸåŒ–å®Œäº† (APIã‚­ãƒ¼: è¨­å®šæ¸ˆã¿)")
        else:
            logger.warning(f"âš ï¸ LLMFeedbackGenerator åˆæœŸåŒ–å®Œäº† (APIã‚­ãƒ¼: æœªè¨­å®š)")
        logger.info("=" * 60)

    def _get_api_key_from_secret_manager(self) -> str:
        """
        ç’°å¢ƒå¤‰æ•°ã‹ã‚‰OpenAI APIã‚­ãƒ¼ã‚’å–å¾—
        Cloud Runç’°å¢ƒã§ã¯Secret Managerã®ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆãŒç’°å¢ƒå¤‰æ•°ã¨ã—ã¦ãƒã‚¦ãƒ³ãƒˆã•ã‚Œã¾ã™
        """
        logger.info("ğŸ”‘ OpenAI APIã‚­ãƒ¼å–å¾—ã‚’é–‹å§‹...")
        logger.info("ğŸ“ ç’°å¢ƒå¤‰æ•° 'OPENAI_API_KEY' ã‚’ç¢ºèªä¸­...")

        try:
            # OPENAI_API_KEY ã¾ãŸã¯ OPEN_API_KEY ã‹ã‚‰å–å¾—ï¼ˆä¸¡æ–¹ã«å¯¾å¿œï¼‰
            api_key = os.environ.get('OPENAI_API_KEY', os.environ.get('OPEN_API_KEY', ''))

            if api_key:
                # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã®ãŸã‚æœ€åˆã®7æ–‡å­—ã®ã¿è¡¨ç¤º
                masked_key = api_key[:7] + "..." if len(api_key) > 7 else "***"
                logger.info(f"âœ… OpenAI APIã‚­ãƒ¼ã‚’ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—ã—ã¾ã—ãŸ")
                logger.info(f"ğŸ” APIã‚­ãƒ¼ (ãƒã‚¹ã‚¯è¡¨ç¤º): {masked_key}")
                logger.info(f"ğŸ“ APIã‚­ãƒ¼ã®é•·ã•: {len(api_key)}æ–‡å­—")
            else:
                logger.error("âŒ OPENAI_API_KEYç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ï¼")
                if self.config.IS_CLOUD_RUN:
                    logger.error("ğŸ’¡ Cloud Runç’°å¢ƒ: Secret Managerã®ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆã‚’ç’°å¢ƒå¤‰æ•°ã¨ã—ã¦ãƒã‚¦ãƒ³ãƒˆã—ã¦ãã ã•ã„")
                    logger.error("   ä¾‹: gcloud run services update SERVICE_NAME --update-secrets=OPENAI_API_KEY=openai-api-key:latest")
                else:
                    logger.error("ğŸ’¡ ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒ: ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã§ 'export OPENAI_API_KEY=your-api-key' ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„")

            return api_key

        except Exception as e:
            logger.error(f"APIã‚­ãƒ¼å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return ''

    def _generate_with_llm(self, prompt: str) -> str:
        """
        OpenAI APIç­‰ã®LLMã‚’ä½¿ç”¨ã—ã¦ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’ç”Ÿæˆ
        """
        try:
            logger.info("ğŸ¤– ChatGPT API (gpt-3.5-turbo) ã‚’å‘¼ã³å‡ºã—ä¸­...")
            logger.debug(f"ğŸ“¤ é€ä¿¡ã™ã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: {prompt[:200]}...")  # æœ€åˆã®200æ–‡å­—ã®ã¿

            headers = {
                'Authorization': f'Bearer {self.llm_api_key}',
                'Content-Type': 'application/json'
            }

            data = {
                'model': 'gpt-3.5-turbo',
                'messages': [
                    {
                        'role': 'system',
                        'content': 'ã‚ãªãŸã¯å„ªç§€ãªã‚¹ãƒˆãƒ¬ã‚¹ç®¡ç†ã‚³ãƒ³ã‚µãƒ«ã‚¿ãƒ³ãƒˆã§ã™ã€‚æ¸©ã‹ãã€å…·ä½“çš„ã§å®Ÿè·µçš„ãªã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’æä¾›ã—ã¾ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è‡ªå¾‹æ€§ã‚’å°Šé‡ã—ã€å‘½ä»¤å½¢ï¼ˆã€Œã€œã—ã¾ã—ã‚‡ã†ã€ã€Œã€œã—ã¦ãã ã•ã„ã€ï¼‰ã¯çµ¶å¯¾ã«ä½¿ã‚ãšã€ææ¡ˆå‹ã®è¡¨ç¾ï¼ˆã€Œã€œã—ã¦ã¿ã‚‹ã®ã¯ã„ã‹ãŒã§ã—ã‚‡ã†ã‹ï¼Ÿã€ãªã©ï¼‰ã®ã¿ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚æ±ºå®šæ¨©ã¯å¸¸ã«ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚ã‚Šã¾ã™ã€‚ã€é‡è¦ã€‘ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã¯å¿…ãš150æ–‡å­—ä»¥å†…ã«åã‚ã¦ãã ã•ã„ã€‚ã“ã‚Œã¯å³æ ¼ãªåˆ¶ç´„ã§ã™ã€‚'
                    },
                    {
                        'role': 'user',
                        'content': prompt
                    }
                ],
                'max_tokens': 200,
                'temperature': 0.3
            }

            response = requests.post(
                f"{self.llm_api_base}/chat/completions",
                headers=headers,
                json=data,
                timeout=30
            )

            if response.status_code == 200:
                result = response.json()
                generated_text = result['choices'][0]['message']['content'].strip()

                # 150æ–‡å­—ã‚’è¶…ãˆã¦ã„ã‚‹å ´åˆã¯åˆ‡ã‚Šæ¨ã¦
                if len(generated_text) > 150:
                    logger.warning(f"âš ï¸ ç”Ÿæˆã•ã‚ŒãŸãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãŒ150æ–‡å­—ã‚’è¶…ãˆã¦ã„ã¾ã™ï¼ˆ{len(generated_text)}æ–‡å­—ï¼‰ã€‚150æ–‡å­—ã«åˆ‡ã‚Šæ¨ã¦ã¾ã™ã€‚")
                    generated_text = generated_text[:150]
                    # æœ«å°¾ãŒä¸­é€”åŠç«¯ãªæ–‡ã«ãªã‚‰ãªã„ã‚ˆã†ã€å¥ç‚¹ã§çµ‚ã‚ã‚‹ã‚ˆã†ã«èª¿æ•´
                    last_period = max(generated_text.rfind('ã€‚'), generated_text.rfind('ï¼Ÿ'), generated_text.rfind('ï¼'))
                    if last_period > 100:  # 100æ–‡å­—ä»¥ä¸Šæ®‹ã‚‹å ´åˆã®ã¿
                        generated_text = generated_text[:last_period + 1]

                logger.info(f"âœ… ChatGPT APIã‹ã‚‰ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’ç”Ÿæˆã—ã¾ã—ãŸ (æ–‡å­—æ•°: {len(generated_text)})")
                logger.info(f"ğŸ“ ç”Ÿæˆã•ã‚ŒãŸãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯: {generated_text}")
                return generated_text
            else:
                logger.warning(f"âŒ LLM API ã‚¨ãƒ©ãƒ¼: {response.status_code}, Response: {response.text}")
                return self._generate_rule_based_feedback_simple()

        except Exception as e:
            logger.error(f"LLM ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return self._generate_rule_based_feedback_simple()

    def _generate_rule_based_feedback_simple(self) -> str:
        """
        ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯
        """
        return "ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’ç”Ÿæˆã™ã‚‹ã«ã¯OpenAI APIã‚­ãƒ¼ãŒå¿…è¦ã§ã™ã€‚"

    def generate_daily_dice_feedback(self,
                                    daily_dice_result: Dict,
                                    timeline_data: List[Dict] = None,
                                    user_id: str = 'default') -> Dict:
        """
        1æ—¥ã®çµ‚ã‚ã‚Šã«DiCEçµæœã«åŸºã¥ã„ãŸæ—¥æ¬¡ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’ç”Ÿæˆ
        ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³å…¨ä½“ã‚’è€ƒæ…®ã—ãŸåŒ…æ‹¬çš„ãªã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’æä¾›

        Args:
            daily_dice_result: 1æ—¥åˆ†ã®DiCEåˆ†æçµæœ
            timeline_data: 1æ—¥ã®ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³ãƒ‡ãƒ¼ã‚¿ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
            user_id: ãƒ¦ãƒ¼ã‚¶ãƒ¼IDï¼ˆæ˜¨æ—¥ã®ãƒ‡ãƒ¼ã‚¿å–å¾—ç”¨ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 'default'ï¼‰

        Returns:
            æ—¥æ¬¡ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯è¾æ›¸
        """
        try:
            if not daily_dice_result:
                return self._get_fallback_daily_feedback()

            # DiCEçµæœã‹ã‚‰é‡è¦ãªæƒ…å ±ã‚’æŠ½å‡º
            hourly_schedule = daily_dice_result.get('hourly_schedule', [])
            total_improvement = daily_dice_result.get('total_improvement', 0)
            date = daily_dice_result.get('date', datetime.now().strftime('%Y-%m-%d'))

            # ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰çµ±è¨ˆæƒ…å ±ã‚’è¨ˆç®—
            timeline_stats = self._analyze_timeline_data(timeline_data) if timeline_data else {}

            # æ˜¨æ—¥ã®Daily Summaryãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆé€²æ—è¿½è·¡ã®ãŸã‚ï¼‰
            yesterday_summary = None
            if self.sheets_connector:
                from datetime import datetime as dt_class, timedelta
                yesterday_date = (dt_class.strptime(date, '%Y-%m-%d') - timedelta(days=1)).strftime('%Y-%m-%d')
                yesterday_summary = self.sheets_connector.get_daily_summary(user_id, yesterday_date)
                logger.info(f"ğŸ“Š æ˜¨æ—¥ã®ãƒ‡ãƒ¼ã‚¿å–å¾—: {yesterday_date}, å­˜åœ¨={yesterday_summary is not None}")

            # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰ï¼ˆæ˜¨æ—¥ã®ãƒ‡ãƒ¼ã‚¿ã‚’å«ã‚€ï¼‰
            prompt = self._build_daily_dice_feedback_prompt(
                hourly_schedule,
                total_improvement,
                date,
                timeline_stats,
                yesterday_summary
            )

            # LLMã§ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ç”Ÿæˆ
            if self.llm_api_key:
                logger.info("ğŸ”‘ OpenAI APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã™ã€‚ChatGPTã§ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’ç”Ÿæˆã—ã¾ã™ã€‚")
                feedback_content = self._generate_with_llm(prompt)
            else:
                logger.warning("âš ï¸ OpenAI APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
                feedback_content = self._generate_rule_based_daily_feedback(
                    hourly_schedule,
                    total_improvement,
                    timeline_stats
                )

            # æ˜æ—¥ã¸ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ©ãƒ³ã‚’ç”Ÿæˆ
            action_plan = self._generate_tomorrow_action_plan(hourly_schedule, timeline_stats)

            return {
                'type': 'daily_dice_feedback',
                'date': date,
                'generated_at': datetime.now().isoformat(),
                'main_feedback': feedback_content,
                'total_improvement_potential': total_improvement,
                'num_suggestions': len(hourly_schedule),
                'action_plan': action_plan,
                'timeline_stats': timeline_stats,
                'confidence': 0.85 if self.llm_api_key else 0.65
            }

        except Exception as e:
            logger.error(f"æ—¥æ¬¡DiCEãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return self._get_fallback_daily_feedback()

    def _analyze_timeline_data(self, timeline_data: List[Dict]) -> Dict:
        """
        ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†æã—ã¦çµ±è¨ˆæƒ…å ±ã‚’ç”Ÿæˆ
        """
        try:
            if not timeline_data:
                return {}

            # frustration_valueãŒnullã§ãªã„ã‚‚ã®ã ã‘ã‚’ãƒ•ã‚£ãƒ«ã‚¿
            frustration_values = [
                item.get('frustration_value')
                for item in timeline_data
                if item.get('frustration_value') is not None
            ]
            activities = [item.get('activity', 'ä¸æ˜') for item in timeline_data]

            # frustration_valueãŒnullã®å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
            if len(frustration_values) == 0:
                return {
                    'avg_frustration': None,
                    'min_frustration': None,
                    'max_frustration': None,
                    'total_activities': 0,
                    'highest_stress_activity': ('ä¸æ˜', None),
                    'lowest_stress_activity': ('ä¸æ˜', None),
                    'activity_distribution': {}
                }

            # æ´»å‹•åˆ¥ã®å¹³å‡ãƒ•ãƒ©ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å€¤
            activity_frustration = {}
            for item in timeline_data:
                activity = item.get('activity', 'ä¸æ˜')
                frustration = item.get('frustration_value')
                # nullã®å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
                if frustration is None:
                    continue
                if activity not in activity_frustration:
                    activity_frustration[activity] = []
                activity_frustration[activity].append(frustration)

            # å¹³å‡å€¤ã‚’è¨ˆç®—
            activity_avg = {
                activity: sum(values) / len(values)
                for activity, values in activity_frustration.items()
            }

            # æœ€ã‚‚ã‚¹ãƒˆãƒ¬ã‚¹ãŒé«˜ã‹ã£ãŸæ´»å‹•ã¨ä½ã‹ã£ãŸæ´»å‹•
            sorted_activities = sorted(activity_avg.items(), key=lambda x: x[1], reverse=True)

            return {
                'avg_frustration': sum(frustration_values) / len(frustration_values) if frustration_values else None,
                'min_frustration': min(frustration_values) if frustration_values else None,
                'max_frustration': max(frustration_values) if frustration_values else None,
                'total_activities': len(frustration_values),  # äºˆæ¸¬å€¤ãŒã‚ã‚‹ã‚‚ã®ã ã‘ã‚«ã‚¦ãƒ³ãƒˆ
                'highest_stress_activity': sorted_activities[0] if sorted_activities else ('ä¸æ˜', None),
                'lowest_stress_activity': sorted_activities[-1] if sorted_activities else ('ä¸æ˜', None),
                'activity_distribution': activity_avg
            }

        except Exception as e:
            logger.error(f"ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³ãƒ‡ãƒ¼ã‚¿åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            return {}

    def _build_daily_dice_feedback_prompt(self,
                                         hourly_schedule: List[Dict],
                                         total_improvement: float,
                                         date: str,
                                         timeline_stats: Dict,
                                         yesterday_summary: Dict = None) -> str:
        """
        æ—¥æ¬¡DiCEãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ç”¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰
        """
        try:
            # æ”¹å–„ææ¡ˆã‚’ãƒ†ã‚­ã‚¹ãƒˆåŒ–
            suggestions_text = []
            for suggestion in hourly_schedule[:5]:  # ä¸Šä½5ä»¶
                time_range = suggestion.get('time_range', suggestion.get('time', 'ä¸æ˜'))
                original = suggestion.get('original_activity', 'ä¸æ˜')
                suggested = suggestion.get('suggested_activity', 'ä¸æ˜')
                improvement = suggestion.get('improvement', 0)

                suggestions_text.append(
                    f"- {time_range}: ã€Œ{original}ã€â†’ã€Œ{suggested}ã€(æ”¹å–„: {improvement:.1f}ç‚¹)"
                )

            # ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³çµ±è¨ˆ
            avg_frustration = timeline_stats.get('avg_frustration')
            highest_stress = timeline_stats.get('highest_stress_activity', ('ä¸æ˜', None))
            lowest_stress = timeline_stats.get('lowest_stress_activity', ('ä¸æ˜', None))

            # ãƒ‡ãƒ¼ã‚¿ãŒå…¨ããªã„å ´åˆã®æ—©æœŸãƒªã‚¿ãƒ¼ãƒ³
            if avg_frustration is None:
                return "ä»Šæ—¥ã®ãƒ•ãƒ©ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚Fitbitãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚"

            # æ˜¨æ—¥ã¨ã®æ¯”è¼ƒæƒ…å ±ã‚’æ§‹ç¯‰
            comparison_text = ""
            if yesterday_summary:
                yesterday_avg = yesterday_summary.get('avg_predicted')
                yesterday_activities = yesterday_summary.get('total_activities', 0)

                if yesterday_avg is not None and avg_frustration is not None:
                    diff = avg_frustration - yesterday_avg
                    diff_direction = "æ”¹å–„" if diff < 0 else "ä¸Šæ˜‡" if diff > 0 else "æ¨ªã°ã„"
                    comparison_text = f"""
## æ˜¨æ—¥ã¨ã®æ¯”è¼ƒï¼ˆé€²æ—è¿½è·¡ï¼‰
- æ˜¨æ—¥ã®å¹³å‡ãƒ•ãƒ©ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å€¤: {yesterday_avg:.1f}ç‚¹
- ä»Šæ—¥ã®å¹³å‡: {avg_frustration:.1f}ç‚¹ï¼ˆæ˜¨æ—¥ã‚ˆã‚Š{abs(diff):.1f}ç‚¹{diff_direction}ï¼‰
- æ´»å‹•æ•°: æ˜¨æ—¥{yesterday_activities}ä»¶ â†’ ä»Šæ—¥{timeline_stats.get('total_activities', 0)}ä»¶
"""
            else:
                comparison_text = "\n## æ˜¨æ—¥ã¨ã®æ¯”è¼ƒ\næ˜¨æ—¥ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚åˆæ—¥ã®è¨˜éŒ²ã§ã™ã€‚\n"

            # Noneãƒã‚§ãƒƒã‚¯ã‚’è¿½åŠ 
            max_f = timeline_stats.get('max_frustration')
            min_f = timeline_stats.get('min_frustration')
            highest_stress_val = highest_stress[1] if highest_stress[1] is not None else 0
            lowest_stress_val = lowest_stress[1] if lowest_stress[1] is not None else 0

            prompt = f"""
ã‚ãªãŸã¯ã‚¹ãƒˆãƒ¬ã‚¹ç®¡ç†ã®å°‚é–€å®¶ã§ã™ã€‚è‡ªå·±æ±ºå®šç†è«–ï¼ˆSelf-Determination Theoryï¼‰ã«åŸºã¥ãã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è‡ªå¾‹æ€§ã‚’å°Šé‡ã—ã€å†…ç™ºçš„å‹•æ©Ÿã¥ã‘ã‚’ä¿ƒã™ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

## ä»Šæ—¥ã®æ—¥ä»˜
{date}
{comparison_text}
## ä»Šæ—¥ã®çµ±è¨ˆ
- å¹³å‡ãƒ•ãƒ©ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å€¤: {avg_frustration:.1f}ç‚¹ (1-20ã‚¹ã‚±ãƒ¼ãƒ«)
- æœ€å¤§: {max_f:.1f if max_f is not None else 'ä¸æ˜'}ç‚¹ã€æœ€å°: {min_f:.1f if min_f is not None else 'ä¸æ˜'}ç‚¹
- æ´»å‹•æ•°: {timeline_stats.get('total_activities', 0)}ä»¶
- æœ€ã‚‚ã‚¹ãƒˆãƒ¬ã‚¹ãŒé«˜ã‹ã£ãŸæ´»å‹•: {highest_stress[0]} ({highest_stress_val:.1f}ç‚¹)
- æœ€ã‚‚ãƒªãƒ©ãƒƒã‚¯ã‚¹ã§ããŸæ´»å‹•: {lowest_stress[0]} ({lowest_stress_val:.1f}ç‚¹)

## DiCEåˆ†æã«ã‚ˆã‚‹æ”¹å–„ææ¡ˆ
ç·æ”¹å–„ãƒãƒ†ãƒ³ã‚·ãƒ£ãƒ«: {total_improvement:.1f}ç‚¹
ææ¡ˆæ•°: {len(hourly_schedule)}ä»¶

### ä¸»ãªæ”¹å–„ææ¡ˆ
{chr(10).join(suggestions_text[:5]) if suggestions_text else 'æ”¹å–„ææ¡ˆãªã—'}

## ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã®å¿…é ˆæ§‹é€ ï¼ˆ150æ–‡å­—å³å®ˆï¼‰

### é‡è¦ï¼šDiCEææ¡ˆã®ä¼ãˆæ–¹
DiCEææ¡ˆã¯ã€Œæ´»å‹•ã‚’å®Œå…¨ã«å¤‰ãˆã‚‹ã€ã®ã§ã¯ãªãã€ã€Œå…ƒã®æ´»å‹•ã®å¾Œã‚„é–“ã«å°‘é‡å–ã‚Šå…¥ã‚Œã‚‹ã€ææ¡ˆã¨ã—ã¦ä¼ãˆã¦ãã ã•ã„ã€‚

**Few-shotä¾‹ï¼ˆå¿…ãšå‚è€ƒã«ã™ã‚‹ã“ã¨ï¼‰**:
1. ä»•äº‹ä¸­ã«ç¡çœ ãŒææ¡ˆã•ã‚ŒãŸå ´åˆ
   â†’ ã€Œä»•äº‹ã®å¾Œã‚„é–“ã«15åˆ†ç¨‹åº¦ã®ä»®çœ ã‚’å–ã‚Šå…¥ã‚Œã¦ã¿ã‚‹ã®ã¯ã„ã‹ãŒã§ã—ã‚‡ã†ã‹ã€

2. èº«ã®å›ã‚Šã®æ´»å‹•ä¸­ã«é£Ÿäº‹ãŒææ¡ˆã•ã‚ŒãŸå ´åˆ
   â†’ ã€Œå°‘ã—ç”˜ã„ã‚‚ã®ã‚’é£Ÿã¹ãªãŒã‚‰ä½œæ¥­ã—ã¦ã¿ã‚‹ã®ã‚‚è‰¯ã„ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€

3. å‹‰å¼·ä¸­ã«é‹å‹•ãŒææ¡ˆã•ã‚ŒãŸå ´åˆ
   â†’ ã€Œå‹‰å¼·ã®åˆé–“ã«è»½ã„ã‚¹ãƒˆãƒ¬ãƒƒãƒã‚’å–ã‚Šå…¥ã‚Œã‚‹ã®ã‚‚ä¸€ã¤ã®æ–¹æ³•ã§ã™ã€

**ææ¡ˆã®å‹**:
ã€Œ{original}ã®å¾Œã‚„é–“ã«{suggested}ã‚’å°‘ã—å–ã‚Šå…¥ã‚Œã¦ã¿ã‚‹ã®ã¯ã„ã‹ãŒã§ã—ã‚‡ã†ã‹ï¼Ÿã€

**çµ¶å¯¾ã«ä½¿ã£ã¦ã¯ã„ã‘ãªã„è¡¨ç¾**:
- âŒ ã€Œ{original}ã‚’{suggested}ã«å¤‰ãˆã¾ã—ã‚‡ã†ã€
- âŒ ã€Œã€œã—ã¦ãã ã•ã„ã€ã€Œã€œã—ã¾ã—ã‚‡ã†ã€
- âŒ ã€Œã€œã™ã¹ãã§ã™ã€ã€Œã€œãŒå¿…è¦ã§ã™ã€

**å¿…ãšä½¿ã†ã¹ãææ¡ˆå‹ã®è¡¨ç¾**:
- âœ… ã€Œã€œå–ã‚Šå…¥ã‚Œã¦ã¿ã‚‹ã®ã¯ã„ã‹ãŒã§ã—ã‚‡ã†ã‹ï¼Ÿã€
- âœ… ã€Œã€œã‚‚è‰¯ã„ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€

## å‡ºåŠ›å½¢å¼
1. æœ€ã‚‚ã‚¹ãƒˆãƒ¬ã‚¹ãŒé«˜ã‹ã£ãŸæ´»å‹•ã‚’ç°¡æ½”ã«æ˜ç¤ºï¼ˆ20æ–‡å­—ä»¥å†…ï¼‰
2. DiCEææ¡ˆã‚’ã€Œå¾Œã‚„é–“ã«å–ã‚Šå…¥ã‚Œã‚‹ã€å½¢å¼ã§ä¼ãˆã‚‹ï¼ˆ80æ–‡å­—ä»¥å†…ï¼‰
3. ç°¡æ½”ãªç· ã‚ã®è¨€è‘‰ï¼ˆ30æ–‡å­—ä»¥å†…ï¼‰

**æ–‡å­—æ•°**: å¿…ãš150æ–‡å­—ä»¥å†…ï¼ˆå³å®ˆï¼‰
**è¡¨ç¾**: ææ¡ˆå‹ã®ã¿ã€å‘½ä»¤å½¢ã¯çµ¶å¯¾ç¦æ­¢
"""

            return prompt

        except Exception as e:
            logger.error(f"æ—¥æ¬¡DiCEãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰ã‚¨ãƒ©ãƒ¼: {e}")
            return "ä»Šæ—¥ã‚‚ãŠç–²ã‚Œã•ã¾ã§ã—ãŸã€‚æ˜æ—¥ã¯ã‚ˆã‚Šè‰¯ã„ä¸€æ—¥ã«ãªã‚Šã¾ã™ã‚ˆã†ã«ã€‚"

    def _generate_rule_based_daily_feedback(self,
                                           hourly_schedule: List[Dict],
                                           total_improvement: float,
                                           timeline_stats: Dict) -> str:
        """
        APIã‚­ãƒ¼ãŒãªã„å ´åˆã®ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        """
        return "ä»Šæ—¥ã‚‚ãŠç–²ã‚Œã•ã¾ã§ã—ãŸã€‚ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’ç”Ÿæˆã™ã‚‹ã«ã¯OpenAI APIã‚­ãƒ¼ãŒå¿…è¦ã§ã™ã€‚"

    def _generate_tomorrow_action_plan(self,
                                      hourly_schedule: List[Dict],
                                      timeline_stats: Dict) -> List[str]:
        """
        æ˜æ—¥ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ©ãƒ³ã‚’ç”Ÿæˆ
        """
        try:
            action_plan = []

            # æ”¹å–„åŠ¹æœãŒé«˜ã„ä¸Šä½3ä»¶ã®ææ¡ˆã‚’æŠ½å‡º
            top_suggestions = sorted(
                hourly_schedule,
                key=lambda x: x.get('improvement', 0),
                reverse=True
            )[:3]

            for suggestion in top_suggestions:
                time_range = suggestion.get('time_range', 'ä¸æ˜')
                suggested = suggestion.get('suggested_activity', 'ä¸æ˜')
                improvement = suggestion.get('improvement', 0)

                if improvement > 2:  # 2ç‚¹ä»¥ä¸Šã®æ”¹å–„åŠ¹æœãŒã‚ã‚‹å ´åˆã®ã¿
                    action_plan.append(
                        f"{time_range}é ƒã«ã€Œ{suggested}ã€ã‚’è©¦ã—ã¦ã¿ã‚‹ (æœŸå¾…åŠ¹æœ: {improvement:.1f}ç‚¹)"
                    )

            # ä¸€èˆ¬çš„ãªã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’è¿½åŠ 
            highest_stress = timeline_stats.get('highest_stress_activity', ('ä¸æ˜', 10))
            if highest_stress[1] > 15:
                action_plan.append(f"ã€Œ{highest_stress[0]}ã€ã®å‰å¾Œã«ä¼‘æ†©æ™‚é–“ã‚’è¨­ã‘ã‚‹")

            if not action_plan:
                action_plan.append("ç¾åœ¨ã®è‰¯å¥½ãªç”Ÿæ´»ãƒªã‚ºãƒ ã‚’ç¶­æŒã™ã‚‹")
                action_plan.append("å®šæœŸçš„ãªä¼‘æ†©ã¨ãƒªãƒ©ãƒƒã‚¯ã‚¹ã‚¿ã‚¤ãƒ ã‚’ç¢ºä¿ã™ã‚‹")

            return action_plan

        except Exception as e:
            logger.error(f"æ˜æ—¥ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ©ãƒ³ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return ["ååˆ†ãªç¡çœ ã¨ä¼‘æ¯ã‚’å–ã‚‹", "ç„¡ç†ã®ãªã„ãƒšãƒ¼ã‚¹ã§æ´»å‹•ã™ã‚‹"]

    def _get_fallback_daily_feedback(self) -> Dict:
        """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨æ—¥æ¬¡ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯"""
        return {
            'type': 'daily_dice_feedback',
            'date': datetime.now().strftime('%Y-%m-%d'),
            'generated_at': datetime.now().isoformat(),
            'main_feedback': "ä»Šæ—¥ã‚‚ãŠç–²ã‚Œã•ã¾ã§ã—ãŸã€‚ã‚†ã£ãã‚Šä¼‘ã‚“ã§ã€æ˜æ—¥ã‚‚å¥åº·çš„ãªä¸€æ—¥ã‚’éã”ã—ã¦ãã ã•ã„ã€‚",
            'total_improvement_potential': 0,
            'num_suggestions': 0,
            'action_plan': ["ååˆ†ãªä¼‘æ¯ã‚’å–ã‚‹", "æ˜æ—¥ã‚‚ç„¡ç†ã‚’ã—ãªã„"],
            'timeline_stats': {},
            'confidence': 0.3
        }

    def generate_prediction_only_feedback(self,
                                         user_id: str,
                                         target_date: str,
                                         avg_stress: float) -> Dict:
        """
        æ¨å®šå€¤ã®ã¿ã«åŸºã¥ã„ãŸæ—¥æ¬¡ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’ç”Ÿæˆï¼ˆDiCEãªã—ï¼‰

        Args:
            user_id: ãƒ¦ãƒ¼ã‚¶ãƒ¼ID
            target_date: å¯¾è±¡æ—¥ï¼ˆ'YYYY-MM-DD'å½¢å¼ï¼‰
            avg_stress: æ—¥æ¬¡å¹³å‡äºˆæ¸¬å€¤ï¼ˆDaily Summaryã‹ã‚‰å–å¾—ï¼‰

        Returns:
            ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯è¾æ›¸
        """
        try:
            if not self.sheets_connector:
                logger.warning("sheets_connectorãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
                return self._get_fallback_prediction_only_feedback(target_date)

            # 1. Hourly_Logã‹ã‚‰å½“æ—¥ãƒ‡ãƒ¼ã‚¿å–å¾—
            hourly_log = self.sheets_connector.get_hourly_log(user_id, target_date)

            if hourly_log.empty:
                logger.warning(f"Hourly_Logã«ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“: {user_id}, {target_date}")
                return self._get_fallback_prediction_only_feedback(target_date)

            # 2. äºˆæ¸¬NASA_Fã§ä¸¦ã³æ›¿ãˆï¼ˆNaNé™¤å¤–ï¼‰
            hourly_log_clean = hourly_log.dropna(subset=['äºˆæ¸¬NASA_F'])

            if hourly_log_clean.empty:
                logger.warning(f"äºˆæ¸¬NASA_Fã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“: {user_id}, {target_date}")
                return self._get_fallback_prediction_only_feedback(target_date)

            hourly_log_sorted = hourly_log_clean.sort_values('äºˆæ¸¬NASA_F', ascending=False)

            # 3. é«˜ã‚¹ãƒˆãƒ¬ã‚¹æ´»å‹•ï¼ˆä¸Šä½3ä»¶ï¼‰ã¨ä½ã‚¹ãƒˆãƒ¬ã‚¹æ´»å‹•ï¼ˆä¸‹ä½3ä»¶ï¼‰ã‚’æŠ½å‡º
            high_stress = hourly_log_sorted.head(3)
            low_stress = hourly_log_sorted.tail(3)

            # 4. ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆ
            prompt = self._build_prediction_only_feedback_prompt(
                high_stress,
                low_stress,
                avg_stress,
                target_date
            )

            # 5. ChatGPTã§ç”Ÿæˆ
            if self.llm_api_key:
                logger.info("ğŸ”‘ OpenAI APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã™ã€‚ChatGPTã§æ¨å®šå€¤ã®ã¿ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’ç”Ÿæˆã—ã¾ã™ã€‚")
                feedback_content = self._generate_with_llm(prompt)
            else:
                logger.warning("âš ï¸ OpenAI APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
                feedback_content = "ä»Šæ—¥ã‚‚ãŠç–²ã‚Œã•ã¾ã§ã—ãŸã€‚ã‚†ã£ãã‚Šä¼‘ã‚“ã§ã€æ˜æ—¥ã‚‚å¥åº·çš„ãªä¸€æ—¥ã‚’éã”ã—ã¦ãã ã•ã„ã€‚"

            return {
                'type': 'prediction_only_feedback',
                'date': target_date,
                'generated_at': datetime.now().isoformat(),
                'main_feedback': feedback_content,
                'avg_stress': avg_stress,
                'confidence': 0.85 if self.llm_api_key else 0.65
            }

        except Exception as e:
            logger.error(f"æ¨å®šå€¤ã®ã¿ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return self._get_fallback_prediction_only_feedback(target_date)

    def _build_prediction_only_feedback_prompt(self,
                                               high_stress: pd.DataFrame,
                                               low_stress: pd.DataFrame,
                                               avg_stress: float,
                                               target_date: str) -> str:
        """
        æ¨å®šå€¤ã®ã¿ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰
        """
        # é«˜ã‚¹ãƒˆãƒ¬ã‚¹æ´»å‹•ãƒªã‚¹ãƒˆã‚’ä½œæˆ
        high_stress_list = []
        for _, row in high_stress.iterrows():
            time = row.get('æ™‚åˆ»', '--:--')
            activity = row.get('æ´»å‹•å', 'ä¸æ˜')
            predicted_f = row.get('äºˆæ¸¬NASA_F', 0)
            high_stress_list.append(f"- {time} {activity}ï¼ˆ{predicted_f:.1f}ç‚¹ï¼‰")

        # ä½ã‚¹ãƒˆãƒ¬ã‚¹æ´»å‹•ãƒªã‚¹ãƒˆã‚’ä½œæˆ
        low_stress_list = []
        for _, row in low_stress.iterrows():
            time = row.get('æ™‚åˆ»', '--:--')
            activity = row.get('æ´»å‹•å', 'ä¸æ˜')
            predicted_f = row.get('äºˆæ¸¬NASA_F', 0)
            low_stress_list.append(f"- {time} {activity}ï¼ˆ{predicted_f:.1f}ç‚¹ï¼‰")

        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰
        prompt = f"""ã‚ãªãŸã¯å„ªç§€ãªã‚¹ãƒˆãƒ¬ã‚¹ç®¡ç†ã‚³ãƒ³ã‚µãƒ«ã‚¿ãƒ³ãƒˆã§ã™ã€‚
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®1æ—¥ã®ãƒ•ãƒ©ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ¨å®šå€¤ã‚’æŒ¯ã‚Šè¿”ã‚Šã€äº‹å®Ÿã«åŸºã¥ã„ãŸæ°—ã¥ãã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚

é‡è¦ãªåˆ¶ç´„ï¼š
- å…·ä½“çš„ãªè¡Œå‹•ææ¡ˆã¯çµ¶å¯¾ã«ã—ãªã„ã§ãã ã•ã„
- äº‹å®Ÿã®æŒ¯ã‚Šè¿”ã‚Šã¨æ°—ã¥ãã®ä¿ƒé€²ã®ã¿ã«å¾¹ã—ã¦ãã ã•ã„
- å‘½ä»¤å½¢ï¼ˆã€Œã€œã—ã¾ã—ã‚‡ã†ã€ã€Œã€œã—ã¦ãã ã•ã„ã€ï¼‰ã¯ä½¿ã‚ãªã„ã§ãã ã•ã„
- ã€Œã€œã—ã¦ã¿ã‚‹ã®ã¯ã„ã‹ãŒã§ã—ã‚‡ã†ã‹ã€ã®ã‚ˆã†ãªææ¡ˆã‚‚å«ã‚ãªã„ã§ãã ã•ã„
- ãƒ¦ãƒ¼ã‚¶ãƒ¼è‡ªèº«ãŒè€ƒãˆã‚‹ãã£ã‹ã‘ã‚’æä¾›ã™ã‚‹ã ã‘ã§ã™

ã€æ—¥ä»˜ã€‘{target_date}

ã€1æ—¥ã®å¹³å‡ãƒ•ãƒ©ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã€‘{avg_stress:.1f}ç‚¹

ã€é«˜ã‚¹ãƒˆãƒ¬ã‚¹ã ã£ãŸæ™‚é–“å¸¯ã€‘
{chr(10).join(high_stress_list)}

ã€ä½ã‚¹ãƒˆãƒ¬ã‚¹ã ã£ãŸæ™‚é–“å¸¯ã€‘
{chr(10).join(low_stress_list)}

ä¸Šè¨˜ã®ãƒ‡ãƒ¼ã‚¿ã‚’ã‚‚ã¨ã«ã€ä»¥ä¸‹ã®ç‚¹ã‚’å«ã‚ã¦æŒ¯ã‚Šè¿”ã‚Šã‚’æä¾›ã—ã¦ãã ã•ã„ï¼š
1. ä»Šæ—¥ã®ãƒ•ãƒ©ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å€¤ã®å…¨ä½“çš„ãªå‚¾å‘
2. é«˜ã‚¹ãƒˆãƒ¬ã‚¹ã ã£ãŸæ´»å‹•ã®ç‰¹å¾´
3. ä½ã‚¹ãƒˆãƒ¬ã‚¹ã ã£ãŸæ´»å‹•ã®ç‰¹å¾´
4. æ°—ã¥ãã‚’ä¿ƒã™å•ã„ã‹ã‘

ã€é‡è¦ãªåˆ¶ç´„ã€‘
- ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã¯å¿…ãš150æ–‡å­—ä»¥å†…ã«åã‚ã¦ãã ã•ã„ï¼ˆå³æ ¼ãªåˆ¶ç´„ï¼‰
- æ¸©ã‹ãå…±æ„Ÿçš„ãªãƒˆãƒ¼ãƒ³ã§
- ç®‡æ¡æ›¸ãã¯ä½¿ã‚ãšã€è‡ªç„¶ãªæ–‡ç« ã§
"""
        return prompt

    def _get_fallback_prediction_only_feedback(self, target_date: str) -> Dict:
        """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨æ¨å®šå€¤ã®ã¿ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯"""
        return {
            'type': 'prediction_only_feedback',
            'date': target_date,
            'generated_at': datetime.now().isoformat(),
            'main_feedback': "ä»Šæ—¥ã‚‚ãŠç–²ã‚Œã•ã¾ã§ã—ãŸã€‚ã‚†ã£ãã‚Šä¼‘ã‚“ã§ã€æ˜æ—¥ã‚‚å¥åº·çš„ãªä¸€æ—¥ã‚’éã”ã—ã¦ãã ã•ã„ã€‚",
            'avg_stress': 0,
            'confidence': 0.3
        }